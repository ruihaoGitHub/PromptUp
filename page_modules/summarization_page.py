"""
æ‘˜è¦ä»»åŠ¡é¡µé¢æ¨¡å—
æä¾›æ‘˜è¦å™¨ Prompt ç”Ÿæˆå’Œä¼˜åŒ–åŠŸèƒ½
"""
import streamlit as st
import pandas as pd
from .base_page import BasePage
from config.defaults import get_default_value, get_placeholder, get_default_lab_dataset, get_default_dataset


class SummarizationPage(BasePage):
    """æ‘˜è¦ä»»åŠ¡é¡µé¢"""
    
    def render(self):
        """æ¸²æŸ“æ‘˜è¦ä»»åŠ¡é¡µé¢"""
        col1, col2 = self.create_two_columns()
        
        with col1:
            st.subheader("ğŸ“„ æ‘˜è¦ä»»åŠ¡é…ç½®")
            st.info("ğŸ“Œ æ‘˜è¦ä»»åŠ¡éœ€è¦æ˜ç¡®ä¿¡æ¯æå–è§„åˆ™ï¼Œç³»ç»Ÿå°†è®¾è®¡æœ€ä¼˜çš„æå–ç­–ç•¥ã€‚")
            
            # ä»»åŠ¡æè¿°
            task_description = st.text_area(
                "ä»»åŠ¡æè¿°",
                height=100,
                placeholder=get_placeholder("summarization", "task_description"),
                help="æ¸…æ™°æè¿°æ‘˜è¦çš„ç›®çš„",
                key="sum_task_desc"
            )
            
            # æºæ–‡æœ¬ç±»å‹
            source_type = st.selectbox(
                "ğŸ“ æºæ–‡æœ¬ç±»å‹",
                [
                    "æ–°é—»æŠ¥é“",
                    "å­¦æœ¯è®ºæ–‡",
                    "ä¼šè®®è®°å½•",
                    "æŠ€æœ¯æ–‡æ¡£",
                    "å®¢æˆ·åé¦ˆ",
                    "äº§å“è¯„è®º",
                    "ç ”ç©¶æŠ¥å‘Š",
                    "é‚®ä»¶å†…å®¹",
                    "å…¶ä»–"
                ],
                help="é€‰æ‹©éœ€è¦æ‘˜è¦çš„æ–‡æœ¬ç±»å‹",
                index=max(
                    0,
                    [
                        "æ–°é—»æŠ¥é“",
                        "å­¦æœ¯è®ºæ–‡",
                        "ä¼šè®®è®°å½•",
                        "æŠ€æœ¯æ–‡æ¡£",
                        "å®¢æˆ·åé¦ˆ",
                        "äº§å“è¯„è®º",
                        "ç ”ç©¶æŠ¥å‘Š",
                        "é‚®ä»¶å†…å®¹",
                        "å…¶ä»–"
                    ].index(get_default_value("summarization", "source_type"))
                    if get_default_value("summarization", "source_type") in [
                        "æ–°é—»æŠ¥é“",
                        "å­¦æœ¯è®ºæ–‡",
                        "ä¼šè®®è®°å½•",
                        "æŠ€æœ¯æ–‡æ¡£",
                        "å®¢æˆ·åé¦ˆ",
                        "äº§å“è¯„è®º",
                        "ç ”ç©¶æŠ¥å‘Š",
                        "é‚®ä»¶å†…å®¹",
                        "å…¶ä»–"
                    ] else 0
                )
            )
            
            # ç›®æ ‡å—ä¼—
            target_audience = st.text_input(
                "ğŸ‘¥ ç›®æ ‡å—ä¼—",
                placeholder=get_placeholder("summarization", "target_audience"),
                help="æ‘˜è¦å°†å‘ˆç°ç»™è°çœ‹ï¼Ÿè¿™ä¼šå½±å“è¯­è¨€é£æ ¼å’Œè¯¦ç»†ç¨‹åº¦"
            )
            
            # æ ¸å¿ƒå…³æ³¨ç‚¹
            focus_points = st.text_area(
                "ğŸ¯ æ ¸å¿ƒå…³æ³¨ç‚¹",
                height=100,
                placeholder=get_placeholder("summarization", "focus_points"),
                help="æ‘˜è¦ä¸­å¿…é¡»ä¿ç•™å“ªäº›ä¿¡æ¯ï¼Ÿ"
            )
            
            # ç¯‡å¹…é™åˆ¶ï¼ˆå¯é€‰ï¼‰
            with st.expander("ğŸ“ ç¯‡å¹…é™åˆ¶ï¼ˆå¯é€‰ï¼‰", expanded=False):
                length_constraint = st.selectbox(
                    "æ‘˜è¦é•¿åº¦",
                    ["ä¸é™åˆ¶", "100å­—ä»¥å†…", "200å­—ä»¥å†…", "3-5ä¸ªè¦ç‚¹", "æ¯ä¸ªå…³æ³¨ç‚¹ä¸è¶…è¿‡50å­—"],
                    help="æ§åˆ¶æ‘˜è¦çš„ç¯‡å¹…"
                )
                if length_constraint == "ä¸é™åˆ¶":
                    length_constraint = None
            
            # æ„å»ºæ‘˜è¦å™¨æŒ‰é’®
            build_summarization_btn = st.button("ğŸ”¨ æ„å»ºæ‘˜è¦å™¨ Prompt", type="primary", use_container_width=True)
        
        # æ‘˜è¦ä»»åŠ¡ä¼˜åŒ–é€»è¾‘
        if build_summarization_btn:
            if not self._validate_api_key():
                return
            
            # å¦‚æœç”¨æˆ·æ²¡æœ‰è¾“å…¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
            if not task_description or task_description.strip() == "":
                task_description = get_default_value("summarization", "task_description")
                st.info("ğŸ’¡ æœªè¾“å…¥ä»»åŠ¡æè¿°ï¼Œä½¿ç”¨é»˜è®¤ç¤ºä¾‹")
            
            if not target_audience or target_audience.strip() == "":
                target_audience = get_default_value("summarization", "target_audience")
            
            if not focus_points or focus_points.strip() == "":
                focus_points = get_default_value("summarization", "focus_points")
            
            # ä¿å­˜ç”¨æˆ·è¾“å…¥çš„ä»»åŠ¡æè¿°åˆ° session_stateï¼Œä¾›éšæœºæœç´¢ä½¿ç”¨
            st.session_state.user_task_description_summarization = task_description
            st.session_state.summarization_source_type = source_type
            st.session_state.summarization_target_audience = target_audience
            st.session_state.summarization_focus_points = focus_points
            
            with st.spinner("ğŸ”® æ­£åœ¨ç”Ÿæˆæå–è§„åˆ™ã€è®¾è®¡è¾“å‡ºæ ¼å¼ã€æ„å»ºæ‘˜è¦å™¨..."):
                try:
                    # æ‰§è¡Œæ‘˜è¦ä»»åŠ¡ä¼˜åŒ–
                    result = self.optimizer.optimize_summarization(
                        task_description=task_description,
                        source_type=source_type,
                        target_audience=target_audience,
                        focus_points=focus_points,
                        length_constraint=length_constraint
                    )
                    
                    # ä¿å­˜ç»“æœ
                    st.session_state.summarization_result = result
                    
                    st.success("âœ… æ‘˜è¦å™¨ Prompt æ„å»ºå®Œæˆï¼")
                    
                except Exception as e:
                    self._handle_optimization_error(e)
        
        # æ˜¾ç¤ºæ‘˜è¦ä»»åŠ¡ä¼˜åŒ–ç»“æœ
        if 'summarization_result' in st.session_state and st.session_state.summarization_result:
            result = st.session_state.summarization_result
            
            with col2:
                st.subheader("ğŸ“ æ‘˜è¦å™¨ Prompt")
                
                # 1. ä¼˜åŒ–æ€è·¯
                with st.expander("ğŸ§  æŸ¥çœ‹ä¼˜åŒ–æ€è·¯", expanded=True):
                    st.write(result.thinking_process)
                
                # 2. è§’è‰²è®¾å®š
                with st.expander("ğŸ‘¤ è§’è‰²è®¾å®š", expanded=False):
                    st.info(result.role_setting)
                
                # 3. æå–è§„åˆ™
                with st.expander("ğŸ“‹ ä¿¡æ¯æå–è§„åˆ™", expanded=True):
                    for idx, rule in enumerate(result.extraction_rules, 1):
                        st.markdown(f"**è§„åˆ™ {idx}:** {rule}")
                    st.caption("ğŸ’¡ æ˜ç¡®çš„æå–è§„åˆ™å¸®åŠ©æ¨¡å‹è¯†åˆ«å…³é”®ä¿¡æ¯")
                
                # 4. è´Ÿé¢çº¦æŸ
                with st.expander("ğŸš« è´Ÿé¢çº¦æŸï¼ˆé˜²æ­¢æ¨¡å‹å¹»è§‰ï¼‰", expanded=True):
                    for idx, constraint in enumerate(result.negative_constraints, 1):
                        st.markdown(f"**çº¦æŸ {idx}:** {constraint}")
                    st.caption("ğŸ’¡ å‘Šè¯‰æ¨¡å‹ã€Œä¸è¦åšä»€ä¹ˆã€ï¼Œé˜²æ­¢æ·»åŠ åŸæ–‡æ²¡æœ‰çš„å†…å®¹")
                
                # 5. å¤„ç†æ­¥éª¤
                with st.expander("ğŸ”„ æ€è€ƒæ­¥éª¤å¼•å¯¼", expanded=False):
                    st.write(result.step_by_step_guide)
                
                # 6. å…³æ³¨ç‚¹
                with st.expander("ğŸ¯ æ ¸å¿ƒå…³æ³¨é¢†åŸŸ", expanded=False):
                    for idx, area in enumerate(result.focus_areas, 1):
                        st.markdown(f"**å…³æ³¨ç‚¹ {idx}:** {area}")
                
                # 7. æœ€ç»ˆ Prompt
                st.markdown("**âœ¨ æœ€ç»ˆå®Œæ•´çš„æ‘˜è¦ Promptï¼ˆå¯ç›´æ¥å¤åˆ¶ï¼‰ï¼š**")
                st.caption("ğŸ’¡ ç”¨ {{text}} å ä½ç¬¦è¡¨ç¤ºå¾…æ‘˜è¦çš„æ–‡æœ¬")
                st.text_area(
                    "æ‘˜è¦å™¨ Prompt",
                    value=result.final_prompt,
                    height=400,
                    label_visibility="collapsed"
                )
                
                # ç›´æ¥æ˜¾ç¤ºä»£ç æ¡†ï¼Œå¸¦æœ‰å¤åˆ¶æŒ‰é’®
                st.code(result.final_prompt, language=None)
                st.caption("ğŸ“Œ ç‚¹å‡»ä»£ç æ¡†å³ä¸Šè§’çš„å¤åˆ¶æŒ‰é’®å³å¯å¤åˆ¶")
        
        # éªŒè¯å®éªŒå®¤åŒºåŸŸ
        if 'summarization_result' in st.session_state and st.session_state.summarization_result:
            self._render_validation_lab(st.session_state.summarization_result)

        self._render_optimization_lab()

    def _render_optimization_lab(self):
        """æ¸²æŸ“æ‘˜è¦ä»»åŠ¡ä¼˜åŒ–å®éªŒå®¤ï¼ˆéšæœºæœç´¢/é—ä¼ ç®—æ³•ï¼‰"""
        st.divider()
        st.subheader("ğŸ§¬ æç¤ºè¯ä¼˜åŒ–ï¼ˆéšæœºæœç´¢ / è´å¶æ–¯ä¼˜åŒ– / é—ä¼ ç®—æ³•ï¼‰")
        st.markdown("*é€šè¿‡æœç´¢/è¿›åŒ–é‡‡æ ·è§’è‰²/é£æ ¼/æŠ€å·§ç»„åˆï¼Œåœ¨å°å‹æµ‹è¯•é›†ä¸Šå¯»æ‰¾æ›´ä¼˜ Prompt ç»“æ„*" )

        optimization_algorithm = st.radio(
            "é€‰æ‹©ä¼˜åŒ–ç®—æ³•",
            ["éšæœºæœç´¢", "è´å¶æ–¯ä¼˜åŒ–", "é—ä¼ ç®—æ³•"],
            key="sum_opt_algorithm",
            help="éšæœºæœç´¢é€‚åˆå¿«é€Ÿä½“éªŒï¼Œé—ä¼ ç®—æ³•é€‚åˆæ›´ç³»ç»Ÿçš„ä¼˜åŒ–",
            horizontal=True
        )

        st.markdown("**ğŸ“Š ä¼˜åŒ–æ•°æ®æ¥æº**")
        data_source = st.radio(
            "é€‰æ‹©ä¼˜åŒ–ä½¿ç”¨çš„æ•°æ®æ¥æº",
            ["ä½¿ç”¨é»˜è®¤æ•°æ®", "ä¸Šä¼ CSVæ–‡ä»¶", "æ‰‹åŠ¨è¾“å…¥"],
            key="sum_opt_data_source",
            help="é€‰æ‹©ç”¨äºä¼˜åŒ–çš„æµ‹è¯•æ•°æ®æ¥æº",
            horizontal=True
        )

        if data_source == "ä¸Šä¼ CSVæ–‡ä»¶":
            self._render_opt_csv_upload()
        elif data_source == "æ‰‹åŠ¨è¾“å…¥":
            self._render_opt_manual_input()

        task_desc, task_key, dataset, extra_config = self._get_optimization_config()

        if optimization_algorithm == "éšæœºæœç´¢":
            col_a, col_b = st.columns([1, 2])
            with col_a:
                iterations = st.slider("è¿­ä»£æ¬¡æ•°", min_value=5, max_value=50, value=12, step=1, key="sum_opt_iterations")
            with col_b:
                st.caption("å»ºè®®ï¼šå¿«é€Ÿä½“éªŒ 5-10 æ¬¡ï¼›æœ‰æ•ˆä¼˜åŒ– 20-50 æ¬¡ï¼ˆæˆæœ¬æ›´é«˜ï¼‰ã€‚")

            if st.button("ğŸš€ è¿è¡Œéšæœºæœç´¢", type="primary", use_container_width=True, key="sum_opt_random_btn"):
                with st.spinner("â³ æ­£åœ¨ç”Ÿæˆæœç´¢ç©ºé—´å¹¶æ‰§è¡Œéšæœºæœç´¢..."):
                    try:
                        search_space = self.optimizer.search_space_generator.generate(
                            task_description=task_desc,
                            task_type=task_key,
                            **extra_config
                        )

                        st.success("âœ… æœç´¢ç©ºé—´ç”Ÿæˆå®Œæˆï¼")
                        st.info("ğŸ’¡ ç³»ç»Ÿå°†ä»è¿™äº›é€‰é¡¹ä¸­éšæœºç»„åˆè¿›è¡Œæµ‹è¯•ï¼Œæ¯ä¸ªç»„åˆåŒ…å«ï¼š1ä¸ªè§’è‰² + 1ç§é£æ ¼ + 1ç§æŠ€å·§")
                        self._render_search_space_preview(search_space)

                        results, best = self.optimizer.random_search.run(
                            task_description=task_desc,
                            task_type=task_key,
                            test_dataset=dataset,
                            search_space=search_space,
                            iterations=iterations,
                            labels=None
                        )

                        st.session_state.sum_opt_random_results = results
                        st.session_state.sum_opt_random_best = best
                        st.session_state.sum_opt_random_space = search_space
                    except Exception as e:
                        st.error(f"âŒ éšæœºæœç´¢å¤±è´¥ï¼š{str(e)}")

            if 'sum_opt_random_best' in st.session_state and st.session_state.sum_opt_random_best:
                best = st.session_state.sum_opt_random_best
                search_space = st.session_state.get('sum_opt_random_space')
                results = st.session_state.get('sum_opt_random_results', [])
                # æ–°å¢ï¼šéšæœºæœç´¢å¾—åˆ†æ›²çº¿
                if results:
                    st.divider()
                    st.markdown("### ğŸ“ˆ éšæœºæœç´¢å¾—åˆ†æ›²çº¿")
                    df = pd.DataFrame({
                        "è¿­ä»£": [r.iteration_id for r in results],
                        "å¾—åˆ†": [r.avg_score for r in results]
                    })
                    st.line_chart(df.set_index("è¿­ä»£"))
                self._render_optimization_result(best, search_space)
        elif optimization_algorithm == "é—ä¼ ç®—æ³•":
            col_a, col_b, col_c, col_d = st.columns(4)
            with col_a:
                generations = st.slider("è¿›åŒ–ä»£æ•°", min_value=3, max_value=20, value=6, step=1, key="sum_opt_generations")
            with col_b:
                population_size = st.slider("ç§ç¾¤è§„æ¨¡", min_value=4, max_value=24, value=8, step=1, key="sum_opt_population")
            with col_c:
                elite_ratio = st.slider("ç²¾è‹±æ¯”ä¾‹", min_value=0.1, max_value=0.5, value=0.2, step=0.05, key="sum_opt_elite")
            with col_d:
                mutation_rate = st.slider("å˜å¼‚ç‡", min_value=0.05, max_value=0.6, value=0.2, step=0.05, key="sum_opt_mutation")

            if st.button("ğŸ§¬ è¿è¡Œé—ä¼ ç®—æ³•", type="primary", use_container_width=True, key="sum_opt_ga_btn"):
                with st.spinner("â³ æ­£åœ¨ç”Ÿæˆæœç´¢ç©ºé—´å¹¶æ‰§è¡Œé—ä¼ ç®—æ³•..."):
                    try:
                        search_space = self.optimizer.search_space_generator.generate(
                            task_description=task_desc,
                            task_type=task_key,
                            **extra_config
                        )

                        st.success("âœ… æœç´¢ç©ºé—´ç”Ÿæˆå®Œæˆï¼")
                        st.info("ğŸ’¡ ç³»ç»Ÿå°†ä»è¿™äº›é€‰é¡¹ä¸­è¿›åŒ–ç»„åˆè¿›è¡Œæµ‹è¯•ï¼Œæ¯ä¸ªç»„åˆåŒ…å«ï¼š1ä¸ªè§’è‰² + 1ç§é£æ ¼ + 1ç§æŠ€å·§")
                        self._render_search_space_preview(search_space)

                        progress = st.progress(0)
                        progress_text = st.empty()

                        def _progress_callback(current_gen, total_gen, best_score, avg_score):
                            if total_gen > 0:
                                progress_value = int(min(100, (current_gen / total_gen) * 100))
                                progress.progress(progress_value)
                            progress_text.info(
                                f"ç¬¬ {current_gen}/{total_gen} ä»£ | æœ€ä½³å¾—åˆ† {best_score:.2f} | å¹³å‡å¾—åˆ† {avg_score:.2f}"
                            )

                        results, best, evolution_history = self.optimizer.run_genetic_algorithm(
                            task_description=task_desc,
                            task_type=task_key,
                            test_dataset=dataset,
                            search_space=search_space,
                            generations=generations,
                            population_size=population_size,
                            elite_ratio=elite_ratio,
                            mutation_rate=mutation_rate,
                            progress_callback=_progress_callback
                        )

                        st.session_state.sum_opt_ga_results = results
                        st.session_state.sum_opt_ga_best = best
                        st.session_state.sum_opt_ga_history = evolution_history
                        st.session_state.sum_opt_ga_space = search_space
                    except Exception as e:
                        st.error(f"âŒ é—ä¼ ç®—æ³•å¤±è´¥ï¼š{str(e)}")

            if 'sum_opt_ga_best' in st.session_state and st.session_state.sum_opt_ga_best:
                best = st.session_state.sum_opt_ga_best
                search_space = st.session_state.get('sum_opt_ga_space')
                evolution_history = st.session_state.get('sum_opt_ga_history', [])
                self._render_optimization_result(best, search_space, evolution_history)
        else:
            col_a, col_b = st.columns([1, 2])
            with col_a:
                n_trials = st.slider("è¯•éªŒæ¬¡æ•°", min_value=5, max_value=50, value=12, step=1, key="sum_opt_bo_trials")
            with col_b:
                st.caption("å»ºè®®ï¼šå¿«é€Ÿä½“éªŒ 8-12 æ¬¡ï¼›ç¨³å®šä¼˜åŒ– 15-30 æ¬¡ï¼ˆæˆæœ¬æ›´é«˜ï¼‰ã€‚")

            if st.button("ğŸ§ª è¿è¡Œè´å¶æ–¯ä¼˜åŒ–", type="primary", use_container_width=True, key="sum_opt_bo_btn"):
                with st.spinner("â³ æ­£åœ¨ç”Ÿæˆæœç´¢ç©ºé—´å¹¶æ‰§è¡Œè´å¶æ–¯ä¼˜åŒ–..."):
                    try:
                        search_space = self.optimizer.search_space_generator.generate(
                            task_description=task_desc,
                            task_type=task_key,
                            **extra_config
                        )

                        st.success("âœ… æœç´¢ç©ºé—´ç”Ÿæˆå®Œæˆï¼")
                        st.info("ğŸ’¡ ç³»ç»Ÿå°†ä½¿ç”¨ TPE æ™ºèƒ½é€‰æ‹©ç»„åˆè¿›è¡Œæµ‹è¯•ï¼Œæ¯ä¸ªç»„åˆåŒ…å«ï¼š1ä¸ªè§’è‰² + 1ç§é£æ ¼ + 1ç§æŠ€å·§")
                        self._render_search_space_preview(search_space)

                        progress = st.progress(0)
                        progress_text = st.empty()

                        def _progress_callback(current_trial, total_trials, best_score):
                            if total_trials > 0:
                                progress_value = int(min(100, (current_trial / total_trials) * 100))
                                progress.progress(progress_value)
                            progress_text.info(
                                f"è¯•éªŒ {current_trial}/{total_trials} | å½“å‰æœ€ä½³ {best_score:.2f}"
                            )

                        results, best, trial_history = self.optimizer.run_bayesian_optimization(
                            task_description=task_desc,
                            task_type=task_key,
                            test_dataset=dataset,
                            search_space=search_space,
                            n_trials=n_trials,
                            progress_callback=_progress_callback
                        )

                        st.session_state.sum_opt_bo_results = results
                        st.session_state.sum_opt_bo_best = best
                        st.session_state.sum_opt_bo_history = trial_history
                        st.session_state.sum_opt_bo_space = search_space
                    except Exception as e:
                        st.error(f"âŒ è´å¶æ–¯ä¼˜åŒ–å¤±è´¥ï¼š{str(e)}")

            if 'sum_opt_bo_best' in st.session_state and st.session_state.sum_opt_bo_best:
                best = st.session_state.sum_opt_bo_best
                search_space = st.session_state.get('sum_opt_bo_space')
                trial_history = st.session_state.get('sum_opt_bo_history', [])
                if trial_history:
                    st.divider()
                    st.markdown("### ğŸ“ˆ è´å¶æ–¯ä¼˜åŒ–å¾—åˆ†æ›²çº¿")
                    df = pd.DataFrame({
                        "è¯•éªŒ": [h["trial"] for h in trial_history],
                        "å¾—åˆ†": [h["score"] for h in trial_history],
                        "å†å²æœ€ä½³": [h["best_score"] for h in trial_history]
                    })
                    st.line_chart(df.set_index("è¯•éªŒ"))
                self._render_optimization_result(best, search_space)

    def _render_search_space_preview(self, search_space):
        with st.expander("ğŸ” æŸ¥çœ‹ç”Ÿæˆçš„æœç´¢ç©ºé—´", expanded=True):
            col1, col2, col3 = st.columns(3)
            with col1:
                st.markdown("**ğŸ­ è§’è‰²è®¾å®š (5ä¸ª)**")
                for i, role in enumerate(search_space.roles, 1):
                    st.markdown(f"{i}. {role}")
            with col2:
                st.markdown("**ğŸ¨ å›ç­”é£æ ¼ (5ç§)**")
                for i, style in enumerate(search_space.styles, 1):
                    st.markdown(f"{i}. {style}")
            with col3:
                st.markdown("**ğŸ› ï¸ æç¤ºæŠ€å·§ (3ç§)**")
                for i, technique in enumerate(search_space.techniques, 1):
                    st.markdown(f"{i}. {technique}")

    def _render_optimization_result(self, best, search_space, evolution_history=None):
        st.success(f"âœ… æœ€ä½³å¾—åˆ†ï¼š{best.avg_score:.2f}")
        st.markdown(f"**æœ€ä½³ç»„åˆï¼š** {best.role} + {best.style} + {best.technique}")
        st.text_area("æœ€ä½³ Prompt", value=best.full_prompt, height=200)

        if evolution_history:
            st.divider()
            st.markdown("### ğŸ“ˆ è¿›åŒ–è¿‡ç¨‹")
            history_df = pd.DataFrame(evolution_history)
            history_df = history_df.rename(columns={
                "generation": "ä»£æ•°",
                "best_score": "æœ€ä½³å¾—åˆ†",
                "avg_score": "å¹³å‡å¾—åˆ†"
            })
            st.line_chart(history_df.set_index("ä»£æ•°")[["æœ€ä½³å¾—åˆ†", "å¹³å‡å¾—åˆ†"]])

        if search_space:
            st.divider()
            st.markdown("### ğŸ” æœç´¢ç©ºé—´è¯¦æƒ…")
            with st.expander("æŸ¥çœ‹å®Œæ•´çš„æœç´¢ç©ºé—´", expanded=False):
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.markdown("**ğŸ­ è§’è‰²è®¾å®š (5ä¸ª)**")
                    for i, role in enumerate(search_space.roles, 1):
                        if role == best.role:
                            st.markdown(f"**{i}. {role} â† æœ€ä½³é€‰æ‹©**")
                        else:
                            st.markdown(f"{i}. {role}")
                with col2:
                    st.markdown("**ğŸ¨ å›ç­”é£æ ¼ (5ç§)**")
                    for i, style in enumerate(search_space.styles, 1):
                        if style == best.style:
                            st.markdown(f"**{i}. {style} â† æœ€ä½³é€‰æ‹©**")
                        else:
                            st.markdown(f"{i}. {style}")
                with col3:
                    st.markdown("**ğŸ› ï¸ æç¤ºæŠ€å·§ (3ç§)**")
                    for i, technique in enumerate(search_space.techniques, 1):
                        if technique == best.technique:
                            st.markdown(f"**{i}. {technique} â† æœ€ä½³é€‰æ‹©**")
                        else:
                            st.markdown(f"{i}. {technique}")

    def _render_opt_csv_upload(self):
        st.markdown("**ğŸ“ CSVæ–‡ä»¶ä¸Šä¼ **")
        st.info("CSVæ–‡ä»¶åº”åŒ…å«ä¸¤åˆ—ï¼š'text'ï¼ˆæ–‡æœ¬ï¼‰å’Œ 'expected'ï¼ˆå‚è€ƒæ‘˜è¦ï¼‰")
        uploaded_file = st.file_uploader(
            "é€‰æ‹©CSVæ–‡ä»¶",
            type=["csv"],
            key="sum_opt_csv_upload",
            help="ä¸Šä¼ åŒ…å«æµ‹è¯•æ•°æ®çš„CSVæ–‡ä»¶"
        )
        if uploaded_file is not None:
            try:
                df = pd.read_csv(uploaded_file)
                required_columns = ["text", "expected"]
                if not all(col in df.columns for col in required_columns):
                    st.error(f"âŒ CSVæ–‡ä»¶å¿…é¡»åŒ…å«ä»¥ä¸‹åˆ—ï¼š{', '.join(required_columns)}")
                    return
                st.success(f"âœ… æˆåŠŸåŠ è½½ {len(df)} æ¡æµ‹è¯•æ•°æ®")
                st.markdown("**æ•°æ®é¢„è§ˆï¼š**")
                st.dataframe(df.head(), use_container_width=True)
                st.session_state.sum_opt_custom_data = df.to_dict('records')
            except Exception as e:
                st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}")

    def _render_opt_manual_input(self):
        st.markdown("**âœï¸ æ‰‹åŠ¨è¾“å…¥æµ‹è¯•æ•°æ®**")
        manual_data = st.session_state.get('sum_opt_manual_data', [
            {"text": "", "expected": ""},
            {"text": "", "expected": ""},
            {"text": "", "expected": ""}
        ])

        updated_data = []
        for i, item in enumerate(manual_data):
            col1, col2, col3 = st.columns([4, 4, 1])
            with col1:
                text = st.text_area(
                    f"åŸæ–‡ {i+1}",
                    value=item["text"],
                    key=f"sum_opt_manual_text_{i}",
                    height=100,
                    placeholder="è¾“å…¥åŸæ–‡"
                )
            with col2:
                expected = st.text_area(
                    f"å‚è€ƒæ‘˜è¦ {i+1}",
                    value=item["expected"],
                    key=f"sum_opt_manual_expected_{i}",
                    height=80,
                    placeholder="è¾“å…¥å‚è€ƒæ‘˜è¦"
                )
            with col3:
                if st.button("ğŸ—‘ï¸", key=f"sum_opt_manual_delete_{i}", help=f"åˆ é™¤ç¬¬{i+1}è¡Œ"):
                    continue

            if text.strip() or expected.strip():
                updated_data.append({"text": text, "expected": expected})

        if st.button("â• æ·»åŠ ä¸€è¡Œ", key="sum_opt_manual_add_row"):
            updated_data.append({"text": "", "expected": ""})

        st.session_state.sum_opt_manual_data = updated_data
        valid_count = sum(1 for item in updated_data if item["text"].strip() and item["expected"].strip())
        st.info(f"å½“å‰æœ‰ {valid_count} æ¡æœ‰æ•ˆæµ‹è¯•æ•°æ®ç”¨äºä¼˜åŒ–")

    def _get_opt_test_dataset(self):
        data_source = st.session_state.get('sum_opt_data_source', 'ä½¿ç”¨é»˜è®¤æ•°æ®')

        if data_source == "ä½¿ç”¨é»˜è®¤æ•°æ®":
            return get_default_dataset("summarization")

        if data_source == "ä¸Šä¼ CSVæ–‡ä»¶":
            if st.session_state.get('sum_opt_custom_data'):
                return [
                    {"input": item["text"], "ground_truth": item["expected"]}
                    for item in st.session_state.sum_opt_custom_data
                    if item.get("text", "").strip() and item.get("expected", "").strip()
                ] or get_default_dataset("summarization")
            return get_default_dataset("summarization")

        if data_source == "æ‰‹åŠ¨è¾“å…¥":
            manual_data = [
                item for item in st.session_state.get('sum_opt_manual_data', [])
                if item.get("text", "").strip() and item.get("expected", "").strip()
            ]
            if manual_data:
                return [
                    {"input": item["text"], "ground_truth": item["expected"]}
                    for item in manual_data
                ]
            return get_default_dataset("summarization")

        return get_default_dataset("summarization")

    def _get_optimization_config(self):
        user_task_desc = st.session_state.get('user_task_description_summarization', get_default_value("summarization", "task_description"))
        source_type = st.session_state.get('summarization_source_type', get_default_value("summarization", "source_type"))
        target_audience = st.session_state.get('summarization_target_audience', get_default_value("summarization", "target_audience"))
        focus_points = st.session_state.get('summarization_focus_points', get_default_value("summarization", "focus_points"))

        test_dataset = self._get_opt_test_dataset()

        return user_task_desc, "summarization", test_dataset, {
            "source_type": source_type,
            "target_audience": target_audience,
            "focus_points": focus_points
        }
    
    def _render_validation_lab(self, result):
        """æ¸²æŸ“æ‘˜è¦éªŒè¯å®éªŒå®¤"""
        st.divider()
        st.subheader("ğŸ”¬ æ•ˆæœéªŒè¯å®éªŒå®¤")
        st.markdown("*ä½¿ç”¨æµ‹è¯•æ ·æœ¬éªŒè¯æ‘˜è¦è´¨é‡*")

        # æµ‹è¯•æ•°æ®æ¥æºé€‰æ‹©
        st.markdown("**ğŸ“Š æµ‹è¯•æ•°æ®æ¥æº**")
        data_source = st.radio(
            "é€‰æ‹©æ•°æ®æ¥æº",
            ["ä½¿ç”¨é»˜è®¤æ•°æ®", "ä¸Šä¼ CSVæ–‡ä»¶", "æ‰‹åŠ¨è¾“å…¥"],
            key="sum_data_source",
            help="é€‰æ‹©æµ‹è¯•æ•°æ®çš„æ¥æºæ–¹å¼",
            horizontal=True
        )

        # æ ¹æ®é€‰æ‹©æ˜¾ç¤ºç›¸åº”çš„è¾“å…¥ç•Œé¢
        if data_source == "ä¸Šä¼ CSVæ–‡ä»¶":
            self._render_csv_upload()
        elif data_source == "æ‰‹åŠ¨è¾“å…¥":
            self._render_manual_input()

        # è·å–æµ‹è¯•æ•°æ®
        test_cases = self._get_test_cases()
        
        col_test1, col_test2 = st.columns([1, 1])
        
        with col_test1:
            st.markdown("**ğŸ“„ æµ‹è¯•æ ·æœ¬ï¼ˆåŸæ–‡ / å‚è€ƒæ‘˜è¦ï¼‰**")
            st.caption("ä¿®æ”¹ä¸‹æ–¹çš„æµ‹è¯•æ–‡æœ¬å’Œå‚è€ƒæ‘˜è¦ï¼š")

            for i, case in enumerate(test_cases):
                with st.container():
                    st.markdown(f"**æµ‹è¯• {i+1}:**")
                    text = st.text_area(
                        f"åŸæ–‡ {i+1}",
                        value=case["text"],
                        height=120,
                        key=f"sum_test_text_{i}"
                    )
                    expected = st.text_area(
                        f"å‚è€ƒæ‘˜è¦ {i+1}",
                        value=case["expected"],
                        height=100,
                        key=f"sum_test_expected_{i}"
                    )
                    test_cases[i] = {"text": text, "expected": expected}
        
        with col_test2:
            st.markdown("**ğŸ¯ è¯„åˆ†æ ‡å‡†**")
            st.info("""
**ROUGE Scoreï¼ˆæ‘˜è¦ä»»åŠ¡ï¼‰**

**ROUGE æŒ‡æ ‡è¯´æ˜**ï¼š
- **ROUGE-1**ï¼šå•è¯é‡å ç‡
- **ROUGE-2**ï¼šåŒè¯ç»„é‡å ç‡
- **ROUGE-L**ï¼šæœ€é•¿å…¬å…±å­åºåˆ—

**è¯„åˆ†æ ‡å‡†**ï¼š
- ğŸŸ¢ **ä¼˜ç§€** â‰¥ 50%
- ğŸŸ¡ **è‰¯å¥½** 30% - 50%
- ğŸ”´ **éœ€æ”¹è¿›** < 30%
            """)
        
        # è¿è¡ŒéªŒè¯æŒ‰é’®
        if st.button("ğŸš€ ç”Ÿæˆæ‘˜è¦", type="primary", use_container_width=True, key="sum_validation_btn"):
            valid_cases = [c for c in test_cases if c["text"].strip() and c["expected"].strip()]
            if not valid_cases:
                st.error("âŒ è¯·è‡³å°‘æä¾›ä¸€æ¡å®Œæ•´çš„æµ‹è¯•æ ·æœ¬ï¼ˆåŸæ–‡ä¸å‚è€ƒæ‘˜è¦ï¼‰")
            else:
                with st.spinner("â³ æ­£åœ¨ç”Ÿæˆæ‘˜è¦..."):
                    try:
                        from metrics import MetricsCalculator
                        calc = MetricsCalculator()

                        results = []
                        for case in valid_cases:
                            prompt_with_text = result.final_prompt.replace("{{text}}", case["text"])
                            prompt_with_text = prompt_with_text.replace("{text}", case["text"])
                            prompt_with_text = prompt_with_text.replace("[å¾…æ‘˜è¦æ–‡æœ¬]", case["text"])

                            response = self.optimizer.llm.invoke(prompt_with_text)
                            summary = response.content.strip()

                            rouge_scores = calc.calculate_rouge(summary, case["expected"], lang="zh")

                            results.append({
                                "original": case["text"],
                                "summary": summary,
                                "reference": case["expected"],
                                "rouge_scores": rouge_scores,
                                "compression_ratio": len(summary) / len(case["text"]) * 100
                            })

                        st.session_state.sum_validation_results = results

                        avg_rouge1 = sum(r["rouge_scores"]["rouge1"] for r in results) / len(results)
                        avg_rouge2 = sum(r["rouge_scores"]["rouge2"] for r in results) / len(results)
                        avg_rougeL = sum(r["rouge_scores"]["rougeL"] for r in results) / len(results)
                        st.session_state.sum_avg_rouge = {
                            "rouge1": avg_rouge1,
                            "rouge2": avg_rouge2,
                            "rougeL": avg_rougeL
                        }

                    except Exception as e:
                        st.error(f"âŒ ç”Ÿæˆæ‘˜è¦å¤±è´¥ï¼š{str(e)}")
        
        # æ˜¾ç¤ºéªŒè¯ç»“æœ
        if 'sum_validation_results' in st.session_state and st.session_state.sum_validation_results:
            results = st.session_state.sum_validation_results
            avg_scores = st.session_state.get('sum_avg_rouge', {"rouge1": 0, "rouge2": 0, "rougeL": 0})

            st.divider()
            st.markdown("### ğŸ“Š æ‘˜è¦ç»“æœ")

            avg_rouge = (avg_scores['rouge1'] + avg_scores['rouge2'] + avg_scores['rougeL']) / 3

            if avg_rouge >= 50:
                st.success(f"ğŸ‰ å¹³å‡ ROUGE åˆ†æ•°ï¼š{avg_rouge:.2f}% - ğŸŸ¢ ä¼˜ç§€ï¼")
            elif avg_rouge >= 30:
                st.info(f"ğŸ‘ å¹³å‡ ROUGE åˆ†æ•°ï¼š{avg_rouge:.2f}% - ğŸŸ¡ è‰¯å¥½")
            else:
                st.warning(f"âš ï¸ å¹³å‡ ROUGE åˆ†æ•°ï¼š{avg_rouge:.2f}% - ğŸ”´ éœ€æ”¹è¿›")

            col_r1, col_r2, col_r3 = st.columns(3)
            with col_r1:
                st.metric("ROUGE-1", f"{avg_scores['rouge1']:.2f}%", help="å•è¯é‡å ç‡")
            with col_r2:
                st.metric("ROUGE-2", f"{avg_scores['rouge2']:.2f}%", help="åŒè¯ç»„é‡å ç‡")
            with col_r3:
                st.metric("ROUGE-L", f"{avg_scores['rougeL']:.2f}%", help="æœ€é•¿å…¬å…±å­åºåˆ—")

            for i, r in enumerate(results, 1):
                with st.expander(f"æµ‹è¯• {i} ç»“æœ", expanded=(i == 1)):
                    col_result1, col_result2, col_result3 = st.columns([1, 1, 1])

                    with col_result1:
                        st.markdown("**ğŸ“„ åŸæ–‡**")
                        st.text_area(
                            f"åŸæ–‡_{i}",
                            value=r["original"],
                            height=150,
                            label_visibility="collapsed",
                            disabled=True
                        )

                    with col_result2:
                        st.markdown("**âœ¨ AIç”Ÿæˆçš„æ‘˜è¦**")
                        st.text_area(
                            f"AIæ‘˜è¦_{i}",
                            value=r["summary"],
                            height=150,
                            label_visibility="collapsed"
                        )

                    with col_result3:
                        st.markdown("**ğŸ“Œ å‚è€ƒæ‘˜è¦**")
                        st.text_area(
                            f"å‚è€ƒæ‘˜è¦_{i}",
                            value=r["reference"],
                            height=150,
                            label_visibility="collapsed",
                            disabled=True
                        )

                    st.markdown("**ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯**")
                    stat_col1, stat_col2, stat_col3, stat_col4 = st.columns(4)
                    with stat_col1:
                        st.metric("åŸæ–‡å­—æ•°", len(r["original"]))
                    with stat_col2:
                        st.metric("æ‘˜è¦å­—æ•°", len(r["summary"]))
                    with stat_col3:
                        st.metric("å‹ç¼©ç‡", f"{r['compression_ratio']:.1f}%")
                    with stat_col4:
                        r_avg = (r["rouge_scores"]["rouge1"] + r["rouge_scores"]["rouge2"] + r["rouge_scores"]["rougeL"]) / 3
                        st.metric("è¯¥æ ·æœ¬ROUGEå‡å€¼", f"{r_avg:.2f}%")

            st.markdown("**ğŸ’¡ äººå·¥è¯„ä¼°å»ºè®®**")
            st.caption("ROUGE åˆ†æ•°æ˜¯è‡ªåŠ¨åŒ–æŒ‡æ ‡ï¼Œå»ºè®®ç»“åˆäººå·¥è¯„ä¼°åˆ¤æ–­æ‘˜è¦è´¨é‡ï¼ˆå®Œæ•´æ€§ã€å‡†ç¡®æ€§ã€ç®€æ´æ€§ã€å¯è¯»æ€§ï¼‰")

    def _render_csv_upload(self):
        """æ¸²æŸ“CSVæ–‡ä»¶ä¸Šä¼ ç•Œé¢"""
        st.markdown("**ğŸ“ CSVæ–‡ä»¶ä¸Šä¼ **")
        st.info("CSVæ–‡ä»¶åº”åŒ…å«ä¸¤åˆ—ï¼š'text'ï¼ˆåŸæ–‡ï¼‰å’Œ 'expected'ï¼ˆå‚è€ƒæ‘˜è¦ï¼‰")

        uploaded_file = st.file_uploader(
            "é€‰æ‹©CSVæ–‡ä»¶",
            type=["csv"],
            key="sum_csv_upload",
            help="ä¸Šä¼ åŒ…å«æ‘˜è¦æµ‹è¯•æ•°æ®çš„CSVæ–‡ä»¶"
        )

        if uploaded_file is not None:
            try:
                df = pd.read_csv(uploaded_file)
                required_columns = ["text", "expected"]
                if not all(col in df.columns for col in required_columns):
                    st.error(f"âŒ CSVæ–‡ä»¶å¿…é¡»åŒ…å«ä»¥ä¸‹åˆ—ï¼š{', '.join(required_columns)}")
                    return

                st.success(f"âœ… æˆåŠŸåŠ è½½ {len(df)} æ¡æµ‹è¯•æ•°æ®")
                st.markdown("**æ•°æ®é¢„è§ˆï¼š**")
                st.dataframe(df.head(), use_container_width=True)

                st.session_state.sum_custom_test_data = df.to_dict('records')

            except Exception as e:
                st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}")

    def _render_manual_input(self):
        """æ¸²æŸ“æ‰‹åŠ¨è¾“å…¥ç•Œé¢"""
        st.markdown("**âœï¸ æ‰‹åŠ¨è¾“å…¥æµ‹è¯•æ•°æ®**")

        manual_data = st.session_state.get('sum_manual_test_data', [
            {"text": "", "expected": ""},
            {"text": "", "expected": ""},
            {"text": "", "expected": ""}
        ])

        st.markdown("æ·»åŠ æµ‹è¯•æ ·æœ¬ï¼š")

        updated_data = []
        for i, item in enumerate(manual_data):
            col1, col2, col3 = st.columns([4, 4, 1])
            with col1:
                text = st.text_area(
                    f"åŸæ–‡ {i+1}",
                    value=item["text"],
                    key=f"sum_manual_text_{i}",
                    height=100,
                    placeholder="è¾“å…¥å¾…æ‘˜è¦åŸæ–‡"
                )
            with col2:
                expected = st.text_area(
                    f"å‚è€ƒæ‘˜è¦ {i+1}",
                    value=item["expected"],
                    key=f"sum_manual_expected_{i}",
                    height=100,
                    placeholder="è¾“å…¥å‚è€ƒæ‘˜è¦"
                )
            with col3:
                if st.button("ğŸ—‘ï¸", key=f"sum_delete_{i}", help=f"åˆ é™¤ç¬¬{i+1}è¡Œ"):
                    continue

            if text.strip() or expected.strip():
                updated_data.append({"text": text, "expected": expected})

        if st.button("â• æ·»åŠ ä¸€è¡Œ", key="sum_add_manual_row"):
            updated_data.append({"text": "", "expected": ""})

        st.session_state.sum_manual_test_data = updated_data

        valid_count = sum(1 for item in updated_data if item["text"].strip() and item["expected"].strip())
        st.info(f"å½“å‰æœ‰ {valid_count} æ¡æœ‰æ•ˆæµ‹è¯•æ•°æ®")

    def _get_test_cases(self):
        """è·å–æµ‹è¯•æ•°æ®ï¼Œæ ¹æ®ç”¨æˆ·é€‰æ‹©è¿”å›ç›¸åº”æ•°æ®"""
        data_source = st.session_state.get('sum_data_source', 'ä½¿ç”¨é»˜è®¤æ•°æ®')

        if data_source == "ä½¿ç”¨é»˜è®¤æ•°æ®":
            if 'sum_custom_test_data' in st.session_state:
                del st.session_state.sum_custom_test_data
            if 'sum_manual_test_data' in st.session_state:
                del st.session_state.sum_manual_test_data
            return get_default_lab_dataset("summarization")

        elif data_source == "ä¸Šä¼ CSVæ–‡ä»¶":
            if 'sum_custom_test_data' in st.session_state and st.session_state.sum_custom_test_data:
                return st.session_state.sum_custom_test_data
            else:
                return get_default_lab_dataset("summarization")

        elif data_source == "æ‰‹åŠ¨è¾“å…¥":
            if 'sum_manual_test_data' in st.session_state:
                manual_data = [item for item in st.session_state.sum_manual_test_data
                              if item["text"].strip() and item["expected"].strip()]
                if manual_data:
                    return manual_data
            return get_default_lab_dataset("summarization")

        return get_default_lab_dataset("summarization")
    
    def _validate_api_key(self):
        """éªŒè¯ API Key"""
        api_key = st.session_state.get('api_key_input', '')
        if not api_key or api_key.strip() == "":
            st.error("âŒ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® API Key")
            return False
        return True
    
    def _handle_optimization_error(self, e):
        """å¤„ç†ä¼˜åŒ–é”™è¯¯"""
        error_msg = str(e)
        st.error(f"âŒ æ„å»ºå¤±è´¥ï¼š{error_msg}")
        
        api_provider = st.session_state.get('api_provider', 'NVIDIA')
        
        # æä¾›è§£å†³æ–¹æ¡ˆ
        if "404" in error_msg or "401" in error_msg:
            st.warning("""**å¯èƒ½çš„åŸå› å’Œè§£å†³æ–¹æ¡ˆï¼š**""")
            if api_provider == "NVIDIA":
                st.markdown("""
                1. **API Key æ— æ•ˆæˆ–æœªé…ç½®**
                   - è¯·è®¿é—® [NVIDIA Build](https://build.nvidia.com/) è·å– API Key
                2. **æ¨¡å‹ä¸æ”¯æŒ**
                   - æ¨èä½¿ç”¨ meta/llama-3.1-405b-instruct
                """)
        
        st.info("ğŸ”§ å»ºè®®ï¼šè¿è¡Œ `python test_nvidia.py` æµ‹è¯• API è¿æ¥")
