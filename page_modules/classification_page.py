"""
åˆ†ç±»ä»»åŠ¡é¡µé¢æ¨¡å—
æä¾›åˆ†ç±»å™¨ Prompt ç”Ÿæˆå’Œä¼˜åŒ–åŠŸèƒ½
"""
import streamlit as st
import pandas as pd
import io
from .base_page import BasePage
from config.defaults import get_default_value, get_placeholder, get_default_lab_dataset, get_default_dataset


class ClassificationPage(BasePage):
    """åˆ†ç±»ä»»åŠ¡é¡µé¢"""
    
    def render(self):
        """æ¸²æŸ“åˆ†ç±»ä»»åŠ¡é¡µé¢"""
        col1, col2 = self.create_two_columns()
        
        with col1:
            st.subheader("ğŸ·ï¸ åˆ†ç±»ä»»åŠ¡é…ç½®")
            
            # ä»»åŠ¡æè¿°
            task_description = st.text_area(
                "ä»»åŠ¡æè¿°",
                height=100,
                placeholder=get_placeholder("classification", "task_description"),
                help="æ¸…æ™°æè¿°è¿™æ˜¯ä¸€ä¸ªä»€ä¹ˆæ ·çš„åˆ†ç±»ä»»åŠ¡ã€‚",
                key="cls_task_desc"
            )
            
            # æ ‡ç­¾è¾“å…¥
            labels_input = st.text_input(
                "ç›®æ ‡æ ‡ç­¾ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰",
                placeholder=get_placeholder("classification", "labels"),
                help="è¾“å…¥æ‰€æœ‰å¯èƒ½çš„åˆ†ç±»æ ‡ç­¾ï¼Œç”¨é€—å·åˆ†éš”ï¼ˆä¸­æ–‡é€—å·ã€è‹±æ–‡é€—å·å‡å¯ï¼‰ã€‚",
                key="cls_labels"
            )
            
            # æ„å»ºåˆ†ç±»å™¨æŒ‰é’®
            build_btn = st.button("ğŸ”¨ æ„å»ºåˆ†ç±»å™¨ Prompt", type="primary", use_container_width=True)
        
        # åˆ†ç±»ä»»åŠ¡ä¼˜åŒ–é€»è¾‘
        if build_btn:
            if not self._validate_api_key():
                return
            
            # å¦‚æœç”¨æˆ·æ²¡æœ‰è¾“å…¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
            if not task_description or task_description.strip() == "":
                task_description = get_default_value("classification", "task_description")
                st.info("ğŸ’¡ æœªè¾“å…¥ä»»åŠ¡æè¿°ï¼Œä½¿ç”¨é»˜è®¤ç¤ºä¾‹")
            
            if not labels_input or labels_input.strip() == "":
                labels_input = get_default_value("classification", "labels")
                st.info("ğŸ’¡ æœªè¾“å…¥æ ‡ç­¾ï¼Œä½¿ç”¨é»˜è®¤æ ‡ç­¾ï¼š" + labels_input)
            
            # è§£ææ ‡ç­¾ï¼ˆæ”¯æŒä¸­æ–‡é€—å·å’Œè‹±æ–‡é€—å·ï¼‰
            labels_input_normalized = labels_input.replace("ï¼Œ", ",")
            labels_list = [label.strip() for label in labels_input_normalized.split(",") if label.strip()]
            
            # ä¿å­˜ç”¨æˆ·è¾“å…¥çš„æ ‡ç­¾åˆ° session_stateï¼Œä¾›éšæœºæœç´¢ä½¿ç”¨
            st.session_state.user_labels = labels_list
            st.session_state.user_task_description = task_description
            
            if len(labels_list) < 2:
                st.error("âŒ è‡³å°‘éœ€è¦ 2 ä¸ªæ ‡ç­¾")
            else:
                with st.spinner("ğŸ”® æ­£åœ¨æ„å»ºåˆ†ç±»å™¨..."):
                    try:
                        # æ‰§è¡Œåˆ†ç±»ä»»åŠ¡ä¼˜åŒ–
                        result = self.optimizer.optimize_classification(
                            task_description=task_description,
                            labels=labels_list
                        )
                        
                        # ä¿å­˜ç»“æœ
                        st.session_state.classification_result = result
                        
                        st.success("âœ… åˆ†ç±»å™¨ Prompt æ„å»ºå®Œæˆï¼")
                        
                    except Exception as e:
                        self._handle_optimization_error(e)
        
        # æ˜¾ç¤ºåˆ†ç±»ä»»åŠ¡ä¼˜åŒ–ç»“æœ
        if 'classification_result' in st.session_state and st.session_state.classification_result:
            result = st.session_state.classification_result
            
            with col2:
                st.subheader("ğŸ¯ åˆ†ç±»å™¨ Prompt")
                
                # 1. ä¼˜åŒ–æ€è·¯
                with st.expander("ğŸ§  æŸ¥çœ‹ä¼˜åŒ–æ€è·¯", expanded=True):
                    st.write(result.thinking_process)
                
                # 2. è§’è‰²å®šä¹‰
                with st.expander("ğŸ‘¤ è§’è‰²è®¾å®š", expanded=False):
                    st.info(result.role_definition)
                
                # 3. æœ€ç»ˆ Prompt
                st.markdown("**âœ¨ æœ€ç»ˆå®Œæ•´çš„åˆ†ç±» Promptï¼ˆå¯ç›´æ¥å¤åˆ¶ï¼‰ï¼š**")
                st.text_area(
                    "åˆ†ç±»å™¨ Prompt",
                    value=result.final_prompt,
                    height=400,
                    label_visibility="collapsed"
                )
                
                # ç›´æ¥æ˜¾ç¤ºä»£ç æ¡†ï¼Œå¸¦æœ‰å¤åˆ¶æŒ‰é’®
                st.code(result.final_prompt, language=None)
                st.caption("ğŸ“Œ ç‚¹å‡»ä»£ç æ¡†å³ä¸Šè§’çš„å¤åˆ¶æŒ‰é’®å³å¯å¤åˆ¶")
        
        # éªŒè¯å®éªŒå®¤åŒºåŸŸ
        if 'classification_result' in st.session_state and st.session_state.classification_result:
            self._render_validation_lab(st.session_state.classification_result)

        self._render_optimization_lab()

    def _render_optimization_lab(self):
        """æ¸²æŸ“åˆ†ç±»ä»»åŠ¡ä¼˜åŒ–å®éªŒå®¤ï¼ˆéšæœºæœç´¢/é—ä¼ ç®—æ³•ï¼‰"""
        st.divider()
        st.subheader("ğŸ§¬ æç¤ºè¯ä¼˜åŒ–ï¼ˆéšæœºæœç´¢ / è´å¶æ–¯ä¼˜åŒ– / é—ä¼ ç®—æ³•ï¼‰")
        st.markdown("*é€šè¿‡æœç´¢/è¿›åŒ–é‡‡æ ·è§’è‰²/é£æ ¼/æŠ€å·§ç»„åˆï¼Œåœ¨å°å‹æµ‹è¯•é›†ä¸Šå¯»æ‰¾æ›´ä¼˜ Prompt ç»“æ„*" )

        optimization_algorithm = st.radio(
            "é€‰æ‹©ä¼˜åŒ–ç®—æ³•",
            ["éšæœºæœç´¢", "è´å¶æ–¯ä¼˜åŒ–", "é—ä¼ ç®—æ³•"],
            key="cls_opt_algorithm",
            help="éšæœºæœç´¢é€‚åˆå¿«é€Ÿä½“éªŒï¼Œé—ä¼ ç®—æ³•é€‚åˆæ›´ç³»ç»Ÿçš„ä¼˜åŒ–",
            horizontal=True
        )

        st.markdown("**ğŸ“Š ä¼˜åŒ–æ•°æ®æ¥æº**")
        data_source = st.radio(
            "é€‰æ‹©ä¼˜åŒ–ä½¿ç”¨çš„æ•°æ®æ¥æº",
            ["ä½¿ç”¨é»˜è®¤æ•°æ®", "ä¸Šä¼ CSVæ–‡ä»¶", "æ‰‹åŠ¨è¾“å…¥"],
            key="cls_opt_data_source",
            help="é€‰æ‹©ç”¨äºä¼˜åŒ–çš„æµ‹è¯•æ•°æ®æ¥æº",
            horizontal=True
        )

        if data_source == "ä¸Šä¼ CSVæ–‡ä»¶":
            self._render_opt_csv_upload()
        elif data_source == "æ‰‹åŠ¨è¾“å…¥":
            self._render_opt_manual_input()

        task_desc, task_key, dataset, extra_config = self._get_optimization_config()

        if optimization_algorithm == "éšæœºæœç´¢":
            col_a, col_b = st.columns([1, 2])
            with col_a:
                iterations = st.slider("è¿­ä»£æ¬¡æ•°", min_value=5, max_value=50, value=12, step=1, key="cls_opt_iterations")
            with col_b:
                st.caption("å»ºè®®ï¼šå¿«é€Ÿä½“éªŒ 5-10 æ¬¡ï¼›æœ‰æ•ˆä¼˜åŒ– 20-50 æ¬¡ï¼ˆæˆæœ¬æ›´é«˜ï¼‰ã€‚")

            if st.button("ğŸš€ è¿è¡Œéšæœºæœç´¢", type="primary", use_container_width=True, key="cls_opt_random_btn"):
                with st.spinner("â³ æ­£åœ¨ç”Ÿæˆæœç´¢ç©ºé—´å¹¶æ‰§è¡Œéšæœºæœç´¢..."):
                    try:
                        search_space = self.optimizer.search_space_generator.generate(
                            task_description=task_desc,
                            task_type=task_key,
                            **extra_config
                        )

                        st.success("âœ… æœç´¢ç©ºé—´ç”Ÿæˆå®Œæˆï¼")
                        st.info("ğŸ’¡ ç³»ç»Ÿå°†ä»è¿™äº›é€‰é¡¹ä¸­éšæœºç»„åˆè¿›è¡Œæµ‹è¯•ï¼Œæ¯ä¸ªç»„åˆåŒ…å«ï¼š1ä¸ªè§’è‰² + 1ç§é£æ ¼ + 1ç§æŠ€å·§")
                        self._render_search_space_preview(search_space)

                        results, best = self.optimizer.random_search.run(
                            task_description=task_desc,
                            task_type=task_key,
                            test_dataset=dataset,
                            search_space=search_space,
                            iterations=iterations,
                            labels=extra_config.get("labels")
                        )

                        st.session_state.cls_opt_random_results = results
                        st.session_state.cls_opt_random_best = best
                        st.session_state.cls_opt_random_space = search_space
                    except Exception as e:
                        st.error(f"âŒ éšæœºæœç´¢å¤±è´¥ï¼š{str(e)}")

            if 'cls_opt_random_best' in st.session_state and st.session_state.cls_opt_random_best:
                best = st.session_state.cls_opt_random_best
                search_space = st.session_state.get('cls_opt_random_space')
                results = st.session_state.get('cls_opt_random_results', [])
                # æ–°å¢ï¼šéšæœºæœç´¢å¾—åˆ†æ›²çº¿
                if results:
                    st.divider()
                    st.markdown("### ğŸ“ˆ éšæœºæœç´¢å¾—åˆ†æ›²çº¿")
                    df = pd.DataFrame({
                        "è¿­ä»£": [r.iteration_id for r in results],
                        "å¾—åˆ†": [r.avg_score for r in results]
                    })
                    st.line_chart(df.set_index("è¿­ä»£"))
                self._render_optimization_result(best, search_space)
        elif optimization_algorithm == "é—ä¼ ç®—æ³•":
            col_a, col_b, col_c, col_d = st.columns(4)
            with col_a:
                generations = st.slider("è¿›åŒ–ä»£æ•°", min_value=3, max_value=20, value=6, step=1, key="cls_opt_generations")
            with col_b:
                population_size = st.slider("ç§ç¾¤è§„æ¨¡", min_value=4, max_value=24, value=8, step=1, key="cls_opt_population")
            with col_c:
                elite_ratio = st.slider("ç²¾è‹±æ¯”ä¾‹", min_value=0.1, max_value=0.5, value=0.2, step=0.05, key="cls_opt_elite")
            with col_d:
                mutation_rate = st.slider("å˜å¼‚ç‡", min_value=0.05, max_value=0.6, value=0.2, step=0.05, key="cls_opt_mutation")

            if st.button("ğŸ§¬ è¿è¡Œé—ä¼ ç®—æ³•", type="primary", use_container_width=True, key="cls_opt_ga_btn"):
                with st.spinner("â³ æ­£åœ¨ç”Ÿæˆæœç´¢ç©ºé—´å¹¶æ‰§è¡Œé—ä¼ ç®—æ³•..."):
                    try:
                        search_space = self.optimizer.search_space_generator.generate(
                            task_description=task_desc,
                            task_type=task_key,
                            **extra_config
                        )

                        st.success("âœ… æœç´¢ç©ºé—´ç”Ÿæˆå®Œæˆï¼")
                        st.info("ğŸ’¡ ç³»ç»Ÿå°†ä»è¿™äº›é€‰é¡¹ä¸­è¿›åŒ–ç»„åˆè¿›è¡Œæµ‹è¯•ï¼Œæ¯ä¸ªç»„åˆåŒ…å«ï¼š1ä¸ªè§’è‰² + 1ç§é£æ ¼ + 1ç§æŠ€å·§")
                        self._render_search_space_preview(search_space)

                        progress = st.progress(0)
                        progress_text = st.empty()

                        def _progress_callback(current_gen, total_gen, best_score, avg_score):
                            if total_gen > 0:
                                progress_value = int(min(100, (current_gen / total_gen) * 100))
                                progress.progress(progress_value)
                            progress_text.info(
                                f"ç¬¬ {current_gen}/{total_gen} ä»£ | æœ€ä½³å¾—åˆ† {best_score:.2f} | å¹³å‡å¾—åˆ† {avg_score:.2f}"
                            )

                        results, best, evolution_history = self.optimizer.run_genetic_algorithm(
                            task_description=task_desc,
                            task_type=task_key,
                            test_dataset=dataset,
                            search_space=search_space,
                            generations=generations,
                            population_size=population_size,
                            elite_ratio=elite_ratio,
                            mutation_rate=mutation_rate,
                            progress_callback=_progress_callback
                        )

                        st.session_state.cls_opt_ga_results = results
                        st.session_state.cls_opt_ga_best = best
                        st.session_state.cls_opt_ga_history = evolution_history
                        st.session_state.cls_opt_ga_space = search_space
                    except Exception as e:
                        st.error(f"âŒ é—ä¼ ç®—æ³•å¤±è´¥ï¼š{str(e)}")

            if 'cls_opt_ga_best' in st.session_state and st.session_state.cls_opt_ga_best:
                best = st.session_state.cls_opt_ga_best
                search_space = st.session_state.get('cls_opt_ga_space')
                evolution_history = st.session_state.get('cls_opt_ga_history', [])
                self._render_optimization_result(best, search_space, evolution_history)
        else:
            col_a, col_b = st.columns([1, 2])
            with col_a:
                n_trials = st.slider("è¯•éªŒæ¬¡æ•°", min_value=5, max_value=50, value=12, step=1, key="cls_opt_bo_trials")
            with col_b:
                st.caption("å»ºè®®ï¼šå¿«é€Ÿä½“éªŒ 8-12 æ¬¡ï¼›ç¨³å®šä¼˜åŒ– 15-30 æ¬¡ï¼ˆæˆæœ¬æ›´é«˜ï¼‰ã€‚")

            if st.button("ğŸ§ª è¿è¡Œè´å¶æ–¯ä¼˜åŒ–", type="primary", use_container_width=True, key="cls_opt_bo_btn"):
                with st.spinner("â³ æ­£åœ¨ç”Ÿæˆæœç´¢ç©ºé—´å¹¶æ‰§è¡Œè´å¶æ–¯ä¼˜åŒ–..."):
                    try:
                        search_space = self.optimizer.search_space_generator.generate(
                            task_description=task_desc,
                            task_type=task_key,
                            **extra_config
                        )

                        st.success("âœ… æœç´¢ç©ºé—´ç”Ÿæˆå®Œæˆï¼")
                        st.info("ğŸ’¡ ç³»ç»Ÿå°†ä½¿ç”¨ TPE æ™ºèƒ½é€‰æ‹©ç»„åˆè¿›è¡Œæµ‹è¯•ï¼Œæ¯ä¸ªç»„åˆåŒ…å«ï¼š1ä¸ªè§’è‰² + 1ç§é£æ ¼ + 1ç§æŠ€å·§")
                        self._render_search_space_preview(search_space)

                        progress = st.progress(0)
                        progress_text = st.empty()

                        def _progress_callback(current_trial, total_trials, best_score):
                            if total_trials > 0:
                                progress_value = int(min(100, (current_trial / total_trials) * 100))
                                progress.progress(progress_value)
                            progress_text.info(
                                f"è¯•éªŒ {current_trial}/{total_trials} | å½“å‰æœ€ä½³ {best_score:.2f}"
                            )

                        results, best, trial_history = self.optimizer.run_bayesian_optimization(
                            task_description=task_desc,
                            task_type=task_key,
                            test_dataset=dataset,
                            search_space=search_space,
                            n_trials=n_trials,
                            progress_callback=_progress_callback
                        )

                        st.session_state.cls_opt_bo_results = results
                        st.session_state.cls_opt_bo_best = best
                        st.session_state.cls_opt_bo_history = trial_history
                        st.session_state.cls_opt_bo_space = search_space
                    except Exception as e:
                        st.error(f"âŒ è´å¶æ–¯ä¼˜åŒ–å¤±è´¥ï¼š{str(e)}")

            if 'cls_opt_bo_best' in st.session_state and st.session_state.cls_opt_bo_best:
                best = st.session_state.cls_opt_bo_best
                search_space = st.session_state.get('cls_opt_bo_space')
                trial_history = st.session_state.get('cls_opt_bo_history', [])
                if trial_history:
                    st.divider()
                    st.markdown("### ğŸ“ˆ è´å¶æ–¯ä¼˜åŒ–å¾—åˆ†æ›²çº¿")
                    df = pd.DataFrame({
                        "è¯•éªŒ": [h["trial"] for h in trial_history],
                        "å¾—åˆ†": [h["score"] for h in trial_history],
                        "å†å²æœ€ä½³": [h["best_score"] for h in trial_history]
                    })
                    st.line_chart(df.set_index("è¯•éªŒ"))
                self._render_optimization_result(best, search_space)

    def _render_search_space_preview(self, search_space):
        with st.expander("ğŸ” æŸ¥çœ‹ç”Ÿæˆçš„æœç´¢ç©ºé—´", expanded=True):
            col1, col2, col3 = st.columns(3)
            with col1:
                st.markdown("**ğŸ­ è§’è‰²è®¾å®š (5ä¸ª)**")
                for i, role in enumerate(search_space.roles, 1):
                    st.markdown(f"{i}. {role}")
            with col2:
                st.markdown("**ğŸ¨ å›ç­”é£æ ¼ (5ç§)**")
                for i, style in enumerate(search_space.styles, 1):
                    st.markdown(f"{i}. {style}")
            with col3:
                st.markdown("**ğŸ› ï¸ æç¤ºæŠ€å·§ (3ç§)**")
                for i, technique in enumerate(search_space.techniques, 1):
                    st.markdown(f"{i}. {technique}")

    def _render_optimization_result(self, best, search_space, evolution_history=None):
        st.success(f"âœ… æœ€ä½³å¾—åˆ†ï¼š{best.avg_score:.2f}")
        st.markdown(f"**æœ€ä½³ç»„åˆï¼š** {best.role} + {best.style} + {best.technique}")
        st.text_area("æœ€ä½³ Prompt", value=best.full_prompt, height=200)

        if evolution_history:
            st.divider()
            st.markdown("### ğŸ“ˆ è¿›åŒ–è¿‡ç¨‹")
            history_df = pd.DataFrame(evolution_history)
            history_df = history_df.rename(columns={
                "generation": "ä»£æ•°",
                "best_score": "æœ€ä½³å¾—åˆ†",
                "avg_score": "å¹³å‡å¾—åˆ†"
            })
            st.line_chart(history_df.set_index("ä»£æ•°")[["æœ€ä½³å¾—åˆ†", "å¹³å‡å¾—åˆ†"]])

        if search_space:
            st.divider()
            st.markdown("### ğŸ” æœç´¢ç©ºé—´è¯¦æƒ…")
            with st.expander("æŸ¥çœ‹å®Œæ•´çš„æœç´¢ç©ºé—´", expanded=False):
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.markdown("**ğŸ­ è§’è‰²è®¾å®š (5ä¸ª)**")
                    for i, role in enumerate(search_space.roles, 1):
                        if role == best.role:
                            st.markdown(f"**{i}. {role} â† æœ€ä½³é€‰æ‹©**")
                        else:
                            st.markdown(f"{i}. {role}")
                with col2:
                    st.markdown("**ğŸ¨ å›ç­”é£æ ¼ (5ç§)**")
                    for i, style in enumerate(search_space.styles, 1):
                        if style == best.style:
                            st.markdown(f"**{i}. {style} â† æœ€ä½³é€‰æ‹©**")
                        else:
                            st.markdown(f"{i}. {style}")
                with col3:
                    st.markdown("**ğŸ› ï¸ æç¤ºæŠ€å·§ (3ç§)**")
                    for i, technique in enumerate(search_space.techniques, 1):
                        if technique == best.technique:
                            st.markdown(f"**{i}. {technique} â† æœ€ä½³é€‰æ‹©**")
                        else:
                            st.markdown(f"{i}. {technique}")

    def _render_opt_csv_upload(self):
        st.markdown("**ğŸ“ CSVæ–‡ä»¶ä¸Šä¼ **")
        st.info("CSVæ–‡ä»¶åº”åŒ…å«ä¸¤åˆ—ï¼š'text'ï¼ˆæ–‡æœ¬ï¼‰å’Œ 'expected'ï¼ˆé¢„æœŸæ ‡ç­¾ï¼‰")
        uploaded_file = st.file_uploader(
            "é€‰æ‹©CSVæ–‡ä»¶",
            type=["csv"],
            key="cls_opt_csv_upload",
            help="ä¸Šä¼ åŒ…å«æµ‹è¯•æ•°æ®çš„CSVæ–‡ä»¶"
        )
        if uploaded_file is not None:
            try:
                df = pd.read_csv(uploaded_file)
                required_columns = ["text", "expected"]
                if not all(col in df.columns for col in required_columns):
                    st.error(f"âŒ CSVæ–‡ä»¶å¿…é¡»åŒ…å«ä»¥ä¸‹åˆ—ï¼š{', '.join(required_columns)}")
                    return
                st.success(f"âœ… æˆåŠŸåŠ è½½ {len(df)} æ¡æµ‹è¯•æ•°æ®")
                st.markdown("**æ•°æ®é¢„è§ˆï¼š**")
                st.dataframe(df.head(), use_container_width=True)
                st.session_state.cls_opt_custom_data = df.to_dict('records')
            except Exception as e:
                st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}")

    def _render_opt_manual_input(self):
        st.markdown("**âœï¸ æ‰‹åŠ¨è¾“å…¥æµ‹è¯•æ•°æ®**")
        manual_data = st.session_state.get('cls_opt_manual_data', [
            {"text": "", "expected": ""},
            {"text": "", "expected": ""},
            {"text": "", "expected": ""}
        ])

        updated_data = []
        for i, item in enumerate(manual_data):
            col1, col2, col3 = st.columns([4, 2, 1])
            with col1:
                text = st.text_input(
                    f"æ–‡æœ¬ {i+1}",
                    value=item["text"],
                    key=f"cls_opt_manual_text_{i}",
                    placeholder="è¾“å…¥æµ‹è¯•æ–‡æœ¬"
                )
            with col2:
                expected = st.text_input(
                    f"æ ‡ç­¾ {i+1}",
                    value=item["expected"],
                    key=f"cls_opt_manual_expected_{i}",
                    placeholder="é¢„æœŸæ ‡ç­¾"
                )
            with col3:
                if st.button("ğŸ—‘ï¸", key=f"cls_opt_manual_delete_{i}", help=f"åˆ é™¤ç¬¬{i+1}è¡Œ"):
                    continue

            if text.strip() or expected.strip():
                updated_data.append({"text": text, "expected": expected})

        if st.button("â• æ·»åŠ ä¸€è¡Œ", key="cls_opt_manual_add_row"):
            updated_data.append({"text": "", "expected": ""})

        st.session_state.cls_opt_manual_data = updated_data
        valid_count = sum(1 for item in updated_data if item["text"].strip() and item["expected"].strip())
        st.info(f"å½“å‰æœ‰ {valid_count} æ¡æœ‰æ•ˆæµ‹è¯•æ•°æ®ç”¨äºä¼˜åŒ–")

    def _get_opt_test_dataset(self):
        data_source = st.session_state.get('cls_opt_data_source', 'ä½¿ç”¨é»˜è®¤æ•°æ®')

        if data_source == "ä½¿ç”¨é»˜è®¤æ•°æ®":
            return get_default_dataset("classification")

        if data_source == "ä¸Šä¼ CSVæ–‡ä»¶":
            if st.session_state.get('cls_opt_custom_data'):
                return [
                    {"input": item["text"], "ground_truth": item["expected"]}
                    for item in st.session_state.cls_opt_custom_data
                    if item.get("text", "").strip() and item.get("expected", "").strip()
                ] or get_default_dataset("classification")
            return get_default_dataset("classification")

        if data_source == "æ‰‹åŠ¨è¾“å…¥":
            manual_data = [
                item for item in st.session_state.get('cls_opt_manual_data', [])
                if item.get("text", "").strip() and item.get("expected", "").strip()
            ]
            if manual_data:
                return [
                    {"input": item["text"], "ground_truth": item["expected"]}
                    for item in manual_data
                ]
            return get_default_dataset("classification")

        return get_default_dataset("classification")

    def _get_optimization_config(self):
        user_labels = st.session_state.get('user_labels', get_default_value("classification", "labels"))
        if isinstance(user_labels, str):
            labels_input_normalized = user_labels.replace("ï¼Œ", ",")
            user_labels = [label.strip() for label in labels_input_normalized.split(",") if label.strip()]

        user_task_desc = st.session_state.get('user_task_description', get_default_value("classification", "task_description"))
        labels_str = ", ".join(user_labels)
        task_desc = f"{user_task_desc}ï¼Œåˆ¤æ–­ä¸º{labels_str}"

        test_dataset = self._get_opt_test_dataset()

        return task_desc, "classification", test_dataset, {"labels": user_labels}
    
    def _render_validation_lab(self, result):
        """æ¸²æŸ“åˆ†ç±»éªŒè¯å®éªŒå®¤"""
        st.divider()
        st.subheader("ğŸ”¬ æ•ˆæœéªŒè¯å®éªŒå®¤")
        st.markdown("*ä½¿ç”¨æµ‹è¯•æ ·æœ¬éªŒè¯åˆ†ç±»å™¨çš„å‡†ç¡®æ€§*")

        # æµ‹è¯•æ•°æ®æ¥æºé€‰æ‹©
        st.markdown("**ğŸ“Š æµ‹è¯•æ•°æ®æ¥æº**")
        data_source = st.radio(
            "é€‰æ‹©æ•°æ®æ¥æº",
            ["ä½¿ç”¨é»˜è®¤æ•°æ®", "ä¸Šä¼ CSVæ–‡ä»¶", "æ‰‹åŠ¨è¾“å…¥"],
            key="cls_data_source",
            help="é€‰æ‹©æµ‹è¯•æ•°æ®çš„æ¥æºæ–¹å¼",
            horizontal=True
        )

        # æ ¹æ®é€‰æ‹©æ˜¾ç¤ºç›¸åº”çš„è¾“å…¥ç•Œé¢
        if data_source == "ä¸Šä¼ CSVæ–‡ä»¶":
            self._render_csv_upload()
        elif data_source == "æ‰‹åŠ¨è¾“å…¥":
            self._render_manual_input()

        # è·å–æµ‹è¯•æ•°æ®ï¼ˆä¼˜å…ˆä½¿ç”¨è‡ªå®šä¹‰æ•°æ®ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤æ•°æ®ï¼‰
        test_cases = self._get_test_cases()
        
        col_test1, col_test2 = st.columns([1, 1])
        
        with col_test1:
            st.markdown("**ğŸ“ æµ‹è¯•æ ·æœ¬**")
            st.caption("ä¿®æ”¹ä¸‹æ–¹çš„æµ‹è¯•æ–‡æœ¬å’Œé¢„æœŸæ ‡ç­¾ï¼š")
            
            # æ˜¾ç¤ºæµ‹è¯•æ ·æœ¬
            for i, case in enumerate(test_cases):
                with st.container():
                    st.markdown(f"**æµ‹è¯• {i+1}:**")
                    text = st.text_input(f"æ–‡æœ¬ {i+1}", value=case["text"], key=f"cls_test_text_{i}")
                    expected = st.text_input(f"é¢„æœŸæ ‡ç­¾ {i+1}", value=case["expected"], key=f"cls_test_expected_{i}")
                    test_cases[i] = {"text": text, "expected": expected}
        
        with col_test2:
            st.markdown("**ğŸ¯ è¯„åˆ†æ ‡å‡†**")
            st.info("""
**Accuracyï¼ˆå‡†ç¡®ç‡ï¼‰**
- ğŸŸ¢ **ä¼˜ç§€** â‰¥ 80%
- ğŸŸ¡ **è‰¯å¥½** 60% - 80%
- ğŸ”´ **éœ€æ”¹è¿›** < 60%

**è®¡ç®—æ–¹å¼**ï¼šæ­£ç¡®é¢„æµ‹æ•° / æ€»æ ·æœ¬æ•° Ã— 100%
            """)
        
        # è¿è¡ŒéªŒè¯æŒ‰é’®
        if st.button("ğŸš€ è¿è¡ŒéªŒè¯æµ‹è¯•", type="primary", use_container_width=True, key="cls_validation_btn"):
            with st.spinner("â³ æ­£åœ¨ä½¿ç”¨ä¼˜åŒ–åçš„ Prompt è¿›è¡Œåˆ†ç±»..."):
                try:
                    results = []
                    for i, case in enumerate(test_cases):
                        # æ›¿æ¢å ä½ç¬¦
                        prompt_with_text = result.final_prompt.replace("[å¾…åˆ†ç±»æ–‡æœ¬]", case["text"])
                        prompt_with_text = prompt_with_text.replace("{{text}}", case["text"])
                        prompt_with_text = prompt_with_text.replace("{text}", case["text"])
                        
                        # è°ƒç”¨ LLM
                        response = self.optimizer.llm.invoke(prompt_with_text)
                        predicted = response.content.strip()
                        
                        results.append({
                            "text": case["text"],
                            "expected": case["expected"],
                            "predicted": predicted,
                            "correct": predicted == case["expected"]
                        })
                    
                    # ä¿å­˜ç»“æœ
                    st.session_state.cls_validation_results = results
                    
                    # è®¡ç®—å‡†ç¡®ç‡
                    accuracy = sum(1 for r in results if r["correct"]) / len(results) * 100
                    st.session_state.cls_accuracy = accuracy
                    
                except Exception as e:
                    st.error(f"âŒ éªŒè¯å¤±è´¥ï¼š{str(e)}")
        
        # æ˜¾ç¤ºéªŒè¯ç»“æœ
        if 'cls_validation_results' in st.session_state and st.session_state.cls_validation_results:
            results = st.session_state.cls_validation_results
            accuracy = st.session_state.cls_accuracy
            
            st.divider()
            st.markdown("### ğŸ“Š éªŒè¯ç»“æœ")
            
            # æ˜¾ç¤ºå‡†ç¡®ç‡
            if accuracy >= 80:
                st.success(f"ğŸ‰ å‡†ç¡®ç‡ï¼š{accuracy:.1f}% - ğŸŸ¢ ä¼˜ç§€ï¼")
            elif accuracy >= 60:
                st.info(f"ğŸ‘ å‡†ç¡®ç‡ï¼š{accuracy:.1f}% - ğŸŸ¡ è‰¯å¥½")
            else:
                st.warning(f"âš ï¸ å‡†ç¡®ç‡ï¼š{accuracy:.1f}% - ğŸ”´ éœ€æ”¹è¿›")
            
            # è¯¦ç»†ç»“æœè¡¨æ ¼
            st.markdown("**è¯¦ç»†ç»“æœï¼š**")
            for i, r in enumerate(results, 1):
                col1, col2, col3, col4 = st.columns([3, 1, 1, 1])
                with col1:
                    st.text(f"{r['text'][:40]}...")
                with col2:
                    st.text(f"é¢„æœŸ: {r['expected']}")
                with col3:
                    st.text(f"é¢„æµ‹: {r['predicted']}")
                with col4:
                    if r['correct']:
                        st.success("âœ…")
                    else:
                        st.error("âŒ")
    
    def _validate_api_key(self):
        """éªŒè¯ API Key"""
        api_key = st.session_state.get('api_key_input', '')
        if not api_key or api_key.strip() == "":
            st.error("âŒ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® API Key")
            return False
        return True
    
    def _handle_optimization_error(self, e):
        """å¤„ç†ä¼˜åŒ–é”™è¯¯"""
        error_msg = str(e)
        st.error(f"âŒ æ„å»ºå¤±è´¥ï¼š{error_msg}")
        
        api_provider = st.session_state.get('api_provider', 'NVIDIA')
        
        # æä¾›è§£å†³æ–¹æ¡ˆ
        if "404" in error_msg or "401" in error_msg:
            st.warning("""**å¯èƒ½çš„åŸå› å’Œè§£å†³æ–¹æ¡ˆï¼š**""")
            if api_provider == "NVIDIA":
                st.markdown("""
                1. **API Key æ— æ•ˆæˆ–æœªé…ç½®**
                   - è¯·è®¿é—® [NVIDIA Build](https://build.nvidia.com/) è·å– API Key
                2. **æ¨¡å‹ä¸æ”¯æŒ**
                   - æ¨èä½¿ç”¨ meta/llama-3.1-405b-instruct
                """)
        
        st.info("ğŸ”§ å»ºè®®ï¼šè¿è¡Œ `python test_nvidia.py` æµ‹è¯• API è¿æ¥")
    
    def _render_csv_upload(self):
        """æ¸²æŸ“CSVæ–‡ä»¶ä¸Šä¼ ç•Œé¢"""
        st.markdown("**ğŸ“ CSVæ–‡ä»¶ä¸Šä¼ **")
        st.info("CSVæ–‡ä»¶åº”åŒ…å«ä¸¤åˆ—ï¼š'text'ï¼ˆæ–‡æœ¬ï¼‰å’Œ 'expected'ï¼ˆé¢„æœŸæ ‡ç­¾ï¼‰")
        
        uploaded_file = st.file_uploader(
            "é€‰æ‹©CSVæ–‡ä»¶",
            type=["csv"],
            key="cls_csv_upload",
            help="ä¸Šä¼ åŒ…å«æµ‹è¯•æ•°æ®çš„CSVæ–‡ä»¶"
        )
        
        if uploaded_file is not None:
            try:
                # è¯»å–CSVæ–‡ä»¶
                df = pd.read_csv(uploaded_file)
                
                # éªŒè¯åˆ—å
                required_columns = ["text", "expected"]
                if not all(col in df.columns for col in required_columns):
                    st.error(f"âŒ CSVæ–‡ä»¶å¿…é¡»åŒ…å«ä»¥ä¸‹åˆ—ï¼š{', '.join(required_columns)}")
                    return
                
                # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
                st.success(f"âœ… æˆåŠŸåŠ è½½ {len(df)} æ¡æµ‹è¯•æ•°æ®")
                st.markdown("**æ•°æ®é¢„è§ˆï¼š**")
                st.dataframe(df.head(), use_container_width=True)
                
                # ä¿å­˜åˆ°session_state
                st.session_state.custom_test_data = df.to_dict('records')
                
            except Exception as e:
                st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}")
    
    def _render_manual_input(self):
        """æ¸²æŸ“æ‰‹åŠ¨è¾“å…¥ç•Œé¢"""
        st.markdown("**âœï¸ æ‰‹åŠ¨è¾“å…¥æµ‹è¯•æ•°æ®**")
        
        # è·å–å½“å‰çš„æ‰‹åŠ¨è¾“å…¥æ•°æ®
        manual_data = st.session_state.get('manual_test_data', [
            {"text": "", "expected": ""},
            {"text": "", "expected": ""},
            {"text": "", "expected": ""}
        ])
        
        st.markdown("æ·»åŠ æµ‹è¯•æ ·æœ¬ï¼š")
        
        # æ˜¾ç¤ºç°æœ‰çš„è¾“å…¥æ¡†
        updated_data = []
        for i, item in enumerate(manual_data):
            col1, col2, col3 = st.columns([4, 2, 1])
            with col1:
                text = st.text_input(
                    f"æ–‡æœ¬ {i+1}",
                    value=item["text"],
                    key=f"manual_text_{i}",
                    placeholder="è¾“å…¥æµ‹è¯•æ–‡æœ¬"
                )
            with col2:
                expected = st.text_input(
                    f"æ ‡ç­¾ {i+1}",
                    value=item["expected"],
                    key=f"manual_expected_{i}",
                    placeholder="é¢„æœŸæ ‡ç­¾"
                )
            with col3:
                if st.button("ğŸ—‘ï¸", key=f"delete_{i}", help=f"åˆ é™¤ç¬¬{i+1}è¡Œ"):
                    continue  # è·³è¿‡è¿™è¡Œï¼Œä¸æ·»åŠ åˆ°updated_dataä¸­
            
            if text.strip() or expected.strip():  # åªä¿å­˜éç©ºè¡Œ
                updated_data.append({"text": text, "expected": expected})
        
        # æ·»åŠ æ–°è¡Œçš„æŒ‰é’®
        if st.button("â• æ·»åŠ ä¸€è¡Œ", key="add_manual_row"):
            updated_data.append({"text": "", "expected": ""})
        
        # ä¿å­˜åˆ°session_state
        st.session_state.manual_test_data = updated_data
        
        # æ˜¾ç¤ºæœ‰æ•ˆæ•°æ®æ•°é‡
        valid_count = sum(1 for item in updated_data if item["text"].strip() and item["expected"].strip())
        st.info(f"å½“å‰æœ‰ {valid_count} æ¡æœ‰æ•ˆæµ‹è¯•æ•°æ®")
    
    def _get_test_cases(self):
        """è·å–æµ‹è¯•æ•°æ®ï¼Œæ ¹æ®ç”¨æˆ·é€‰æ‹©è¿”å›ç›¸åº”æ•°æ®"""
        data_source = st.session_state.get('cls_data_source', 'ä½¿ç”¨é»˜è®¤æ•°æ®')

        if data_source == "ä½¿ç”¨é»˜è®¤æ•°æ®":
            # æ¸…é™¤è‡ªå®šä¹‰æ•°æ®
            if 'custom_test_data' in st.session_state:
                del st.session_state.custom_test_data
            if 'manual_test_data' in st.session_state:
                del st.session_state.manual_test_data
            return get_default_lab_dataset("classification")

        elif data_source == "ä¸Šä¼ CSVæ–‡ä»¶":
            # è¿”å›CSVæ•°æ®ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›é»˜è®¤æ•°æ®
            if 'custom_test_data' in st.session_state and st.session_state.custom_test_data:
                return st.session_state.custom_test_data
            else:
                return get_default_lab_dataset("classification")

        elif data_source == "æ‰‹åŠ¨è¾“å…¥":
            # è¿”å›æ‰‹åŠ¨è¾“å…¥æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›é»˜è®¤æ•°æ®
            if 'manual_test_data' in st.session_state:
                manual_data = [item for item in st.session_state.manual_test_data
                              if item["text"].strip() and item["expected"].strip()]
                if manual_data:
                    return manual_data
            return get_default_lab_dataset("classification")

        # é»˜è®¤æƒ…å†µ
        return get_default_lab_dataset("classification")
