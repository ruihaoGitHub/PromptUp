"""
ç¿»è¯‘ä»»åŠ¡é¡µé¢æ¨¡å—
æä¾›ç¿»è¯‘å™¨ Prompt ç”Ÿæˆå’Œä¼˜åŒ–åŠŸèƒ½
"""
import streamlit as st
import re
from .base_page import BasePage


class TranslationPage(BasePage):
    """ç¿»è¯‘ä»»åŠ¡é¡µé¢"""
    
    def render(self):
        """æ¸²æŸ“ç¿»è¯‘ä»»åŠ¡é¡µé¢"""
        col1, col2 = self.create_two_columns()
        
        with col1:
            st.subheader("ğŸŒ ç¿»è¯‘ä»»åŠ¡é…ç½®")
            st.info("ğŸ“Œ é«˜è´¨é‡ç¿»è¯‘éœ€è¦ï¼šå‡†ç¡®çš„æœ¯è¯­ + ç¬¦åˆæ–‡åŒ–çš„è¡¨è¾¾ã€‚ç³»ç»Ÿå°†ä¸ºæ‚¨æ„å»º'ä¿¡è¾¾é›…'çš„ç¿»è¯‘æŒ‡ä»¤ã€‚")
            
            # è¯­è¨€æ–¹å‘é…ç½®
            st.markdown("**ğŸ”„ ç¿»è¯‘æ–¹å‘**")
            lang_col1, lang_col2 = st.columns(2)
            with lang_col1:
                source_lang = st.selectbox(
                    "æºè¯­è¨€",
                    ["ä¸­æ–‡", "è‹±æ–‡", "æ—¥æ–‡", "æ³•æ–‡", "å¾·æ–‡", "è¥¿ç­ç‰™æ–‡", "éŸ©æ–‡"],
                    index=1,
                    help="è¦ç¿»è¯‘çš„åŸå§‹æ–‡æœ¬è¯­è¨€"
                )
            with lang_col2:
                target_lang = st.selectbox(
                    "ç›®æ ‡è¯­è¨€",
                    ["è‹±æ–‡", "ä¸­æ–‡", "æ—¥æ–‡", "æ³•æ–‡", "å¾·æ–‡", "è¥¿ç­ç‰™æ–‡", "éŸ©æ–‡"],
                    index=1,
                    help="ç¿»è¯‘åçš„ç›®æ ‡è¯­è¨€"
                )
            
            # é¢†åŸŸé€‰æ‹©
            st.markdown("**ğŸ“š åº”ç”¨é¢†åŸŸ**")
            domain = st.selectbox(
                "é€‰æ‹©ç¿»è¯‘é¢†åŸŸ",
                [
                    "é€šç”¨æ—¥å¸¸",
                    "IT/æŠ€æœ¯æ–‡æ¡£",
                    "æ³•å¾‹åˆåŒ",
                    "å­¦æœ¯è®ºæ–‡",
                    "å•†åŠ¡é‚®ä»¶",
                    "æ–‡å­¦/å°è¯´",
                    "åŒ»å­¦æ–‡æ¡£",
                    "æ–°é—»æŠ¥é“",
                    "è¥é”€æ–‡æ¡ˆ",
                    "æ¸¸æˆæœ¬åœ°åŒ–"
                ],
                index=2,
                help="ä¸åŒé¢†åŸŸéœ€è¦ä¸åŒçš„ä¸“ä¸šæœ¯è¯­å’Œè¡¨è¾¾é£æ ¼"
            )
            
            # é£æ ¼é€‰æ‹©
            st.markdown("**ğŸ¨ æœŸæœ›é£æ ¼**")
            tone = st.selectbox(
                "é€‰æ‹©ç¿»è¯‘é£æ ¼",
                [
                    "æ ‡å‡†/å‡†ç¡®",
                    "åœ°é“/å£è¯­åŒ–",
                    "ä¼˜ç¾/æ–‡å­¦æ€§",
                    "æç®€/æ‘˜è¦å¼",
                    "æ­£å¼/å•†åŠ¡",
                    "è½»æ¾/æ´»æ³¼"
                ],
                index=4,
                help="å†³å®šè¯‘æ–‡çš„è¡¨è¾¾æ–¹å¼å’Œè¯­è¨€é£æ ¼"
            )
            
            # æœ¯è¯­è¡¨ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰
            st.markdown("**ğŸ“– æœ¯è¯­åº“ï¼ˆGlossaryï¼‰- å¯é€‰**")
            st.caption("å¼ºåˆ¶æŒ‡å®šæŸäº›è¯çš„è¯‘æ³•ï¼Œç¡®ä¿æœ¯è¯­ä¸€è‡´æ€§ã€‚æ¯è¡Œä¸€ä¸ªï¼Œæ ¼å¼ï¼šåŸæ–‡=è¯‘æ–‡")
            glossary_input = st.text_area(
                "æœ¯è¯­æ˜ å°„",
                height=120,
                value="""Notwithstanding=å°½ç®¡æœ‰ä»»ä½•ç›¸åçº¦å®š
Force Majeure=ä¸å¯æŠ—åŠ›
Liability=è´£ä»»
Indemnify=èµ”å¿
Governing Law=é€‚ç”¨æ³•å¾‹
""",
                help="ä¸“æœ‰åè¯çš„å¼ºåˆ¶å¯¹åº”å…³ç³»ï¼Œæ¨¡å‹å°†ä¸¥æ ¼éµå®ˆ",
                key="trans_glossary"
            )
            
            # æ„å»ºç¿»è¯‘å™¨æŒ‰é’®
            build_translation_btn = st.button("ğŸ”¨ æ„å»ºç¿»è¯‘å™¨ Prompt", type="primary", use_container_width=True)
        
        # ç¿»è¯‘ä»»åŠ¡ä¼˜åŒ–é€»è¾‘
        if build_translation_btn:
            if source_lang == target_lang:
                st.error("âŒ æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€ä¸èƒ½ç›¸åŒï¼")
            elif not self._validate_api_key():
                return
            else:
                # å¤„ç†æœ¯è¯­è¡¨è¾“å…¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
                if not glossary_input or glossary_input.strip() == "":
                    # æ ¹æ®é€‰æ‹©çš„é¢†åŸŸæä¾›é»˜è®¤æœ¯è¯­
                    if domain == "IT/æŠ€æœ¯æ–‡æ¡£":
                        glossary_input = """Prompt Engineering=æç¤ºè¯å·¥ç¨‹
LLM=å¤§è¯­è¨€æ¨¡å‹
Token=ä»¤ç‰Œ
Fine-tuning=å¾®è°ƒ
API=åº”ç”¨ç¨‹åºæ¥å£
Machine Learning=æœºå™¨å­¦ä¹ """
                    elif domain == "æ–‡å­¦/å°è¯´":
                        glossary_input = """ä¿®ç‚¼=Cultivation
ç­‘åŸº=Foundation Establishment
é‡‘ä¸¹=Golden Core
å…ƒå©´=Nascent Soul"""
                    else:
                        glossary_input = ""  # å…¶ä»–é¢†åŸŸä½¿ç”¨ç©ºæœ¯è¯­è¡¨
                    
                    if glossary_input:
                        st.info(f"ğŸ’¡ æœªè¾“å…¥æœ¯è¯­åº“ï¼Œä½¿ç”¨ {domain} é¢†åŸŸçš„é»˜è®¤ç¤ºä¾‹")
                
                with st.spinner("ğŸ”® æ­£åœ¨è®¾è®¡é¢†åŸŸä¸“å®¶è§’è‰²ã€æ¤å…¥æœ¯è¯­åº“ã€æ„å»ºä¸‰æ­¥ç¿»è¯‘æ³•..."):
                    try:
                        # æ‰§è¡Œç¿»è¯‘ä»»åŠ¡ä¼˜åŒ–
                        result = self.optimizer.optimize_translation(
                            source_lang=source_lang,
                            target_lang=target_lang,
                            domain=domain,
                            tone=tone,
                            user_glossary=glossary_input
                        )
                        
                        # ä¿å­˜ç»“æœ
                        st.session_state.translation_result = result
                        # ä¿å­˜è¯­è¨€é€‰æ‹©ä¾›éªŒè¯å®éªŒå®¤ä½¿ç”¨
                        st.session_state.source_lang = source_lang
                        st.session_state.target_lang = target_lang
                        
                        st.success("âœ… ç¿»è¯‘å™¨ Prompt æ„å»ºå®Œæˆï¼")
                        
                    except Exception as e:
                        self._handle_optimization_error(e)
        
        # æ˜¾ç¤ºç¿»è¯‘ä»»åŠ¡ä¼˜åŒ–ç»“æœ
        if 'translation_result' in st.session_state and st.session_state.translation_result:
            result = st.session_state.translation_result
            
            with col2:
                st.subheader("ğŸŒ ç¿»è¯‘å™¨ Prompt")
                
                # 1. ä¼˜åŒ–æ€è·¯
                with st.expander("ğŸ§  æŸ¥çœ‹ä¼˜åŒ–æ€è·¯", expanded=True):
                    st.write(result.thinking_process)
                
                # 2. è§’è‰²è®¾å®š
                with st.expander("ğŸ‘¤ é¢†åŸŸä¸“å®¶è§’è‰²", expanded=True):
                    st.info(result.role_definition)
                    st.caption("ğŸ’¡ æ ¹æ®ç¿»è¯‘é¢†åŸŸè®¾å®šçš„ä¸“ä¸šè§’è‰²ï¼Œç¡®ä¿è¯‘æ–‡ä¸“ä¸šæ€§")
                
                # 3. é£æ ¼æŒ‡å—
                with st.expander("ğŸ¨ é£æ ¼æŒ‡å—", expanded=True):
                    for idx, guideline in enumerate(result.style_guidelines, 1):
                        st.markdown(f"**æŒ‡å— {idx}:** {guideline}")
                    st.caption("ğŸ’¡ å…·ä½“çš„é£æ ¼è¦æ±‚ï¼Œä½¿è¯‘æ–‡ç¬¦åˆç›®æ ‡è¯­è¨€çš„è¡¨è¾¾ä¹ æƒ¯")
                
                # 4. æœ¯è¯­è¡¨ï¼ˆå¦‚æœæœ‰ï¼‰
                if result.glossary_section and result.glossary_section.strip():
                    with st.expander("ğŸ“– æœ¯è¯­å¯¹ç…§è¡¨ï¼ˆå¼ºåˆ¶éµå®ˆï¼‰", expanded=True):
                        st.markdown(result.glossary_section)
                        st.caption("ğŸ’¡ ä¸“æœ‰åè¯çš„é”å®šç¿»è¯‘ï¼Œç¡®ä¿æœ¯è¯­ä¸€è‡´æ€§")
                
                # 5. ç¿»è¯‘æµç¨‹
                with st.expander("ğŸ”„ ä¸‰æ­¥ç¿»è¯‘æ³•", expanded=True):
                    st.markdown(result.workflow_steps)
                    st.caption("ğŸ’¡ åˆ†æ­¥éª¤çš„ç¿»è¯‘æµç¨‹ï¼Œé¿å…æœºæ¢°ç›´è¯‘")
                
                # 6. æœ€ç»ˆ Prompt
                st.markdown("**âœ¨ æœ€ç»ˆå®Œæ•´çš„ç¿»è¯‘ Promptï¼ˆå¯ç›´æ¥å¤åˆ¶ï¼‰ï¼š**")
                st.caption("ğŸ’¡ ç”¨ {{text}} å ä½ç¬¦è¡¨ç¤ºå¾…ç¿»è¯‘çš„æ–‡æœ¬")
                st.text_area(
                    "ç¿»è¯‘å™¨ Prompt",
                    value=result.final_prompt,
                    height=450,
                    label_visibility="collapsed"
                )
                
                # ç›´æ¥æ˜¾ç¤ºä»£ç æ¡†ï¼Œå¸¦æœ‰å¤åˆ¶æŒ‰é’®
                st.code(result.final_prompt, language=None)
                st.caption("ğŸ“Œ ç‚¹å‡»ä»£ç æ¡†å³ä¸Šè§’çš„å¤åˆ¶æŒ‰é’®å³å¯å¤åˆ¶")
        
        # éªŒè¯å®éªŒå®¤åŒºåŸŸ
        if 'translation_result' in st.session_state and st.session_state.translation_result:
            self._render_validation_lab(st.session_state.translation_result)
    
    def _render_validation_lab(self, result):
        """æ¸²æŸ“ç¿»è¯‘éªŒè¯å®éªŒå®¤"""
        st.divider()
        st.subheader("ğŸ”¬ æ•ˆæœéªŒè¯å®éªŒå®¤")
        st.markdown("*ä½¿ç”¨ç¤ºä¾‹æ–‡æœ¬æµ‹è¯•ç¿»è¯‘è´¨é‡*")
        
        # é»˜è®¤æµ‹è¯•æ–‡æœ¬ï¼ˆæ ¹æ®è¯­è¨€æ–¹å‘ï¼‰
        source_lang = st.session_state.get('source_lang', 'ä¸­æ–‡')
        target_lang = st.session_state.get('target_lang', 'è‹±æ–‡')
        
        if source_lang == "è‹±æ–‡" and target_lang == "ä¸­æ–‡":
            default_text = """Notwithstanding any provision to the contrary, neither party shall be liable for any delay in performance or failure to perform this Agreement where such delay or failure is due to a Force Majeure event; provided that the affected party shall notify the other party in writing within five (5) business days and use reasonable efforts to mitigate losses."""
            default_reference = """å°½ç®¡æœ‰ä»»ä½•ç›¸åçº¦å®šï¼Œè‹¥å› ä¸å¯æŠ—åŠ›äº‹ä»¶å¯¼è‡´å±¥è¡Œå»¶è¿Ÿæˆ–æœªèƒ½å±¥è¡Œæœ¬åè®®ï¼Œä»»ä½•ä¸€æ–¹å‡ä¸æ‰¿æ‹…è´£ä»»ï¼›ä½†å—å½±å“æ–¹åº”åœ¨äº”ï¼ˆ5ï¼‰ä¸ªå·¥ä½œæ—¥å†…ä»¥ä¹¦é¢å½¢å¼é€šçŸ¥å¯¹æ–¹ï¼Œå¹¶å°½åˆç†åŠªåŠ›å‡è½»æŸå¤±ã€‚"""
        elif source_lang == "ä¸­æ–‡" and target_lang == "è‹±æ–‡":
            default_text = """å°½ç®¡æœ‰ä»»ä½•ç›¸åçº¦å®šï¼Œè‹¥å› ä¸å¯æŠ—åŠ›äº‹ä»¶å¯¼è‡´å±¥è¡Œå»¶è¿Ÿæˆ–æœªèƒ½å±¥è¡Œæœ¬åè®®ï¼Œä»»ä½•ä¸€æ–¹å‡ä¸æ‰¿æ‹…è´£ä»»ï¼›ä½†å—å½±å“æ–¹åº”åœ¨äº”ï¼ˆ5ï¼‰ä¸ªå·¥ä½œæ—¥å†…ä»¥ä¹¦é¢å½¢å¼é€šçŸ¥å¯¹æ–¹ï¼Œå¹¶å°½åˆç†åŠªåŠ›å‡è½»æŸå¤±ã€‚"""
            default_reference = """Notwithstanding any provision to the contrary, neither party shall be liable for any delay in performance or failure to perform this Agreement where such delay or failure is due to a Force Majeure event; provided that the affected party shall notify the other party in writing within five (5) business days and use reasonable efforts to mitigate losses."""
        else:
            default_text = """The company announced a $120 million funding round led by Horizon Capital, valuing the startup at $1.8 billion. The funds will be used to expand its data centers in Asia."""
            default_reference = """è¯¥å…¬å¸å®£å¸ƒç”± Horizon Capital é¢†æŠ•çš„ 1.2 äº¿ç¾å…ƒèèµ„è½®ï¼Œä½¿è¿™å®¶åˆåˆ›å…¬å¸ä¼°å€¼è¾¾åˆ° 18 äº¿ç¾å…ƒã€‚èµ„é‡‘å°†ç”¨äºæ‰©å¤§å…¶åœ¨äºšæ´²çš„æ•°æ®ä¸­å¿ƒã€‚"""
        
        col_test1, col_test2 = st.columns([1, 1])
        
        with col_test1:
            st.markdown(f"**ğŸ“„ {source_lang}åŸæ–‡**")
            test_text = st.text_area(
                "è¾“å…¥è¦ç¿»è¯‘çš„æ–‡æœ¬",
                value=default_text,
                height=150,
                key="trans_test_text"
            )
            
            st.markdown(f"**ğŸ“Œ å‚è€ƒè¯‘æ–‡ï¼ˆç”¨äºè®¡ç®—BLEUåˆ†æ•°ï¼‰**")
            reference_translation = st.text_area(
                "è¾“å…¥äººå·¥ç¿»è¯‘çš„å‚è€ƒè¯‘æ–‡",
                value=default_reference,
                height=100,
                key="trans_reference"
            )
        
        with col_test2:
            st.markdown("**ğŸ¯ è¯„åˆ†æ ‡å‡†**")
            st.info("""
**BLEU Scoreï¼ˆç¿»è¯‘ä»»åŠ¡ï¼‰**

**BLEU æŒ‡æ ‡è¯´æ˜**ï¼š
- è®¡ç®—æ–¹å¼ï¼šn-gram ç²¾ç¡®åº¦çš„å‡ ä½•å¹³å‡
- è¡¡é‡è¯‘æ–‡ä¸å‚è€ƒè¯‘æ–‡çš„ç›¸ä¼¼åº¦

**è¯„åˆ†æ ‡å‡†**ï¼š
- ğŸŸ¢ **ä¼˜ç§€** â‰¥ 40%
- ğŸŸ¡ **è‰¯å¥½** 20% - 40%
- ğŸ”´ **éœ€æ”¹è¿›** < 20%

ğŸ“Œ **æ³¨æ„**ï¼šBLEU åˆ†æ•°åªæ˜¯å‚è€ƒï¼Œè¯·ç»“åˆäººå·¥è¯„ä¼°
            """)
        
        # è¿è¡ŒéªŒè¯æŒ‰é’®
        if st.button("ğŸš€ æ‰§è¡Œç¿»è¯‘", type="primary", use_container_width=True, key="trans_validation_btn"):
            if not test_text or test_text.strip() == "":
                st.error("âŒ è¯·è¾“å…¥è¦ç¿»è¯‘çš„æ–‡æœ¬")
            elif not reference_translation or reference_translation.strip() == "":
                st.error("âŒ è¯·è¾“å…¥å‚è€ƒè¯‘æ–‡ï¼Œç”¨äºè®¡ç®—BLEUåˆ†æ•°")
            else:
                with st.spinner(f"â³ æ­£åœ¨ä»{source_lang}ç¿»è¯‘åˆ°{target_lang}..."):
                    try:
                        # æ›¿æ¢å ä½ç¬¦
                        prompt_with_text = result.final_prompt
                        prompt_with_text = re.sub(r"\{\{\s*text\s*\}\}", test_text, prompt_with_text)
                        prompt_with_text = re.sub(r"\{\{\{\s*text\s*\}\}\}", test_text, prompt_with_text)
                        prompt_with_text = re.sub(r"\{\s*text\s*\}", test_text, prompt_with_text)
                        prompt_with_text = prompt_with_text.replace("[å¾…ç¿»è¯‘æ–‡æœ¬]", test_text)
                        prompt_with_text = prompt_with_text.replace("ã€å¾…ç¿»è¯‘æ–‡æœ¬ã€‘", test_text)
                        prompt_with_text = prompt_with_text.replace("<text>", test_text)
                        
                        # å¼ºåˆ¶è¾“å‡ºä»…åŒ…å«ç›®æ ‡è¯­è¨€è¯‘æ–‡
                        strict_prefix = f"ã€è¾“å‡ºè¦æ±‚ã€‘åªè¾“å‡º{target_lang}è¯‘æ–‡ï¼Œä¸è¦è§£é‡Šã€ä¸è¦åŸæ–‡ã€ä¸è¦åŒè¯­å¯¹ç…§ã€‚\n"
                        prompt_with_text = strict_prefix + prompt_with_text
                        
                        # è°ƒç”¨ LLM
                        response = self.optimizer.llm.invoke(prompt_with_text)
                        translation = response.content.strip()
                        
                        # è®¡ç®— BLEU åˆ†æ•°
                        from metrics import MetricsCalculator
                        calc = MetricsCalculator()
                        # æ ¹æ®ç›®æ ‡è¯­è¨€é€‰æ‹©åˆ†è¯æ–¹å¼
                        lang = "zh" if target_lang == "ä¸­æ–‡" else "en"
                        bleu_score = calc.calculate_bleu(translation, reference_translation, lang=lang)
                        
                        # ä¿å­˜ç»“æœ
                        st.session_state.trans_validation_result = {
                            "original": test_text,
                            "translation": translation,
                            "reference": reference_translation,
                            "bleu_score": bleu_score,
                            "source_lang": source_lang,
                            "target_lang": target_lang
                        }
                        
                    except Exception as e:
                        st.error(f"âŒ ç¿»è¯‘å¤±è´¥ï¼š{str(e)}")
        
        # æ˜¾ç¤ºéªŒè¯ç»“æœ
        if 'trans_validation_result' in st.session_state and st.session_state.trans_validation_result:
            result_data = st.session_state.trans_validation_result
            
            st.divider()
            st.markdown("### ğŸ“Š ç¿»è¯‘ç»“æœ")
            
            # æ˜¾ç¤ºBLEUåˆ†æ•°å’Œè¯„çº§
            bleu_score = result_data["bleu_score"]
            
            # æ ¹æ®BLEUåˆ†æ•°æ˜¾ç¤ºè¯„çº§
            if bleu_score >= 40:
                st.success(f"ğŸ‰ BLEU åˆ†æ•°ï¼š{bleu_score:.2f}% - ğŸŸ¢ ä¼˜ç§€ï¼")
            elif bleu_score >= 20:
                st.info(f"ğŸ‘ BLEU åˆ†æ•°ï¼š{bleu_score:.2f}% - ğŸŸ¡ è‰¯å¥½")
            else:
                st.warning(f"âš ï¸ BLEU åˆ†æ•°ï¼š{bleu_score:.2f}% - ğŸ”´ éœ€æ”¹è¿›")
            
            st.divider()
            
            col_result1, col_result2, col_result3 = st.columns(3)
            
            with col_result1:
                st.markdown(f"**ğŸ“„ {result_data['source_lang']}åŸæ–‡**")
                st.text_area(
                    "åŸæ–‡",
                    value=result_data["original"],
                    height=200,
                    label_visibility="collapsed",
                    disabled=True
                )
            
            with col_result2:
                st.markdown(f"**âœ¨ AIç¿»è¯‘çš„{result_data['target_lang']}è¯‘æ–‡**")
                st.text_area(
                    "AIè¯‘æ–‡",
                    value=result_data["translation"],
                    height=200,
                    label_visibility="collapsed"
                )
            
            with col_result3:
                st.markdown(f"**ğŸ“Œ å‚è€ƒ{result_data['target_lang']}è¯‘æ–‡**")
                st.text_area(
                    "å‚è€ƒè¯‘æ–‡",
                    value=result_data["reference"],
                    height=200,
                    label_visibility="collapsed",
                    disabled=True
                )
            
            st.markdown("**ğŸ’¡ äººå·¥è¯„ä¼°å»ºè®®**")
            st.caption("BLEU åˆ†æ•°æ˜¯è‡ªåŠ¨åŒ–æŒ‡æ ‡ï¼Œå»ºè®®ç»“åˆäººå·¥è¯„ä¼°åˆ¤æ–­ç¿»è¯‘è´¨é‡ï¼ˆå‡†ç¡®æ€§ã€æµç•…æ€§ã€æœ¯è¯­ä¸€è‡´æ€§ï¼‰")
    
    def _validate_api_key(self):
        """éªŒè¯ API Key"""
        api_key = st.session_state.get('api_key_input', '')
        if not api_key or api_key.strip() == "":
            st.error("âŒ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® API Key")
            return False
        return True
    
    def _handle_optimization_error(self, e):
        """å¤„ç†ä¼˜åŒ–é”™è¯¯"""
        error_msg = str(e)
        st.error(f"âŒ æ„å»ºå¤±è´¥ï¼š{error_msg}")
        
        api_provider = st.session_state.get('api_provider', 'NVIDIA')
        
        # æä¾›è§£å†³æ–¹æ¡ˆ
        if "404" in error_msg or "401" in error_msg:
            st.warning("""**å¯èƒ½çš„åŸå› å’Œè§£å†³æ–¹æ¡ˆï¼š**""")
            if api_provider == "NVIDIA":
                st.markdown("""
                1. **API Key æ— æ•ˆæˆ–æœªé…ç½®**
                   - è¯·è®¿é—® [NVIDIA Build](https://build.nvidia.com/) è·å– API Key
                2. **æ¨¡å‹ä¸æ”¯æŒ**
                   - æ¨èä½¿ç”¨ meta/llama-3.1-405b-instruct
                """)
        
        st.info("ğŸ”§ å»ºè®®ï¼šè¿è¡Œ `python test_nvidia.py` æµ‹è¯• API è¿æ¥")
