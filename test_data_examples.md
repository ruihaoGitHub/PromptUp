# 测试数据示例

本文档提供各任务类型的测试数据格式说明和示例。

---

## 1. 分类任务测试数据

### 格式说明
- **支持批量测试**：每行一个测试样本
- **参考答案**：每行一个标签，与测试数据一一对应
- **建议样本数**：至少 5-10 个样本，才能准确评估 Accuracy

### 示例 1：情感分析（积极/消极/中立）

**测试输入：**
```
这个产品真的很好用，非常满意！
价格太贵了，性价比不高，不推荐购买。
还可以吧，没有特别的感觉。
质量很差，用了一次就坏了，太失望了。
物流很快，包装也很好，赞一个！
一般般，没什么亮点。
超出预期，强烈推荐！
客服态度很好，但产品有点小问题。
```

**参考答案：**
```
积极
消极
中立
消极
积极
中立
积极
中立
```

### 示例 2：新闻分类（科技/体育/娱乐/财经）

**测试输入：**
```
苹果公司发布新款iPhone，搭载最新AI芯片
中国男足1:0战胜日本队，晋级世界杯
知名演员张三获得金马奖最佳男主角
A股大涨，上证指数突破3500点
OpenAI 推出 GPT-5 模型，性能提升显著
湖人队击败勇士，詹姆斯砍下40分
新电影《流浪地球3》票房破10亿
央行宣布降息，房贷利率下调
```

**参考答案：**
```
科技
体育
娱乐
财经
科技
体育
娱乐
财经
```

### 示例 3：垃圾邮件检测（垃圾邮件/正常邮件）

**测试输入：**
```
恭喜您中奖100万！请点击链接领取奖金！
明天下午2点开会，请准时参加。
限时特惠！购买产品立减50%！点击购买！
您的快递已到达，请凭取件码领取。
紧急通知：您的账户存在异常，请立即验证身份！
会议纪要已发送到您的邮箱，请查收。
```

**参考答案：**
```
垃圾邮件
正常邮件
垃圾邮件
正常邮件
垃圾邮件
正常邮件
```

---

## 2. 摘要任务测试数据

### 格式说明
- **单文本测试**：输入一篇长文本
- **参考答案**：人工撰写的标准摘要
- **评估指标**：ROUGE-1、ROUGE-2、ROUGE-L

### 示例：技术会议纪要摘要

**测试输入：**
```
2026年1月15日，技术部召开了关于新产品开发的讨论会议。会议由技术总监李明主持，参会人员包括前端团队负责人王芳、后端团队负责人张伟、UI设计师刘洋等10人。

会议首先回顾了上个月的进度：前端团队已完成用户界面的80%，后端API开发完成60%，数据库设计已全部完成。王芳提出前端在移动端适配上遇到了一些兼容性问题，需要额外2周时间解决。张伟表示后端的用户认证模块存在性能瓶颈，计划引入Redis缓存优化。

针对遇到的问题，会议做出以下决策：
1. 移动端适配问题由王芳负责，截止时间延长至2月5日
2. 后端性能优化由张伟负责，1月20日前提交优化方案
3. 增加测试人员2名，加强测试力度
4. 下次会议定于1月30日，届时检查各项问题的解决情况

会议还讨论了产品的营销推广策略，市场部建议在发布前进行小范围内测，收集用户反馈。技术总监李明表示支持，并要求各团队配合市场部的内测工作。

会议于下午5点结束。
```

**参考答案：**
```
**会议要点：**
- 时间：2026年1月15日，主持人：李明
- 进度：前端80%，后端60%，数据库100%

**遇到的问题：**
- 前端：移动端兼容性问题
- 后端：用户认证性能瓶颈

**决策与行动计划：**
1. 王芳负责移动端适配，延期至2月5日
2. 张伟负责性能优化，1月20日提交方案
3. 增加2名测试人员
4. 下次会议：1月30日

**其他：**市场部建议内测，技术部支持配合。
```

---

## 3. 翻译任务测试数据

### 格式说明
- **单文本测试**：输入待翻译文本
- **参考答案**：人工翻译的标准译文
- **评估指标**：BLEU Score

### 示例 1：技术文档翻译（中文 → 英文）

**测试输入：**
```
Prompt Engineering 是一种通过设计和优化输入提示词来提高大语言模型输出质量的技术。它不需要修改模型参数，而是通过精心设计的提示词来引导模型生成更准确、更相关的回答。这种技术在实际应用中非常重要，可以显著提升AI系统的性能和用户体验。
```

**参考答案：**
```
Prompt Engineering is a technique that improves the quality of large language model outputs by designing and optimizing input prompts. It does not require modifying model parameters, but rather guides the model to generate more accurate and relevant responses through carefully designed prompts. This technique is very important in practical applications and can significantly enhance the performance and user experience of AI systems.
```

### 示例 2：日常对话翻译（英文 → 中文）

**测试输入：**
```
I'm really excited about our upcoming trip to Japan! We're planning to visit Tokyo, Kyoto, and Osaka. I can't wait to try authentic ramen and sushi. Have you been to Japan before?
```

**参考答案：**
```
我真的很期待我们即将到来的日本之行！我们计划去东京、京都和大阪。我迫不及待想尝尝正宗的拉面和寿司。你以前去过日本吗？
```

---

## 4. 生成任务测试数据

### 格式说明
- **无标准化指标**：生成任务通常使用人工评估或 LLM-as-a-Judge
- **建议评估维度**：
  - 是否遵循 Prompt 要求
  - 输出格式是否正确
  - 内容是否准确完整

### 示例：代码生成

**测试输入：**
```
实现一个 Python 冒泡排序函数
```

**人工评估标准：**
- ✅ 函数名称合理（如 bubble_sort）
- ✅ 包含输入参数和返回值
- ✅ 算法实现正确
- ✅ 有适当的注释
- ✅ 可以直接运行

---

## 使用建议

1. **分类任务**：
   - 建议准备 10-20 个测试样本
   - 确保各类别分布相对均衡
   - 包含一些边界案例和模糊案例

2. **摘要任务**：
   - 选择中等长度的文本（200-500字）
   - 参考摘要应该简洁、准确、完整
   - 可以使用不同风格的摘要作为参考

3. **翻译任务**：
   - 选择包含专业术语的文本
   - 参考译文应该准确、流畅、地道
   - 可以准备多个参考译文提高评估准确性

4. **批量测试技巧**：
   - 使用文本编辑器准备测试数据
   - 每行一个样本，方便复制粘贴
   - 保存测试数据以便重复使用
