# Optimizers æ¨¡å—

## ğŸ“ æ¨¡å—ç®€ä»‹

æœ¬æ¨¡å—åŒ…å«é’ˆå¯¹ä¸åŒä»»åŠ¡ç±»å‹çš„ä¸“ç”¨ Prompt ä¼˜åŒ–å™¨ï¼Œæ¯ä¸ªä¼˜åŒ–å™¨é’ˆå¯¹ç‰¹å®šä»»åŠ¡ï¼ˆåˆ†ç±»ã€æ‘˜è¦ã€ç¿»è¯‘ï¼‰å®ç°å®šåˆ¶åŒ–çš„ä¼˜åŒ–é€»è¾‘ã€‚

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

- **ä»»åŠ¡ä¸“ç”¨ä¼˜åŒ–**ï¼šä¸ºä¸åŒç±»å‹çš„ NLP ä»»åŠ¡æä¾›ä¸“é—¨çš„ä¼˜åŒ–ç­–ç•¥
- **ç»Ÿä¸€æ¥å£**ï¼šæ‰€æœ‰ä¼˜åŒ–å™¨ç»§æ‰¿è‡ª `BaseOptimizer`ï¼Œæä¾›ä¸€è‡´çš„ API
- **LLM é©±åŠ¨**ï¼šä½¿ç”¨ Meta-Prompt å¼•å¯¼ LLM ç”Ÿæˆé«˜è´¨é‡çš„ä»»åŠ¡ Prompt
- **ç»“æ„åŒ–è¾“å‡º**ï¼šè¿”å›ç¬¦åˆ Pydantic æ¨¡å‹çš„ç»“æ„åŒ–ç»“æœ

## ğŸ“„ æ–‡ä»¶è¯´æ˜

### `base.py`
**åŸºç¡€ä¼˜åŒ–å™¨ç±»**

æä¾›æ‰€æœ‰ä»»åŠ¡ä¼˜åŒ–å™¨çš„é€šç”¨åŠŸèƒ½ï¼š

#### æ ¸å¿ƒç±»

**`BaseOptimizer`**
- **åŠŸèƒ½**: æ‰€æœ‰ä¼˜åŒ–å™¨çš„æŠ½è±¡åŸºç±»
- **æ ¸å¿ƒæ–¹æ³•**:
  - `_call_llm(meta_prompt: str) -> str`: è°ƒç”¨ LLM å¹¶è¿”å›å“åº”
  - `_parse_and_validate(content: str, model_class: Type[BaseModel]) -> BaseModel`: è§£æ JSON å¹¶éªŒè¯æ•°æ®ç»“æ„
  - `optimize(...)`: æŠ½è±¡æ–¹æ³•ï¼Œç”±å­ç±»å®ç°å…·ä½“ä¼˜åŒ–é€»è¾‘

- **é€šç”¨åŠŸèƒ½**:
  - LLM è°ƒç”¨å’Œé”™è¯¯å¤„ç†
  - JSON å“åº”è§£æå’Œæ¸…ç†
  - æ•°æ®æ¨¡å‹éªŒè¯
  - æ—¥å¿—è¾“å‡ºå’Œè°ƒè¯•ä¿¡æ¯

**ç‰¹ç‚¹**:
- ä½¿ç”¨ `abc.ABC` å’Œ `@abstractmethod` ç¡®ä¿å­ç±»å®ç°å¿…éœ€æ–¹æ³•
- ç»Ÿä¸€çš„å¼‚å¸¸å¤„ç†æœºåˆ¶
- å¯é…ç½®çš„ LLM å‚æ•°ï¼ˆtemperatureã€max_tokensï¼‰

### `classification.py`
**åˆ†ç±»ä»»åŠ¡ä¼˜åŒ–å™¨**

é’ˆå¯¹æ–‡æœ¬åˆ†ç±»ä»»åŠ¡çš„ä¸“ç”¨ä¼˜åŒ–å™¨ï¼š

#### æ ¸å¿ƒç±»

**`ClassificationOptimizer`**
- **ç»§æ‰¿**: `BaseOptimizer`
- **ä»»åŠ¡ç±»å‹**: æ–‡æœ¬åˆ†ç±»ï¼ˆæƒ…æ„Ÿåˆ†æã€ä¸»é¢˜åˆ†ç±»ã€æ„å›¾è¯†åˆ«ç­‰ï¼‰

#### æ ¸å¿ƒæ–¹æ³•

**`optimize(task_description: str, labels: List[str]) -> ClassificationPrompt`**
- **è¾“å…¥**:
  - `task_description`: åˆ†ç±»ä»»åŠ¡æè¿°ï¼Œå¦‚ "åˆ¤æ–­ç”¨æˆ·è¯„è®ºçš„æƒ…æ„Ÿå€¾å‘"
  - `labels`: æ ‡ç­¾åˆ—è¡¨ï¼Œå¦‚ `["æ­£é¢", "è´Ÿé¢", "ä¸­ç«‹"]`
  
- **å¤„ç†æµç¨‹**:
  1. åŠ è½½ classification Meta-Prompt æ¨¡æ¿
  2. å¡«å……ä»»åŠ¡æè¿°å’Œæ ‡ç­¾ä¿¡æ¯
  3. è°ƒç”¨ LLM ç”Ÿæˆä¼˜åŒ–åçš„åˆ†ç±» Prompt
  4. è§£æå¹¶éªŒè¯è¿”å›çš„ JSON
  5. æ„å»º `ClassificationPrompt` å¯¹è±¡

- **è¿”å›**: `ClassificationPrompt` å¯¹è±¡ï¼ŒåŒ…å«ï¼š
  - `role_definition`: è§’è‰²è®¾å®šï¼ˆå¦‚ "ä½ æ˜¯ä¸“ä¸šçš„æƒ…æ„Ÿåˆ†æä¸“å®¶"ï¼‰
  - `label_definitions`: æ ‡ç­¾è¯¦ç»†å®šä¹‰
  - `few_shot_examples`: è‡ªåŠ¨ç”Ÿæˆçš„ç¤ºä¾‹
  - `reasoning_guidance`: æ¨ç†å¼•å¯¼
  - `output_format`: è¾“å‡ºæ ¼å¼è¦æ±‚
  - `final_prompt`: æœ€ç»ˆå¯ç”¨çš„å®Œæ•´ Prompt

**ä¼˜åŒ–ç­–ç•¥**:
- è‡ªåŠ¨è®¾è®¡åˆé€‚çš„è§’è‰²èº«ä»½
- ç”Ÿæˆé«˜è´¨é‡çš„ Few-shot ç¤ºä¾‹
- å¼ºåˆ¶è¾“å‡ºæ ¼å¼æ§åˆ¶ï¼ˆåªè¾“å‡ºæ ‡ç­¾åï¼‰
- åŒ…å«å ä½ç¬¦ä»¥ä¾¿åç»­æ›¿æ¢å®é™…æ–‡æœ¬

### `summarization.py`
**æ‘˜è¦ä»»åŠ¡ä¼˜åŒ–å™¨**

é’ˆå¯¹æ–‡æœ¬æ‘˜è¦ä»»åŠ¡çš„ä¸“ç”¨ä¼˜åŒ–å™¨ï¼š

#### æ ¸å¿ƒç±»

**`SummarizationOptimizer`**
- **ç»§æ‰¿**: `BaseOptimizer`
- **ä»»åŠ¡ç±»å‹**: æ–‡æœ¬æ‘˜è¦ï¼ˆä¼šè®®çºªè¦ã€è®ºæ–‡æ‘˜è¦ã€æ–°é—»æ€»ç»“ç­‰ï¼‰

#### æ ¸å¿ƒæ–¹æ³•

**`optimize(task_description: str, source_type: str, target_audience: str, focus_points: str, length_constraint: Optional[str]) -> SummarizationPrompt`**

- **è¾“å…¥**:
  - `task_description`: æ‘˜è¦ä»»åŠ¡æè¿°ï¼Œå¦‚ "æ€»ç»“æŠ€æœ¯ä¼šè®®çš„æ ¸å¿ƒå†³ç­–"
  - `source_type`: æºæ–‡æœ¬ç±»å‹ï¼Œå¦‚ "ä¼šè®®è®°å½•"ã€"å­¦æœ¯è®ºæ–‡"
  - `target_audience`: ç›®æ ‡è¯»è€…ï¼Œå¦‚ "æŠ€æœ¯ç»ç†"ã€"æ™®é€šç”¨æˆ·"
  - `focus_points`: æ ¸å¿ƒå…³æ³¨ç‚¹ï¼Œå¦‚ "è¡ŒåŠ¨è®¡åˆ’å’Œè´Ÿè´£äºº"
  - `length_constraint`: ç¯‡å¹…é™åˆ¶ï¼Œå¦‚ "100å­—ä»¥å†…"ã€"3-5ä¸ªè¦ç‚¹"ï¼ˆå¯é€‰ï¼‰

- **å¤„ç†æµç¨‹**:
  1. åŠ è½½ summarization Meta-Prompt æ¨¡æ¿
  2. å¡«å……æ‰€æœ‰ä»»åŠ¡å‚æ•°
  3. è°ƒç”¨ LLM ç”Ÿæˆä¼˜åŒ–åçš„æ‘˜è¦ Prompt
  4. è§£æå¹¶éªŒè¯è¿”å›çš„ JSON
  5. æ„å»º `SummarizationPrompt` å¯¹è±¡

- **è¿”å›**: `SummarizationPrompt` å¯¹è±¡ï¼ŒåŒ…å«ï¼š
  - `role_setting`: è§’è‰²è®¾å®š
  - `extraction_rules`: æå–è§„åˆ™åˆ—è¡¨
  - `negative_constraints`: è´Ÿé¢çº¦æŸï¼ˆå‘Šè¯‰æ¨¡å‹ä¸è¦åšä»€ä¹ˆï¼‰
  - `step_by_step_guide`: åˆ†æ­¥æ“ä½œæŒ‡å¯¼
  - `final_prompt`: æœ€ç»ˆå¯ç”¨çš„å®Œæ•´ Prompt

**ä¼˜åŒ–ç­–ç•¥**:
- æ ¹æ®ç›®æ ‡è¯»è€…è°ƒæ•´è¯­è¨€é£æ ¼
- æ˜ç¡®ä¿¡æ¯æå–è§„åˆ™
- è®¾ç½®è´Ÿé¢çº¦æŸé¿å…å¸¸è§é”™è¯¯
- æä¾›åˆ†æ­¥æ€è€ƒæ¡†æ¶

### `translation.py`
**ç¿»è¯‘ä»»åŠ¡ä¼˜åŒ–å™¨**

é’ˆå¯¹æ–‡æœ¬ç¿»è¯‘ä»»åŠ¡çš„ä¸“ç”¨ä¼˜åŒ–å™¨ï¼š

#### æ ¸å¿ƒç±»

**`TranslationOptimizer`**
- **ç»§æ‰¿**: `BaseOptimizer`
- **ä»»åŠ¡ç±»å‹**: æ–‡æœ¬ç¿»è¯‘ï¼ˆå¤šè¯­è¨€ã€é¢†åŸŸç¿»è¯‘ã€é£æ ¼è½¬æ¢ç­‰ï¼‰

#### æ ¸å¿ƒæ–¹æ³•

**`optimize(source_lang: str, target_lang: str, domain: str, tone: str, user_glossary: str) -> TranslationPrompt`**

- **è¾“å…¥**:
  - `source_lang`: æºè¯­è¨€ï¼Œå¦‚ "ä¸­æ–‡"ã€"è‹±æ–‡"
  - `target_lang`: ç›®æ ‡è¯­è¨€
  - `domain`: åº”ç”¨é¢†åŸŸï¼Œå¦‚ "é€šç”¨æ—¥å¸¸"ã€"IT/æŠ€æœ¯æ–‡æ¡£"ã€"æ³•å¾‹åˆåŒ"
  - `tone`: æœŸæœ›é£æ ¼ï¼Œå¦‚ "æ ‡å‡†/å‡†ç¡®"ã€"åœ°é“/å£è¯­åŒ–"
  - `user_glossary`: ç”¨æˆ·æä¾›çš„æœ¯è¯­è¡¨ï¼Œæ ¼å¼å¦‚ "Prompt=æç¤ºè¯\nLLM=å¤§è¯­è¨€æ¨¡å‹"

- **å¤„ç†æµç¨‹**:
  1. åŠ è½½ translation Meta-Prompt æ¨¡æ¿
  2. å¡«å……è¯­è¨€å¯¹ã€é¢†åŸŸã€é£æ ¼ã€æœ¯è¯­è¡¨
  3. è°ƒç”¨ LLM ç”Ÿæˆä¼˜åŒ–åçš„ç¿»è¯‘ Prompt
  4. è§£æå¹¶éªŒè¯è¿”å›çš„ JSON
  5. æ„å»º `TranslationPrompt` å¯¹è±¡

- **è¿”å›**: `TranslationPrompt` å¯¹è±¡ï¼ŒåŒ…å«ï¼š
  - `role_setting`: è§’è‰²è®¾å®š
  - `domain_knowledge`: é¢†åŸŸçŸ¥è¯†è¯´æ˜
  - `tone_guidance`: è¯­æ°”/é£æ ¼æŒ‡å¯¼
  - `quality_checks`: è´¨é‡æ£€æŸ¥æ¸…å•
  - `glossary_integration`: æœ¯è¯­è¡¨ä½¿ç”¨è¯´æ˜
  - `final_prompt`: æœ€ç»ˆå¯ç”¨çš„å®Œæ•´ Prompt

**ä¼˜åŒ–ç­–ç•¥**:
- æ ¹æ®é¢†åŸŸæ³¨å…¥ä¸“ä¸šçŸ¥è¯†
- é›†æˆç”¨æˆ·æœ¯è¯­è¡¨
- æä¾›é£æ ¼å’Œè¯­æ°”æŒ‡å¯¼
- åŒ…å«è´¨é‡æ£€æŸ¥æ¸…å•

### `__init__.py`
**æ¨¡å—æ¥å£**

å¯¼å‡ºæ‰€æœ‰ä¼˜åŒ–å™¨ç±»ï¼š
```python
from optimizers import ClassificationOptimizer, SummarizationOptimizer, TranslationOptimizer
```

## ğŸ”— ä¸å…¶ä»–æ¨¡å—çš„å…³ç³»

- **ç»§æ‰¿**: 
  - æ‰€æœ‰ä¼˜åŒ–å™¨ç»§æ‰¿è‡ª `base.BaseOptimizer`

- **ä¾èµ–**:
  - `config.template_loader`: åŠ è½½ Meta-Prompt æ¨¡æ¿
  - `config.models`: ä½¿ç”¨æ•°æ®æ¨¡å‹å®šä¹‰è¿”å›å€¼
  - `services.LLMService`: è°ƒç”¨ LLM
  - `utils.safe_json_loads`: JSON è§£æ

- **è¢«è°ƒç”¨**:
  - `optimizer.PromptOptimizer`: ç»„åˆä½¿ç”¨æ‰€æœ‰ä¼˜åŒ–å™¨

## ğŸ“Š ä¼˜åŒ–å™¨å¯¹æ¯”

| ä¼˜åŒ–å™¨ | ä»»åŠ¡ç±»å‹ | å…³é”®è¾“å‡º | ä¸»è¦ä¼˜åŒ–ç‚¹ |
|--------|----------|----------|------------|
| Classification | æ–‡æœ¬åˆ†ç±» | Few-shot ç¤ºä¾‹ã€è¾“å‡ºæ ¼å¼ | è§’è‰²è®¾å®šã€ç¤ºä¾‹è´¨é‡ |
| Summarization | æ–‡æœ¬æ‘˜è¦ | æå–è§„åˆ™ã€æ­¥éª¤æŒ‡å¯¼ | ä¿¡æ¯ç­›é€‰ã€ç»“æ„åŒ– |
| Translation | æ–‡æœ¬ç¿»è¯‘ | æœ¯è¯­è¡¨é›†æˆã€è´¨é‡æ£€æŸ¥ | é¢†åŸŸçŸ¥è¯†ã€é£æ ¼æ§åˆ¶ |

## ğŸ“š ä½¿ç”¨ç¤ºä¾‹

```python
from optimizers import ClassificationOptimizer
from services import LLMService

# åˆ›å»º LLM å®ä¾‹
llm = LLMService.create_llm(
    provider="nvidia",
    model="meta/llama-3.1-70b-instruct"
)

# åˆ›å»ºåˆ†ç±»ä¼˜åŒ–å™¨
classifier = ClassificationOptimizer(llm)

# ä¼˜åŒ–åˆ†ç±»ä»»åŠ¡
result = classifier.optimize(
    task_description="åˆ¤æ–­ç”¨æˆ·è¯„è®ºçš„æƒ…æ„Ÿå€¾å‘",
    labels=["æ­£é¢", "è´Ÿé¢", "ä¸­ç«‹"]
)

# ä½¿ç”¨ä¼˜åŒ–åçš„ Prompt
print(f"è§’è‰²è®¾å®š: {result.role_definition}")
print(f"å®Œæ•´ Prompt:\n{result.final_prompt}")

# å®é™…åˆ†ç±»
final_prompt = result.final_prompt.replace(
    "[å¾…åˆ†ç±»æ–‡æœ¬]", 
    "è¿™ä¸ªäº§å“å¤ªæ£’äº†ï¼Œéå¸¸æ»¡æ„ï¼"
)
classification_result = llm.invoke(final_prompt)
print(f"åˆ†ç±»ç»“æœ: {classification_result.content}")
```

## âš™ï¸ è‡ªå®šä¹‰ä¼˜åŒ–å™¨

å¦‚éœ€æ·»åŠ æ–°çš„ä»»åŠ¡ç±»å‹ä¼˜åŒ–å™¨ï¼š

1. ç»§æ‰¿ `BaseOptimizer`
2. å®ç° `optimize()` æ–¹æ³•
3. åœ¨ `config/meta_prompts/` æ·»åŠ å¯¹åº”çš„æ¨¡æ¿æ–‡ä»¶
4. åœ¨ `config/models.py` å®šä¹‰æ•°æ®æ¨¡å‹
5. åœ¨ `__init__.py` ä¸­å¯¼å‡º

```python
from optimizers.base import BaseOptimizer
from config.models import CustomPrompt

class CustomOptimizer(BaseOptimizer):
    def optimize(self, task_param: str) -> CustomPrompt:
        # 1. åŠ è½½æ¨¡æ¿
        meta_prompt = load_meta_prompt('custom', task_param=task_param)
        
        # 2. è°ƒç”¨ LLM
        content = self._call_llm(meta_prompt)
        
        # 3. è§£æéªŒè¯
        result = self._parse_and_validate(content, CustomPrompt)
        
        return result
```
