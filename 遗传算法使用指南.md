# 遗传算法使用指南

## 🧬 什么是遗传算法？

遗传算法 (Genetic Algorithm, GA) 是一种模拟生物进化的优化算法，在 Prompt 优化中表现出色。

### 核心概念

| 生物学概念 | Prompt 优化映射 |
|-----------|----------------|
| 🧬 染色体 | 一个完整的 Prompt 方案 |
| 🔬 基因 | Prompt 的组件（角色、风格、技巧） |
| 💪 适应度 | Accuracy/ROUGE/BLEU 分数 |
| 👶 交叉 | 两个高分 Prompt 交换组件 |
| 🎲 变异 | 随机修改某些组件 |
| 🏆 选择 | 保留高分个体到下一代 |

---

## 📊 随机搜索 vs 遗传算法

### 算法对比

| 维度 | 🎲 随机搜索 | 🧬 遗传算法 |
|------|-----------|-----------|
| **策略** | 独立随机采样 | 多代进化迭代 |
| **收敛性** | 无保证，完全随机 | 单调递增，持续改进 |
| **成本** | `迭代次数 × 样本数` | `代数 × 种群 × 样本数` |
| **适用场景** | 快速探索 | 精细打磨 |
| **优势** | 快速、低成本 | 持续优化、效果好 |
| **劣势** | 靠运气，不稳定 | 成本高，需要时间 |

### 典型表现

**随机搜索得分曲线**：
```
分数
 ↑
90|    ●        ●
80|  ●    ●
70|          ●     ●
60|                  ●
  +------------------→ 迭代
     随机波动，无规律
```

**遗传算法得分曲线**：
```
分数
 ↑
90|            ●──●──●
80|        ●──●
70|    ●──●
60|●──●
  +------------------→ 代数
     持续上升，越来越强
```

---

## 🚀 如何使用

### 方法 1：Streamlit 界面

1. 启动界面：
```bash
streamlit run app.py
```

2. 滚动到 **"🔬 Prompt 自动寻优实验室"** 部分

3. 选择算法：
   - **🎲 随机搜索**：快速探索
   - **🧬 遗传算法**：深度优化

4. 配置参数：
   - **代数**：3-10（越多越好，成本越高）
   - **种群规模**：4-20（规模越大，覆盖越全）
   - **精英比例**：0.2（保留 20% 优秀个体）
   - **变异概率**：0.2（20% 概率变异）

5. 提供测试数据集

6. 点击 **"🚀 开始遗传进化寻优"**

7. 观察实时进化曲线，查看结果

---

### 方法 2：命令行测试

#### 测试遗传算法

```bash
python test_genetic_algorithm.py
```

**输出示例**：
```
🧬 遗传算法测试
====================================
📋 测试配置：
  任务类型: classification
  进化代数: 3 代
  种群规模: 4 个体
  预计 API 调用: 36 次

🧬 第 1 代：初始化种群...
  个体 1: 资深数据分析师 + 严谨学术 + 思维链 → 75.00
  个体 2: 情感学家 + 通俗易懂 + 直接回答 → 83.33
  ...

📊 第 1 代统计:
  🥇 最高分: 83.33
  📊 平均分: 79.17
  🏆 冠军: 情感学家 + 通俗易懂 + 直接回答

🧬 选择: 保留 1 个精英到下一代
🧬 繁衍: 生成 3 个新个体
  🔀 变异: 更换技巧 → 特征分析

...

🏆 遗传算法完成！
🥇 最终冠军得分: 91.67%
🧬 进化增益: +8.34 分
```

---

#### 对比两种算法

```bash
python compare_algorithms.py
```

**输出示例**：
```
🔬 算法对比实验：随机搜索 vs 遗传算法

🎲 实验 1: 随机搜索
最佳得分: 83.33

🧬 实验 2: 遗传算法
最佳得分: 91.67
进化增益: +8.34 分

📊 对比分析
─────────────────────────────────────
指标              🎲 随机搜索      🧬 遗传算法      胜者
─────────────────────────────────────
最高分            83.33           91.67           🧬 遗传算法
平均分            78.50           85.42           🧬 遗传算法
最低分            70.00           75.00           🧬 遗传算法
波动性(标准差)    5.21            3.12            🧬 遗传算法 (越小越稳定)

结论:
🏆 遗传算法胜出！最高分比随机搜索高 8.34 分
✅ 遗传算法通过进化机制，能够持续改进 Prompt 质量
✅ 遗传算法波动更小，更稳定可靠

📊 生成对比图表...
✅ 图表已保存到: algorithm_comparison.png
```

生成的图表会清晰展示：
- **左图（随机搜索）**：分数随机波动，无规律
- **右图（遗传算法）**：分数持续上升，进化趋势明显

---

## 🎯 参数调优指南

### 代数 (Generations)

- **3 代**：快速测试，成本低
- **5 代**：标准配置，效果好
- **10 代**：极致优化，成本高

**经验**：分数不再增长后可以提前停止

---

### 种群规模 (Population Size)

- **4-6**：小规模，适合预算有限
- **8-12**：标准规模，推荐
- **15-20**：大规模，覆盖更全面

**经验**：规模太小容易陷入局部最优，太大浪费资源

---

### 精英比例 (Elite Ratio)

- **0.1**：只保留 10% 最强者
- **0.2**：推荐值（保留 20%）
- **0.3-0.5**：保留更多，但进化动力不足

**经验**：0.2 是黄金比例

---

### 变异概率 (Mutation Rate)

- **0.1**：低变异，稳定但可能卡住
- **0.2**：推荐值（20% 概率）
- **0.3-0.5**：高变异，引入更多随机性

**经验**：0.2 能平衡稳定性和创新性

---

## 💡 最佳实践

### 推荐工作流程

```
1️⃣ 随机搜索（5-10次迭代）
    ↓ 快速探索，找到 70-80 分的 Prompt
    
2️⃣ 遗传算法（3-5代，种群8）
    ↓ 深度优化，冲刺到 90+ 分
    
3️⃣ 人工微调
    ↓ 根据实际需求调整细节
    
✅ 最终 Prompt
```

### 成本控制

**低预算场景**（< 100 次 API 调用）：
```python
# 只用随机搜索
iterations = 10
samples = 3
成本 = 10 × 3 = 30 次
```

**中等预算场景**（100-500 次）：
```python
# 随机搜索 + 小规模遗传算法
随机搜索: 10 × 3 = 30 次
遗传算法: 3 代 × 5 个体 × 3 样本 = 45 次
总计: 75 次
```

**高预算场景**（> 500 次）：
```python
# 大规模遗传算法
代数 = 10
种群 = 15
样本 = 8
成本 = 10 × 15 × 8 = 1200 次

推荐：先用简单数据测试，确认效果后再用完整数据集
```

---

## 🔬 进阶技巧

### 1. 自适应变异

根据进化停滞情况动态调整变异率：
```python
if best_score_unchanged_for_3_generations:
    mutation_rate = 0.5  # 增加变异，打破僵局
```

### 2. 多目标优化

同时优化准确率和速度：
```python
fitness = 0.7 * accuracy + 0.3 * (1 - response_time)
```

### 3. 混合策略

结合 LLM 重写实现高级变异：
```python
def llm_mutate(individual):
    """让 LLM 重写某个组件"""
    new_technique = llm.invoke(
        f"请把这条指令改写得更简洁：{individual['technique']}"
    )
    individual['technique'] = new_technique
    return individual
```

---

## ❓ 常见问题

### Q1: 遗传算法一定比随机搜索好吗？

**答**：不一定。
- **数据集简单**：两者差异不大（都接近 100 分）
- **数据集困难**：遗传算法明显更好
- **迭代次数少**：随机搜索可能运气好

**建议**：先对比测试，再决定使用哪个

---

### Q2: 为什么有时候遗传算法分数不增长？

**可能原因**：
1. **搜索空间太小**：只有 5×5×3 = 75 种组合
2. **已达到最优**：测试集太简单
3. **陷入局部最优**：增加变异率或重新初始化

**解决方案**：
- 扩大搜索空间（让 LLM 生成更多角色/风格）
- 增加变异概率
- 使用更困难的测试集

---

### Q3: 成本太高怎么办？

**降低成本的方法**：
1. **减少测试样本**：从 8 个减到 3 个
2. **减少代数**：从 10 代减到 3 代
3. **减小种群**：从 15 减到 5
4. **先用小模型测试**（如 llama-3.1-8b）

**示例**：
```python
# 最小成本配置
generations = 3
population = 4
samples = 2
成本 = 3 × 4 × 2 = 24 次 API 调用
```

---

### Q4: 如何判断遗传算法是否有效？

**观察指标**：
1. **进化曲线**：最高分是否持续上升
2. **进化增益**：最后一代比第一代高多少分
3. **波动性**：分数是否越来越稳定

**有效的表现**：
```
第1代: 最高 75, 平均 68
第2代: 最高 82, 平均 76  ✅ 上升
第3代: 最高 87, 平均 82  ✅ 继续上升
进化增益: +12 分 ✅ 明显提升
```

**无效的表现**：
```
第1代: 最高 90, 平均 85
第2代: 最高 90, 平均 86  ⚠️ 持平
第3代: 最高 90, 平均 87  ⚠️ 仍然持平
进化增益: 0 分 ❌ 无提升

原因：测试集太简单，第一代已经达到满分
```

---

## 📚 学术参考

遗传算法在 Prompt 优化中的应用源自以下研究：

1. **Evol-Instruct** (WizardLM)
   - 用进化算法生成高质量训练数据
   - 让 LLM 自己改写和优化 Prompt

2. **APO (Automatic Prompt Optimization)**
   - 系统化的 Prompt 自动优化框架
   - 结合遗传算法和 LLM 反馈

3. **PromptBreeder**
   - DeepMind 提出的 Prompt 进化系统
   - 使用变异和选择机制自动改进

---

## 🎉 总结

遗传算法是 Prompt 优化的强大工具：

✅ **持续进化**：越往后效果越好  
✅ **科学优化**：基于数据，而非人工猜测  
✅ **突破瓶颈**：通过变异发现新可能  

**推荐策略**：
- 🚀 **快速探索**：先用随机搜索
- 🔬 **深度打磨**：再用遗传算法
- 🎯 **人工微调**：最后精细调整

祝您找到完美的 Prompt！🎊
