"""
AI Prompt è‡ªåŠ¨ä¼˜åŒ–ç³»ç»Ÿ - Streamlit ç•Œé¢
"""
import streamlit as st
import os
from dotenv import load_dotenv
from optimizer import PromptOptimizer, OptimizedPrompt, ClassificationPrompt, SummarizationPrompt, TranslationPrompt
from nvidia_models import get_model_list
from metrics import MetricsCalculator

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="AI Prompt è‡ªåŠ¨ä¼˜åŒ–å¤§å¸ˆ",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰æ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 1rem;
    }
    .sub-header {
        color: #666;
        font-size: 1.1rem;
        margin-bottom: 2rem;
    }
    .stButton>button {
        width: 100%;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        color: white;
        font-weight: bold;
        border-radius: 10px;
        padding: 0.5rem 1rem;
        border: none;
    }
    .stButton>button:hover {
        background: linear-gradient(90deg, #764ba2 0%, #667eea 100%);
    }
    .technique-badge {
        display: inline-block;
        background-color: #e0e7ff;
        color: #4c51bf;
        padding: 0.25rem 0.75rem;
        border-radius: 15px;
        margin: 0.25rem;
        font-size: 0.9rem;
    }
    .keyword-badge {
        display: inline-block;
        background-color: #fef3c7;
        color: #d97706;
        padding: 0.25rem 0.75rem;
        border-radius: 15px;
        margin: 0.25rem;
        font-size: 0.9rem;
    }
</style>
""", unsafe_allow_html=True)

# æ ‡é¢˜åŒºåŸŸ
st.markdown('<p class="main-header">ğŸš€ AI Prompt è‡ªåŠ¨ä¼˜åŒ–å¤§å¸ˆ</p>', unsafe_allow_html=True)
st.markdown('<p class="sub-header">è¾“å…¥ç®€å•çš„æƒ³æ³•ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨åˆ©ç”¨ <b>ç»“æ„åŒ–æ¨¡æ¿ã€è¯­ä¹‰æ‰©å±•ã€å…³é”®è¯å¢å¼º</b> æŠ€æœ¯ä¸ºæ‚¨ç”Ÿæˆä¸“å®¶çº§ Prompt</p>', unsafe_allow_html=True)

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("âš™ï¸ ç³»ç»Ÿé…ç½®")
    
    # ä»»åŠ¡ç±»å‹é€‰æ‹©ï¼ˆæ–°å¢ï¼‰
    task_type = st.radio(
        "ğŸ“‹ ä»»åŠ¡ç±»å‹",
        ["ç”Ÿæˆä»»åŠ¡", "åˆ†ç±»ä»»åŠ¡", "æ‘˜è¦ä»»åŠ¡", "ç¿»è¯‘ä»»åŠ¡"],
        help="é€‰æ‹©è¦ä¼˜åŒ–çš„ Prompt ç±»å‹"
    )
    
    st.divider()
    
    # API æä¾›å•†é€‰æ‹©
    api_provider = st.selectbox(
        "ğŸ”Œ API æä¾›å•†",
        ["NVIDIA", "OpenAI"],
        index=0,
        help="é€‰æ‹©ä½¿ç”¨çš„ API æœåŠ¡æä¾›å•†"
    )
    
    st.divider()
    
    # æ ¹æ®æä¾›å•†æ˜¾ç¤ºä¸åŒçš„é…ç½®
    if api_provider == "NVIDIA":
        st.markdown("âœ¨ **NVIDIA API é…ç½®**")
        
        # åªåœ¨ç¯å¢ƒå˜é‡çœŸæœ‰æœ‰æ•ˆå€¼æ—¶æ‰ä½¿ç”¨
        env_key = os.getenv("NVIDIA_API_KEY", "")
        default_value = env_key if env_key and env_key.startswith("nvapi-") and len(env_key) > 10 else ""
        
        api_key_input = st.text_input(
            "NVIDIA API Key",
            type="password",
            value=default_value,
            help="ä» NVIDIA AI Endpoints è·å– API Key"
        )
        
        # API Key éªŒè¯æç¤º
        if api_key_input:
            if not api_key_input.startswith("nvapi-"):
                st.warning("âš ï¸ NVIDIA API Key åº”è¯¥ä»¥ 'nvapi-' å¼€å¤´")
            else:
                st.success("âœ… API Key æ ¼å¼æ­£ç¡®")
        else:
            st.error("ğŸ”‘ è¯·è¾“å…¥ NVIDIA API Key")
            st.info("ğŸ’¡ **è·å–å…è´¹ API Key**ï¼š[NVIDIA Build](https://build.nvidia.com/) â†’ ç™»å½• â†’ é€‰æ‹©æ¨¡å‹ â†’ Get API Key")
        
        base_url = st.text_input(
            "NVIDIA Base URL",
            value=os.getenv("NVIDIA_BASE_URL", "https://integrate.api.nvidia.com/v1"),
            help="NVIDIA API ç«¯ç‚¹"
        )
        
        # NVIDIA æ¨¡å‹é€‰æ‹©ï¼ˆä½¿ç”¨å®Œæ•´æ¨¡å‹åˆ—è¡¨ï¼‰
        nvidia_models = get_model_list("æ¨èæ¨¡å‹")
        
        model_choice = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            nvidia_models,
            index=0,
            help="æ¨èä½¿ç”¨ Llama 3.1 405B æˆ– Mistral Large ä»¥è·å¾—æœ€ä½³ä¼˜åŒ–æ•ˆæœ"
        )
        
        # é«˜çº§é€‰é¡¹ï¼šæ˜¾ç¤ºæ‰€æœ‰æ¨¡å‹
        with st.expander("ğŸ”§ æŸ¥çœ‹æ‰€æœ‰å¯ç”¨æ¨¡å‹", expanded=False):
            all_models = get_model_list("all")
            st.info(f"å…±æœ‰ {len(all_models)} ä¸ªå¯ç”¨æ¨¡å‹")
            model_choice_advanced = st.selectbox(
                "ä»å…¨éƒ¨æ¨¡å‹ä¸­é€‰æ‹©",
                all_models,
                key="advanced_model"
            )
            if st.button("ä½¿ç”¨æ­¤æ¨¡å‹"):
                model_choice = model_choice_advanced
                st.success(f"å·²åˆ‡æ¢åˆ°ï¼š{model_choice}")

        
    else:  # OpenAI
        st.markdown("âœ¨ **OpenAI API é…ç½®**")
        
        # åªåœ¨ç¯å¢ƒå˜é‡çœŸæœ‰æœ‰æ•ˆå€¼æ—¶æ‰ä½¿ç”¨
        env_key = os.getenv("OPENAI_API_KEY", "")
        default_value = env_key if env_key and env_key.startswith("sk-") and len(env_key) > 10 else ""
        
        api_key_input = st.text_input(
            "OpenAI API Key",
            type="password",
            value=default_value,
            help="ä» OpenAI å®˜ç½‘è·å– API Key"
        )
        
        # API Key éªŒè¯æç¤º
        if api_key_input:
            if not api_key_input.startswith("sk-"):
                st.warning("âš ï¸ OpenAI API Key åº”è¯¥ä»¥ 'sk-' å¼€å¤´")
            else:
                st.success("âœ… API Key æ ¼å¼æ­£ç¡®")
        else:
            st.error("ğŸ”‘ è¯·è¾“å…¥ OpenAI API Key")
            st.info("ğŸ’¡ **è·å– API Key**ï¼š[OpenAI Platform](https://platform.openai.com/) â†’ API Keys")
        
        base_url = st.text_input(
            "API Base URL (å¯é€‰)",
            value=os.getenv("OPENAI_BASE_URL", ""),
            help="å¦‚ä½¿ç”¨ä»£ç†æˆ–ç¬¬ä¸‰æ–¹æœåŠ¡ï¼Œè¯·å¡«å†™å®Œæ•´çš„ base URL"
        )
        
        model_choice = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            ["gpt-4o", "gpt-4o-mini", "gpt-4-turbo", "gpt-3.5-turbo"],
            index=0,
            help="æ¨èä½¿ç”¨ GPT-4o ä»¥è·å¾—æœ€ä½³ä¼˜åŒ–æ•ˆæœ"
        )
    
    # ä¼˜åŒ–æ¨¡å¼ï¼ˆä»…ç”Ÿæˆä»»åŠ¡æ˜¾ç¤ºï¼‰
    if task_type == "ç”Ÿæˆä»»åŠ¡":
        optimization_mode = st.selectbox(
            "ğŸ¯ ä¼˜åŒ–æ¨¡å¼",
            [
                "é€šç”¨å¢å¼º (General)",
                "ä»£ç ç”Ÿæˆ (Coding)",
                "åˆ›æ„å†™ä½œ (Creative)",
                "å­¦æœ¯åˆ†æ (Academic)"
            ],
            help="æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©åˆé€‚çš„ä¼˜åŒ–ç­–ç•¥"
        )
    
    st.divider()
    
    # ä½¿ç”¨è¯´æ˜
    with st.expander("ğŸ“– ä½¿ç”¨è¯´æ˜", expanded=False):
        st.markdown("""
        **å¿«é€Ÿä¸Šæ‰‹**ï¼š
        1. åœ¨å·¦ä¾§è¾“å…¥æ‚¨çš„ API Key
        2. åœ¨ä¸»ç•Œé¢è¾“å…¥ç®€å•çš„ Prompt
        3. ï¼ˆå¯é€‰ï¼‰æ·»åŠ åœºæ™¯æè¿°
        4. ç‚¹å‡»"å¼€å§‹é­”æ³•ä¼˜åŒ–"
        
        **ä¼˜åŒ–æ¨¡å¼è¯´æ˜**ï¼š
        - **é€šç”¨å¢å¼º**ï¼šé€‚ç”¨äºå„ç±»æ—¥å¸¸ä»»åŠ¡
        - **ä»£ç ç”Ÿæˆ**ï¼šä¸“é—¨ä¼˜åŒ–ç¼–ç¨‹ç›¸å…³ä»»åŠ¡
        - **åˆ›æ„å†™ä½œ**ï¼šæ–‡æ¡ˆã€æ•…äº‹ã€è¥é”€å†…å®¹
        - **å­¦æœ¯åˆ†æ**ï¼šç ”ç©¶ã€è®ºæ–‡ã€æ•°æ®åˆ†æ
        
        **æ ¸å¿ƒæŠ€æœ¯**ï¼š
        - ğŸ” è¯­ä¹‰æ‰©å±•ï¼šè¡¥å……éšå«éœ€æ±‚
        - ğŸ¯ å…³é”®è¯å¢å¼ºï¼šåŠ å…¥ä¸“ä¸šæœ¯è¯­
        - ğŸ“ æ¨¡æ¿åº”ç”¨ï¼šCO-STAR/BROKE æ¡†æ¶
        """)
    
    # ç¤ºä¾‹ Prompt
    with st.expander("ğŸ’¡ ç¤ºä¾‹ Prompt", expanded=False):
        st.markdown("""
        **ä»£ç ç±»**ï¼š
        - "å†™ä¸ªè´ªåƒè›‡æ¸¸æˆ"
        - "å¸®æˆ‘å®ç°ä¸€ä¸ªç™»å½•ç³»ç»Ÿ"
        
        **æ–‡æ¡ˆç±»**ï¼š
        - "å†™ä¸ªäº§å“ä»‹ç»"
        - "åˆ›ä½œä¸€ä¸ªå“ç‰Œæ•…äº‹"
        
        **åˆ†æç±»**ï¼š
        - "åˆ†æå¸‚åœºè¶‹åŠ¿"
        - "æ€»ç»“è®ºæ–‡è¦ç‚¹"
        """)

# åˆå§‹åŒ– session state
if 'result' not in st.session_state:
    st.session_state.result = None
if 'comparison_done' not in st.session_state:
    st.session_state.comparison_done = False
if 'comparison_results' not in st.session_state:
    st.session_state.comparison_results = None
if 'classification_result' not in st.session_state:
    st.session_state.classification_result = None
if 'summarization_result' not in st.session_state:
    st.session_state.summarization_result = None
if 'translation_result' not in st.session_state:
    st.session_state.translation_result = None

# ä¸»ç•Œé¢å¸ƒå±€
col1, col2 = st.columns([1, 1])

# ========== æ ¹æ®ä»»åŠ¡ç±»å‹æ˜¾ç¤ºä¸åŒç•Œé¢ ==========
if task_type == "ç”Ÿæˆä»»åŠ¡":
    with col1:
        st.subheader("ğŸ“ åŸå§‹è¾“å…¥")
        
        # ç”¨æˆ·è¾“å…¥åŒºåŸŸ
        user_input = st.text_area(
            "è¾“å…¥æ‚¨çš„ç®€å• Prompt",
            height=150,
            placeholder="ä¾‹å¦‚ï¼šå¸®æˆ‘å†™ä¸ªè´ªåƒè›‡æ¸¸æˆ",
            help="æè¿°æ‚¨æƒ³åšä»€ä¹ˆï¼Œå¯ä»¥å¾ˆç®€å•"
        )
        
        scene_input = st.text_input(
            "åœºæ™¯/è¡¥å……æè¿°ï¼ˆå¯é€‰ï¼‰",
            placeholder="ä¾‹å¦‚ï¼šPython, ç»™å°å­©å­¦ç¼–ç¨‹ç”¨",
            help="æä¾›æ›´å¤šèƒŒæ™¯ä¿¡æ¯ï¼Œå¦‚ç¼–ç¨‹è¯­è¨€ã€ç›®æ ‡å—ä¼—ç­‰"
        )
        
        # ä¼˜åŒ–æŒ‰é’®
        start_btn = st.button("âœ¨ å¼€å§‹é­”æ³•ä¼˜åŒ–", type="primary", use_container_width=True)

    # ç”Ÿæˆä»»åŠ¡ä¼˜åŒ–é€»è¾‘
    if start_btn:
        if not user_input or user_input.strip() == "":
            st.error("âŒ è¯·å…ˆè¾“å…¥ Prompt")
        elif not api_key_input or api_key_input.strip() == "":
            st.error("âŒ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® API Key")
        else:
            with st.spinner("ğŸ”® æ­£åœ¨åˆ†æè¯­ä¹‰ã€æå–å…³é”®è¯ã€æ„å»ºç»“æ„åŒ–æ¨¡æ¿..."):
                try:
                    # åˆ›å»ºä¼˜åŒ–å™¨
                    optimizer = PromptOptimizer(
                        api_key=api_key_input,
                        model=model_choice,
                        base_url=base_url if base_url else None,
                        provider=api_provider.lower()
                    )
                    
                    # æ‰§è¡Œä¼˜åŒ–
                    result = optimizer.optimize(
                        user_prompt=user_input,
                        scene_desc=scene_input,
                        optimization_mode=optimization_mode
                    )
                    
                    # ä¿å­˜ç»“æœåˆ° session state
                    st.session_state.result = result
                    st.session_state.comparison_done = False
                    st.session_state.comparison_results = None
                    
                    st.success("âœ… ä¼˜åŒ–å®Œæˆï¼")
                    
                except Exception as e:
                    error_msg = str(e)
                    st.error(f"âŒ ä¼˜åŒ–å¤±è´¥ï¼š{error_msg}")
                    
                    # æ ¹æ®é”™è¯¯ç±»å‹æä¾›å…·ä½“çš„è§£å†³æ–¹æ¡ˆ
                    if "404" in error_msg or "401" in error_msg:
                        st.warning("""**å¯èƒ½çš„åŸå› å’Œè§£å†³æ–¹æ¡ˆï¼š**""")
                        if api_provider == "NVIDIA":
                            st.markdown("""
                            1. **API Key æ— æ•ˆæˆ–æœªé…ç½®**
                               - è¯·è®¿é—® [NVIDIA Build](https://build.nvidia.com/) è·å– API Key
                               - ç¡®ä¿ API Key æ ¼å¼æ­£ç¡®ï¼ˆä»¥ `nvapi-` å¼€å¤´ï¼‰
                               - åœ¨ä¾§è¾¹æ è¾“å…¥æœ‰æ•ˆçš„ API Key
                            
                            2. **æ¨¡å‹åç§°ä¸æ­£ç¡®**
                               - è¯·ä»ä¸‹æ‹‰åˆ—è¡¨ä¸­é€‰æ‹©æ¨¡å‹
                               - ä¸è¦æ‰‹åŠ¨è¾“å…¥æ¨¡å‹åç§°
                            
                            3. **ç½‘ç»œé—®é¢˜**
                               - NVIDIA API å¯èƒ½éœ€è¦ç§‘å­¦ä¸Šç½‘
                               - æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸
                            """)
                        else:
                            st.markdown("""
                            1. **API Key æ— æ•ˆ**
                               - è¯·è®¿é—® [OpenAI Platform](https://platform.openai.com/) æ£€æŸ¥ API Key
                               - ç¡®ä¿è´¦æˆ·æœ‰è¶³å¤Ÿä½™é¢
                            
                            2. **Base URL é…ç½®é”™è¯¯**
                               - å¦‚æœä½¿ç”¨ä»£ç†ï¼Œè¯·æ£€æŸ¥ Base URL æ˜¯å¦æ­£ç¡®
                            """)
                    elif "rate_limit" in error_msg.lower():
                        st.info("ğŸ’¡ API è¯·æ±‚é¢‘ç‡è¶…é™ï¼Œè¯·ç­‰å¾…å‡ ç§’åé‡è¯•")
                    else:
                        st.info("ğŸ’¡ æç¤ºï¼šè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œ API é…ç½®")
                    
                    # æä¾›æµ‹è¯•è¿æ¥çš„å»ºè®®
                    st.info("ğŸ”§ å»ºè®®ï¼šè¿è¡Œ `python test_nvidia.py` æµ‹è¯• API è¿æ¥")

    # ç”Ÿæˆä»»åŠ¡ç»“æœå±•ç¤ºåŒºåŸŸ
    if st.session_state.result:
        result = st.session_state.result
        
        with col2:
            st.subheader("ğŸŒŸ ä¼˜åŒ–ç»“æœ")
        
        # ä¼˜åŒ–æ€è·¯å±•ç¤º
        with st.expander("ğŸ§  æŸ¥çœ‹ä¼˜åŒ–æ€è·¯ (Thinking Process)", expanded=True):
            st.write(result.thinking_process)
            
            # åº”ç”¨çš„æŠ€æœ¯
            st.markdown("**ğŸ› ï¸ åº”ç”¨çš„ä¼˜åŒ–æŠ€æœ¯ï¼š**")
            techniques_html = "".join([
                f'<span class="technique-badge">{tech}</span>'
                for tech in result.enhancement_techniques
            ])
            st.markdown(techniques_html, unsafe_allow_html=True)
            
            # æ–°å¢çš„å…³é”®è¯
            if result.keywords_added:
                st.markdown("**ğŸ”‘ æ–°å¢çš„å…³é”®è¯ï¼š**")
                keywords_html = "".join([
                    f'<span class="keyword-badge">{kw}</span>'
                    for kw in result.keywords_added
                ])
                st.markdown(keywords_html, unsafe_allow_html=True)
            
            # åº”ç”¨çš„æ¡†æ¶
            st.markdown(f"**ğŸ“ åº”ç”¨çš„æ¡†æ¶ï¼š** `{result.structure_applied}`")
        
        # ä¼˜åŒ–åçš„ Prompt
        st.markdown("**âœ¨ ä¼˜åŒ–åçš„ Promptï¼ˆå¯ç›´æ¥å¤åˆ¶ï¼‰ï¼š**")
        st.text_area(
            "ä¼˜åŒ–ç»“æœ",
            value=result.improved_prompt,
            height=300,
            label_visibility="collapsed"
        )
        
        # å¤åˆ¶æŒ‰é’®
        if st.button("ğŸ“‹ å¤åˆ¶åˆ°å‰ªè´´æ¿", use_container_width=True):
            st.code(result.improved_prompt, language=None)
            st.success("âœ… å·²æ˜¾ç¤ºåœ¨ä»£ç æ¡†ä¸­ï¼Œè¯·æ‰‹åŠ¨å¤åˆ¶")

# A/B å¯¹æ¯”æµ‹è¯•åŒºåŸŸ
if st.session_state.result:
    st.divider()
    st.subheader("ğŸ”¬ A/B æ•ˆæœå¯¹æ¯”æµ‹è¯•")
    st.markdown("*è®© AI åˆ†åˆ«ä½¿ç”¨åŸå§‹ Prompt å’Œä¼˜åŒ–åçš„ Prompt æ‰§è¡Œä»»åŠ¡ï¼Œç›´è§‚å¯¹æ¯”ä¼˜åŒ–æ•ˆæœ*")
    
    col_test1, col_test2, col_test3 = st.columns([2, 1, 2])
    
    with col_test2:
        if st.button("ğŸš€ è¿è¡Œå¯¹æ¯”æµ‹è¯•", type="primary", use_container_width=True):
            if not st.session_state.comparison_done:
                with st.spinner("â³ æ­£åœ¨è¿è¡Œä¸¤ä¸ªç‰ˆæœ¬çš„ Promptï¼Œè¯·ç¨å€™..."):
                    try:
                        optimizer = PromptOptimizer(
                            api_key=api_key_input,
                            model=model_choice,
                            base_url=base_url if base_url else None,
                            provider=api_provider.lower()
                        )
                        
                        res_orig, res_opt = optimizer.compare_results(
                            original_prompt=user_input,
                            optimized_prompt=result.improved_prompt
                        )
                        
                        st.session_state.comparison_results = (res_orig, res_opt)
                        st.session_state.comparison_done = True
                        
                    except Exception as e:
                        st.error(f"âŒ å¯¹æ¯”æµ‹è¯•å¤±è´¥ï¼š{str(e)}")
    
    # æ˜¾ç¤ºå¯¹æ¯”ç»“æœ
    if st.session_state.comparison_done and st.session_state.comparison_results:
        res_orig, res_opt = st.session_state.comparison_results
        
        col_result1, col_result2 = st.columns(2)
        
        with col_result1:
            st.markdown("#### ğŸ“„ åŸå§‹ Prompt äº§å‡º")
            st.info(res_orig)
            
        with col_result2:
            st.markdown("#### âœ¨ ä¼˜åŒ–å Prompt äº§å‡º")
            st.success(res_opt)

# ========== åˆ†ç±»ä»»åŠ¡ç•Œé¢ ==========
elif task_type == "åˆ†ç±»ä»»åŠ¡":
    with col1:
        st.subheader("ğŸ·ï¸ åˆ†ç±»ä»»åŠ¡é…ç½®")
        st.info("ğŸ“Œ åˆ†ç±»ä»»åŠ¡éœ€è¦æ˜ç¡®çš„æ ‡ç­¾å®šä¹‰å’Œç¤ºä¾‹ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨ç”Ÿæˆè¿™äº›è¦ç´ ã€‚")
        
        # ä»»åŠ¡æè¿°
        task_description = st.text_area(
            "ä»»åŠ¡æè¿°",
            height=100,
            placeholder="ä¾‹å¦‚ï¼šåˆ¤æ–­ç”¨æˆ·è¯„è®ºçš„æƒ…æ„Ÿå€¾å‘\næˆ–ï¼šè¯†åˆ«å®¢æœå¯¹è¯ä¸­çš„ç”¨æˆ·æ„å›¾",
            help="æ¸…æ™°æè¿°è¿™æ˜¯ä¸€ä¸ªä»€ä¹ˆæ ·çš„åˆ†ç±»ä»»åŠ¡"
        )
        
        # æ ‡ç­¾è¾“å…¥
        labels_input = st.text_input(
            "ç›®æ ‡æ ‡ç­¾ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰",
            placeholder="ä¾‹å¦‚ï¼šPositive, Negative, Neutral",
            help="è¾“å…¥æ‰€æœ‰å¯èƒ½çš„åˆ†ç±»æ ‡ç­¾ï¼Œç”¨é€—å·åˆ†éš”"
        )
        
        # å¯é€‰ï¼šç¤ºä¾‹æ–‡æœ¬
        with st.expander("ğŸ’¡ æä¾›ç¤ºä¾‹æ–‡æœ¬ï¼ˆå¯é€‰ï¼‰", expanded=False):
            st.caption("å¦‚æœæä¾›ç¤ºä¾‹ï¼Œç³»ç»Ÿä¼šåŸºäºè¿™äº›ç¤ºä¾‹ç”Ÿæˆ Few-Shot æ ·æœ¬")
            example_text_1 = st.text_input("ç¤ºä¾‹ 1ï¼ˆå¯é€‰ï¼‰", placeholder="ä¾‹å¦‚ï¼šè¿™ä¸ªäº§å“å¤ªæ£’äº†ï¼")
            example_text_2 = st.text_input("ç¤ºä¾‹ 2ï¼ˆå¯é€‰ï¼‰", placeholder="ä¾‹å¦‚ï¼šè´¨é‡å¾ˆå·®ï¼Œä¸æ¨èè´­ä¹°")
            example_text_3 = st.text_input("ç¤ºä¾‹ 3ï¼ˆå¯é€‰ï¼‰", placeholder="ä¾‹å¦‚ï¼šä¸€èˆ¬èˆ¬ï¼Œæ²¡ä»€ä¹ˆç‰¹åˆ«çš„")
        
        # æ„å»ºåˆ†ç±»å™¨æŒ‰é’®
        build_btn = st.button("ğŸ”¨ æ„å»ºåˆ†ç±»å™¨ Prompt", type="primary", use_container_width=True)
    
    # åˆ†ç±»ä»»åŠ¡ä¼˜åŒ–é€»è¾‘
    if build_btn:
        if not task_description or not labels_input:
            st.error("âŒ è¯·å¡«å†™ä»»åŠ¡æè¿°å’Œç›®æ ‡æ ‡ç­¾ï¼")
        elif not api_key_input or api_key_input.strip() == "":
            st.error("âŒ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® API Key")
        else:
            # è§£ææ ‡ç­¾
            labels_list = [label.strip() for label in labels_input.split(",") if label.strip()]
            
            if len(labels_list) < 2:
                st.error("âŒ è‡³å°‘éœ€è¦ 2 ä¸ªæ ‡ç­¾")
            else:
                with st.spinner("ğŸ”® æ­£åœ¨ç”Ÿæˆæ ‡ç­¾å®šä¹‰ã€åˆæˆè®­ç»ƒæ ·æœ¬ã€æ„å»ºåˆ†ç±»å™¨..."):
                    try:
                        # åˆ›å»ºä¼˜åŒ–å™¨
                        optimizer = PromptOptimizer(
                            api_key=api_key_input,
                            model=model_choice,
                            base_url=base_url if base_url else None,
                            provider=api_provider.lower()
                        )
                        
                        # æ”¶é›†ç¤ºä¾‹æ–‡æœ¬
                        example_texts = []
                        if example_text_1:
                            example_texts.append(example_text_1)
                        if example_text_2:
                            example_texts.append(example_text_2)
                        if example_text_3:
                            example_texts.append(example_text_3)
                        
                        # æ‰§è¡Œåˆ†ç±»ä»»åŠ¡ä¼˜åŒ–
                        result = optimizer.optimize_classification(
                            task_description=task_description,
                            labels=labels_list,
                            example_texts=example_texts if example_texts else None
                        )
                        
                        # ä¿å­˜ç»“æœ
                        st.session_state.classification_result = result
                        
                        st.success("âœ… åˆ†ç±»å™¨ Prompt æ„å»ºå®Œæˆï¼")
                        
                    except Exception as e:
                        error_msg = str(e)
                        st.error(f"âŒ æ„å»ºå¤±è´¥ï¼š{error_msg}")
                        
                        # æä¾›è§£å†³æ–¹æ¡ˆ
                        if "404" in error_msg or "401" in error_msg:
                            st.warning("""**å¯èƒ½çš„åŸå› å’Œè§£å†³æ–¹æ¡ˆï¼š**""")
                            if api_provider == "NVIDIA":
                                st.markdown("""
                                1. **API Key æ— æ•ˆæˆ–æœªé…ç½®**
                                   - è¯·è®¿é—® [NVIDIA Build](https://build.nvidia.com/) è·å– API Key
                                2. **æ¨¡å‹ä¸æ”¯æŒ**
                                   - æ¨èä½¿ç”¨ meta/llama-3.1-405b-instruct
                                """)
                        
                        st.info("ğŸ”§ å»ºè®®ï¼šè¿è¡Œ `python test_nvidia.py` æµ‹è¯• API è¿æ¥")
    
    # æ˜¾ç¤ºåˆ†ç±»ä»»åŠ¡ä¼˜åŒ–ç»“æœ
    if st.session_state.classification_result:
        result = st.session_state.classification_result
        
        with col2:
            st.subheader("ğŸ¯ åˆ†ç±»å™¨ Prompt")
            
            # 1. ä¼˜åŒ–æ€è·¯
            with st.expander("ğŸ§  æŸ¥çœ‹ä¼˜åŒ–æ€è·¯", expanded=True):
                st.write(result.thinking_process)
            
            # 2. è§’è‰²å®šä¹‰
            with st.expander("ğŸ‘¤ è§’è‰²è®¾å®š", expanded=False):
                st.info(result.role_definition)
            
            # 3. æ ‡ç­¾å®šä¹‰
            with st.expander("ğŸ·ï¸ æ ‡ç­¾è¯¦ç»†å®šä¹‰", expanded=True):
                for label, definition in result.label_definitions.items():
                    st.markdown(f"**{label}**")
                    st.write(definition)
                    st.divider()
                st.caption("ğŸ’¡ ç³»ç»Ÿè‡ªåŠ¨è¡¥å……äº†æ¯ä¸ªæ ‡ç­¾çš„å…·ä½“æ ‡å‡†ï¼Œé˜²æ­¢æ¨¡å‹æ··æ·†ã€‚")
            
            # 4. Few-Shot ç¤ºä¾‹
            with st.expander("ğŸ“ è‡ªåŠ¨åˆæˆçš„ Few-Shot ç¤ºä¾‹", expanded=True):
                for idx, example in enumerate(result.few_shot_examples, 1):
                    st.markdown(f"**ç¤ºä¾‹ {idx}:**")
                    st.code(f"Input: {example.get('input', example.get('text', 'N/A'))}\nLabel: {example.get('label', 'N/A')}")
                st.caption("ğŸ’¡ è¿™äº›ç¤ºä¾‹å¸®åŠ©æ¨¡å‹ç†è§£åˆ†ç±»æ ‡å‡†")
            
            # 5. æ€ç»´é“¾å¼•å¯¼
            with st.expander("ğŸ§  æ€ç»´é“¾å¼•å¯¼", expanded=False):
                st.write(result.reasoning_guidance)
            
            # 6. è¾“å‡ºæ ¼å¼
            with st.expander("ğŸ“ è¾“å‡ºæ ¼å¼è¦æ±‚", expanded=False):
                st.code(result.output_format)
            
            # 7. æœ€ç»ˆ Prompt
            st.markdown("**âœ¨ æœ€ç»ˆå®Œæ•´çš„åˆ†ç±» Promptï¼ˆå¯ç›´æ¥å¤åˆ¶ï¼‰ï¼š**")
            st.text_area(
                "åˆ†ç±»å™¨ Prompt",
                value=result.final_prompt,
                height=400,
                label_visibility="collapsed"
            )
            
            # å¤åˆ¶æŒ‰é’®
            if st.button("ğŸ“‹ å¤åˆ¶åˆ°å‰ªè´´æ¿", use_container_width=True, key="copy_classification"):
                st.code(result.final_prompt, language=None)
                st.success("âœ… å·²æ˜¾ç¤ºåœ¨ä»£ç æ¡†ä¸­ï¼Œè¯·æ‰‹åŠ¨å¤åˆ¶")

elif task_type == "æ‘˜è¦ä»»åŠ¡":
    with col1:
        st.subheader("ğŸ“„ æ‘˜è¦ä»»åŠ¡é…ç½®")
        st.info("ğŸ“Œ æ‘˜è¦ä»»åŠ¡éœ€è¦æ˜ç¡®ä¿¡æ¯æå–è§„åˆ™ï¼Œç³»ç»Ÿå°†è®¾è®¡æœ€ä¼˜çš„æå–ç­–ç•¥ã€‚")
        
        # ä»»åŠ¡æè¿°
        task_description = st.text_area(
            "ä»»åŠ¡æè¿°",
            height=100,
            placeholder="ä¾‹å¦‚ï¼šæ€»ç»“æŠ€æœ¯ä¼šè®®çš„æ ¸å¿ƒå†³ç­–å’Œè¡ŒåŠ¨è®¡åˆ’\næˆ–ï¼šæå–å­¦æœ¯è®ºæ–‡çš„ç ”ç©¶è´¡çŒ®å’Œåˆ›æ–°ç‚¹",
            help="æ¸…æ™°æè¿°æ‘˜è¦çš„ç›®çš„"
        )
        
        # æºæ–‡æœ¬ç±»å‹
        source_type = st.selectbox(
            "ğŸ“ æºæ–‡æœ¬ç±»å‹",
            [
                "ä¼šè®®è®°å½•",
                "å­¦æœ¯è®ºæ–‡",
                "æ–°é—»æŠ¥é“",
                "æŠ€æœ¯æ–‡æ¡£",
                "å®¢æˆ·åé¦ˆ",
                "äº§å“è¯„è®º",
                "ç ”ç©¶æŠ¥å‘Š",
                "é‚®ä»¶å†…å®¹",
                "å…¶ä»–"
            ],
            help="é€‰æ‹©éœ€è¦æ‘˜è¦çš„æ–‡æœ¬ç±»å‹"
        )
        
        # ç›®æ ‡å—ä¼—
        target_audience = st.text_input(
            "ğŸ‘¥ ç›®æ ‡å—ä¼—",
            placeholder="ä¾‹å¦‚ï¼šæŠ€æœ¯ç»ç†ã€ç ”å‘æ€»ç›‘ã€æ™®é€šç”¨æˆ·ã€æŠ•èµ„äºº",
            help="æ‘˜è¦å°†å‘ˆç°ç»™è°çœ‹ï¼Ÿè¿™ä¼šå½±å“è¯­è¨€é£æ ¼å’Œè¯¦ç»†ç¨‹åº¦"
        )
        
        # æ ¸å¿ƒå…³æ³¨ç‚¹
        focus_points = st.text_area(
            "ğŸ¯ æ ¸å¿ƒå…³æ³¨ç‚¹",
            height=100,
            placeholder="ä¾‹å¦‚ï¼š\n- Bug çš„æ ¹æœ¬åŸå› \n- æå‡ºçš„è§£å†³æ–¹æ¡ˆ\n- è´Ÿè´£äººå’Œæˆªæ­¢æ—¶é—´\n- èµ„æºéœ€æ±‚",
            help="æ‘˜è¦ä¸­å¿…é¡»ä¿ç•™å“ªäº›ä¿¡æ¯ï¼Ÿ"
        )
        
        # ç¯‡å¹…é™åˆ¶ï¼ˆå¯é€‰ï¼‰
        with st.expander("ğŸ“ ç¯‡å¹…é™åˆ¶ï¼ˆå¯é€‰ï¼‰", expanded=False):
            length_constraint = st.selectbox(
                "æ‘˜è¦é•¿åº¦",
                ["ä¸é™åˆ¶", "100å­—ä»¥å†…", "200å­—ä»¥å†…", "3-5ä¸ªè¦ç‚¹", "æ¯ä¸ªå…³æ³¨ç‚¹ä¸è¶…è¿‡50å­—"],
                help="æ§åˆ¶æ‘˜è¦çš„ç¯‡å¹…"
            )
            if length_constraint == "ä¸é™åˆ¶":
                length_constraint = None
        
        # æ„å»ºæ‘˜è¦å™¨æŒ‰é’®
        build_summarization_btn = st.button("ğŸ”¨ æ„å»ºæ‘˜è¦å™¨ Prompt", type="primary", use_container_width=True)
    
    # æ‘˜è¦ä»»åŠ¡ä¼˜åŒ–é€»è¾‘
    if build_summarization_btn:
        if not task_description or not target_audience or not focus_points:
            st.error("âŒ è¯·å¡«å†™ä»»åŠ¡æè¿°ã€ç›®æ ‡å—ä¼—å’Œæ ¸å¿ƒå…³æ³¨ç‚¹ï¼")
        elif not api_key_input or api_key_input.strip() == "":
            st.error("âŒ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® API Key")
        else:
            with st.spinner("ğŸ”® æ­£åœ¨ç”Ÿæˆæå–è§„åˆ™ã€è®¾è®¡è¾“å‡ºæ ¼å¼ã€æ„å»ºæ‘˜è¦å™¨..."):
                try:
                    # åˆ›å»ºä¼˜åŒ–å™¨
                    optimizer = PromptOptimizer(
                        api_key=api_key_input,
                        model=model_choice,
                        base_url=base_url if base_url else None,
                        provider=api_provider.lower()
                    )
                    
                    # æ‰§è¡Œæ‘˜è¦ä»»åŠ¡ä¼˜åŒ–
                    result = optimizer.optimize_summarization(
                        task_description=task_description,
                        source_type=source_type,
                        target_audience=target_audience,
                        focus_points=focus_points,
                        length_constraint=length_constraint
                    )
                    
                    # ä¿å­˜ç»“æœ
                    st.session_state.summarization_result = result
                    
                    st.success("âœ… æ‘˜è¦å™¨ Prompt æ„å»ºå®Œæˆï¼")
                    
                except Exception as e:
                    error_msg = str(e)
                    st.error(f"âŒ æ„å»ºå¤±è´¥ï¼š{error_msg}")
                    
                    # æä¾›è§£å†³æ–¹æ¡ˆ
                    if "404" in error_msg or "401" in error_msg:
                        st.warning("""**å¯èƒ½çš„åŸå› å’Œè§£å†³æ–¹æ¡ˆï¼š**""")
                        if api_provider == "NVIDIA":
                            st.markdown("""
                            1. **API Key æ— æ•ˆæˆ–æœªé…ç½®**
                               - è¯·è®¿é—® [NVIDIA Build](https://build.nvidia.com/) è·å– API Key
                            2. **æ¨¡å‹ä¸æ”¯æŒ**
                               - æ¨èä½¿ç”¨ meta/llama-3.1-405b-instruct
                            """)
                    
                    st.info("ğŸ”§ å»ºè®®ï¼šè¿è¡Œ `python test_nvidia.py` æµ‹è¯• API è¿æ¥")
    
    # æ˜¾ç¤ºæ‘˜è¦ä»»åŠ¡ä¼˜åŒ–ç»“æœ
    if st.session_state.summarization_result:
        result = st.session_state.summarization_result
        
        with col2:
            st.subheader("ğŸ“ æ‘˜è¦å™¨ Prompt")
            
            # 1. ä¼˜åŒ–æ€è·¯
            with st.expander("ğŸ§  æŸ¥çœ‹ä¼˜åŒ–æ€è·¯", expanded=True):
                st.write(result.thinking_process)
            
            # 2. è§’è‰²è®¾å®š
            with st.expander("ğŸ‘¤ è§’è‰²è®¾å®š", expanded=False):
                st.info(result.role_setting)
            
            # 3. æå–è§„åˆ™
            with st.expander("ğŸ“‹ ä¿¡æ¯æå–è§„åˆ™", expanded=True):
                for idx, rule in enumerate(result.extraction_rules, 1):
                    st.markdown(f"**è§„åˆ™ {idx}:** {rule}")
                st.caption("ğŸ’¡ æ˜ç¡®çš„æå–è§„åˆ™å¸®åŠ©æ¨¡å‹è¯†åˆ«å…³é”®ä¿¡æ¯")
            
            # 4. è´Ÿé¢çº¦æŸ
            with st.expander("ğŸš« è´Ÿé¢çº¦æŸï¼ˆé˜²æ­¢æ¨¡å‹å¹»è§‰ï¼‰", expanded=True):
                for idx, constraint in enumerate(result.negative_constraints, 1):
                    st.markdown(f"**çº¦æŸ {idx}:** {constraint}")
                st.caption("ğŸ’¡ å‘Šè¯‰æ¨¡å‹ã€Œä¸è¦åšä»€ä¹ˆã€ï¼Œé˜²æ­¢æ·»åŠ åŸæ–‡æ²¡æœ‰çš„å†…å®¹")
            
            # 5. è¾“å‡ºæ ¼å¼
            with st.expander("ğŸ“ è¾“å‡ºæ ¼å¼æ¨¡æ¿", expanded=True):
                st.markdown(result.format_template)
                st.caption("ğŸ’¡ ç»“æ„åŒ–æ ¼å¼è®©æ‘˜è¦æ›´æ¸…æ™°æ˜“è¯»")
            
            # 6. å¤„ç†æ­¥éª¤
            with st.expander("ğŸ”„ æ€è€ƒæ­¥éª¤å¼•å¯¼", expanded=False):
                st.write(result.step_by_step_guide)
            
            # 7. å…³æ³¨ç‚¹
            with st.expander("ğŸ¯ æ ¸å¿ƒå…³æ³¨é¢†åŸŸ", expanded=False):
                for idx, area in enumerate(result.focus_areas, 1):
                    st.markdown(f"**å…³æ³¨ç‚¹ {idx}:** {area}")
            
            # 8. æœ€ç»ˆ Prompt
            st.markdown("**âœ¨ æœ€ç»ˆå®Œæ•´çš„æ‘˜è¦ Promptï¼ˆå¯ç›´æ¥å¤åˆ¶ï¼‰ï¼š**")
            st.caption("ğŸ’¡ ç”¨ {{text}} å ä½ç¬¦è¡¨ç¤ºå¾…æ‘˜è¦çš„æ–‡æœ¬")
            st.text_area(
                "æ‘˜è¦å™¨ Prompt",
                value=result.final_prompt,
                height=400,
                label_visibility="collapsed"
            )
            
            # å¤åˆ¶æŒ‰é’®
            if st.button("ğŸ“‹ å¤åˆ¶åˆ°å‰ªè´´æ¿", use_container_width=True, key="copy_summarization"):
                st.code(result.final_prompt, language=None)
                st.success("âœ… å·²æ˜¾ç¤ºåœ¨ä»£ç æ¡†ä¸­ï¼Œè¯·æ‰‹åŠ¨å¤åˆ¶")

# ç¿»è¯‘ä»»åŠ¡åˆ†æ”¯
elif task_type == "ç¿»è¯‘ä»»åŠ¡":
    with col1:
        st.subheader("ğŸŒ ç¿»è¯‘ä»»åŠ¡é…ç½®")
        st.info("ğŸ“Œ é«˜è´¨é‡ç¿»è¯‘éœ€è¦ï¼šå‡†ç¡®çš„æœ¯è¯­ + ç¬¦åˆæ–‡åŒ–çš„è¡¨è¾¾ã€‚ç³»ç»Ÿå°†ä¸ºæ‚¨æ„å»º'ä¿¡è¾¾é›…'çš„ç¿»è¯‘æŒ‡ä»¤ã€‚")
        
        # è¯­è¨€æ–¹å‘é…ç½®
        st.markdown("**ğŸ”„ ç¿»è¯‘æ–¹å‘**")
        lang_col1, lang_col2 = st.columns(2)
        with lang_col1:
            source_lang = st.selectbox(
                "æºè¯­è¨€",
                ["ä¸­æ–‡", "è‹±æ–‡", "æ—¥æ–‡", "æ³•æ–‡", "å¾·æ–‡", "è¥¿ç­ç‰™æ–‡", "éŸ©æ–‡"],
                help="è¦ç¿»è¯‘çš„åŸå§‹æ–‡æœ¬è¯­è¨€"
            )
        with lang_col2:
            target_lang = st.selectbox(
                "ç›®æ ‡è¯­è¨€",
                ["è‹±æ–‡", "ä¸­æ–‡", "æ—¥æ–‡", "æ³•æ–‡", "å¾·æ–‡", "è¥¿ç­ç‰™æ–‡", "éŸ©æ–‡"],
                index=1,
                help="ç¿»è¯‘åçš„ç›®æ ‡è¯­è¨€"
            )
        
        # é¢†åŸŸé€‰æ‹©
        st.markdown("**ğŸ“š åº”ç”¨é¢†åŸŸ**")
        domain = st.selectbox(
            "é€‰æ‹©ç¿»è¯‘é¢†åŸŸ",
            [
                "é€šç”¨æ—¥å¸¸",
                "IT/æŠ€æœ¯æ–‡æ¡£",
                "æ³•å¾‹åˆåŒ",
                "å­¦æœ¯è®ºæ–‡",
                "å•†åŠ¡é‚®ä»¶",
                "æ–‡å­¦/å°è¯´",
                "åŒ»å­¦æ–‡æ¡£",
                "æ–°é—»æŠ¥é“",
                "è¥é”€æ–‡æ¡ˆ",
                "æ¸¸æˆæœ¬åœ°åŒ–"
            ],
            help="ä¸åŒé¢†åŸŸéœ€è¦ä¸åŒçš„ä¸“ä¸šæœ¯è¯­å’Œè¡¨è¾¾é£æ ¼"
        )
        
        # é£æ ¼é€‰æ‹©
        st.markdown("**ğŸ¨ æœŸæœ›é£æ ¼**")
        tone = st.selectbox(
            "é€‰æ‹©ç¿»è¯‘é£æ ¼",
            [
                "æ ‡å‡†/å‡†ç¡®",
                "åœ°é“/å£è¯­åŒ–",
                "ä¼˜ç¾/æ–‡å­¦æ€§",
                "æç®€/æ‘˜è¦å¼",
                "æ­£å¼/å•†åŠ¡",
                "è½»æ¾/æ´»æ³¼"
            ],
            help="å†³å®šè¯‘æ–‡çš„è¡¨è¾¾æ–¹å¼å’Œè¯­è¨€é£æ ¼"
        )
        
        # æœ¯è¯­è¡¨ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰
        st.markdown("**ğŸ“– æœ¯è¯­åº“ï¼ˆGlossaryï¼‰- å¯é€‰**")
        st.caption("å¼ºåˆ¶æŒ‡å®šæŸäº›è¯çš„è¯‘æ³•ï¼Œç¡®ä¿æœ¯è¯­ä¸€è‡´æ€§ã€‚æ¯è¡Œä¸€ä¸ªï¼Œæ ¼å¼ï¼šåŸæ–‡=è¯‘æ–‡")
        glossary_input = st.text_area(
            "æœ¯è¯­æ˜ å°„",
            height=120,
            placeholder="""ä¾‹å¦‚ï¼ˆITé¢†åŸŸï¼‰ï¼š
Prompt Engineering=æç¤ºè¯å·¥ç¨‹
LLM=å¤§è¯­è¨€æ¨¡å‹
Token=ä»¤ç‰Œ
Fine-tuning=å¾®è°ƒ

ä¾‹å¦‚ï¼ˆæ–‡å­¦ä½œå“ï¼‰ï¼š
ä¿®ç‚¼=Cultivation
ç­‘åŸº=Foundation Establishment
é‡‘ä¸¹=Golden Core""",
            help="ä¸“æœ‰åè¯çš„å¼ºåˆ¶å¯¹åº”å…³ç³»ï¼Œæ¨¡å‹å°†ä¸¥æ ¼éµå®ˆ"
        )
        
        # æ„å»ºç¿»è¯‘å™¨æŒ‰é’®
        build_translation_btn = st.button("ğŸ”¨ æ„å»ºç¿»è¯‘å™¨ Prompt", type="primary", use_container_width=True)
    
    # ç¿»è¯‘ä»»åŠ¡ä¼˜åŒ–é€»è¾‘
    if build_translation_btn:
        if source_lang == target_lang:
            st.error("âŒ æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€ä¸èƒ½ç›¸åŒï¼")
        elif not api_key_input or api_key_input.strip() == "":
            st.error("âŒ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® API Key")
        else:
            with st.spinner("ğŸ”® æ­£åœ¨è®¾è®¡é¢†åŸŸä¸“å®¶è§’è‰²ã€æ¤å…¥æœ¯è¯­åº“ã€æ„å»ºä¸‰æ­¥ç¿»è¯‘æ³•..."):
                try:
                    # åˆ›å»ºä¼˜åŒ–å™¨
                    optimizer = PromptOptimizer(
                        api_key=api_key_input,
                        model=model_choice,
                        base_url=base_url if base_url else None,
                        provider=api_provider.lower()
                    )
                    
                    # æ‰§è¡Œç¿»è¯‘ä»»åŠ¡ä¼˜åŒ–
                    result = optimizer.optimize_translation(
                        source_lang=source_lang,
                        target_lang=target_lang,
                        domain=domain,
                        tone=tone,
                        user_glossary=glossary_input
                    )
                    
                    # ä¿å­˜ç»“æœ
                    st.session_state.translation_result = result
                    
                    st.success("âœ… ç¿»è¯‘å™¨ Prompt æ„å»ºå®Œæˆï¼")
                    
                except Exception as e:
                    error_msg = str(e)
                    st.error(f"âŒ æ„å»ºå¤±è´¥ï¼š{error_msg}")
                    
                    # æä¾›è§£å†³æ–¹æ¡ˆ
                    if "404" in error_msg or "401" in error_msg:
                        st.warning("""**å¯èƒ½çš„åŸå› å’Œè§£å†³æ–¹æ¡ˆï¼š**""")
                        if api_provider == "NVIDIA":
                            st.markdown("""
                            1. **API Key æ— æ•ˆæˆ–æœªé…ç½®**
                               - è¯·è®¿é—® [NVIDIA Build](https://build.nvidia.com/) è·å– API Key
                            2. **æ¨¡å‹ä¸æ”¯æŒ**
                               - æ¨èä½¿ç”¨ meta/llama-3.1-405b-instruct
                            """)
                    
                    st.info("ğŸ”§ å»ºè®®ï¼šè¿è¡Œ `python test_nvidia.py` æµ‹è¯• API è¿æ¥")
    
    # æ˜¾ç¤ºç¿»è¯‘ä»»åŠ¡ä¼˜åŒ–ç»“æœ
    if st.session_state.translation_result:
        result = st.session_state.translation_result
        
        with col2:
            st.subheader("ğŸŒ ç¿»è¯‘å™¨ Prompt")
            
            # 1. ä¼˜åŒ–æ€è·¯
            with st.expander("ğŸ§  æŸ¥çœ‹ä¼˜åŒ–æ€è·¯", expanded=True):
                st.write(result.thinking_process)
            
            # 2. è§’è‰²è®¾å®š
            with st.expander("ğŸ‘¤ é¢†åŸŸä¸“å®¶è§’è‰²", expanded=True):
                st.info(result.role_definition)
                st.caption("ğŸ’¡ æ ¹æ®ç¿»è¯‘é¢†åŸŸè®¾å®šçš„ä¸“ä¸šè§’è‰²ï¼Œç¡®ä¿è¯‘æ–‡ä¸“ä¸šæ€§")
            
            # 3. é£æ ¼æŒ‡å—
            with st.expander("ğŸ¨ é£æ ¼æŒ‡å—", expanded=True):
                for idx, guideline in enumerate(result.style_guidelines, 1):
                    st.markdown(f"**æŒ‡å— {idx}:** {guideline}")
                st.caption("ğŸ’¡ å…·ä½“çš„é£æ ¼è¦æ±‚ï¼Œä½¿è¯‘æ–‡ç¬¦åˆç›®æ ‡è¯­è¨€çš„è¡¨è¾¾ä¹ æƒ¯")
            
            # 4. æœ¯è¯­è¡¨ï¼ˆå¦‚æœæœ‰ï¼‰
            if result.glossary_section and result.glossary_section.strip():
                with st.expander("ğŸ“– æœ¯è¯­å¯¹ç…§è¡¨ï¼ˆå¼ºåˆ¶éµå®ˆï¼‰", expanded=True):
                    st.markdown(result.glossary_section)
                    st.caption("ğŸ’¡ ä¸“æœ‰åè¯çš„é”å®šç¿»è¯‘ï¼Œç¡®ä¿æœ¯è¯­ä¸€è‡´æ€§")
            
            # 5. ç¿»è¯‘æµç¨‹
            with st.expander("ğŸ”„ ä¸‰æ­¥ç¿»è¯‘æ³•", expanded=True):
                st.markdown(result.workflow_steps)
                st.caption("ğŸ’¡ åˆ†æ­¥éª¤çš„ç¿»è¯‘æµç¨‹ï¼Œé¿å…æœºæ¢°ç›´è¯‘")
            
            # 6. æœ€ç»ˆ Prompt
            st.markdown("**âœ¨ æœ€ç»ˆå®Œæ•´çš„ç¿»è¯‘ Promptï¼ˆå¯ç›´æ¥å¤åˆ¶ï¼‰ï¼š**")
            st.caption("ğŸ’¡ ç”¨ {{text}} å ä½ç¬¦è¡¨ç¤ºå¾…ç¿»è¯‘çš„æ–‡æœ¬")
            st.text_area(
                "ç¿»è¯‘å™¨ Prompt",
                value=result.final_prompt,
                height=450,
                label_visibility="collapsed"
            )
            
            # å¤åˆ¶æŒ‰é’®
            if st.button("ğŸ“‹ å¤åˆ¶åˆ°å‰ªè´´æ¿", use_container_width=True, key="copy_translation"):
                st.code(result.final_prompt, language=None)
                st.success("âœ… å·²æ˜¾ç¤ºåœ¨ä»£ç æ¡†ä¸­ï¼Œè¯·æ‰‹åŠ¨å¤åˆ¶")
            
            # ä½¿ç”¨ç¤ºä¾‹
            with st.expander("ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹", expanded=False):
                st.markdown(f"""
**å¦‚ä½•ä½¿ç”¨è¿™ä¸ªç¿»è¯‘ Promptï¼š**

1. å¤åˆ¶ä¸Šé¢çš„å®Œæ•´ Prompt
2. å°† `{{{{text}}}}` æ›¿æ¢ä¸ºæ‚¨è¦ç¿»è¯‘çš„å®é™…æ–‡æœ¬
3. å‘é€ç»™ LLMï¼ˆå¦‚ ChatGPTã€Claudeã€Llama ç­‰ï¼‰

**ç¤ºä¾‹ï¼ˆ{source_lang} â†’ {target_lang}ï¼‰ï¼š**
```
{result.final_prompt[:200]}...
[è¿™é‡Œæ”¾å…¥æ‚¨çš„ {source_lang} æ–‡æœ¬]
```

**ä¸“ä¸šæç¤ºï¼š**
- âœ… æœ¯è¯­è¡¨å¯ä»¥éšæ—¶æ›´æ–°ï¼Œæ¯æ¬¡ç¿»è¯‘æ—¶ä¿æŒä¸€è‡´
- âœ… å¯¹äºä¸“ä¸šæ–‡æ¡£ï¼Œå»ºè®®å…ˆç¿»è¯‘ä¸€å°æ®µæµ‹è¯•æ•ˆæœ
- âœ… å¦‚æœè¯‘æ–‡ä¸å¤Ÿåœ°é“ï¼Œå¯ä»¥è¦æ±‚æ¨¡å‹"å†æ¬¡æ¶¦è‰²"
                """)

# ========== æ•ˆæœéªŒè¯å®éªŒå®¤ ==========
st.markdown("---")
st.header("ğŸ§ª æ•ˆæœéªŒè¯å®éªŒå®¤")
st.markdown("åœ¨æ­¤è¾“å…¥æµ‹è¯•æ•°æ®å’Œæ ‡å‡†ç­”æ¡ˆï¼Œç³»ç»Ÿå°†è‡ªåŠ¨è®¡ç®—æ€§èƒ½æŒ‡æ ‡ï¼ˆAccuracy / BLEU / ROUGEï¼‰ã€‚")

# åˆ¤æ–­æ˜¯å¦å·²ç»ç”Ÿæˆäº†ä¼˜åŒ–åçš„ Prompt
has_result = False
current_result = None
placeholder_text = ""

if task_type == "ç”Ÿæˆä»»åŠ¡" and st.session_state.result:
    has_result = True
    current_result = st.session_state.result
    placeholder_text = "å¾…å¤„ç†çš„è¾“å…¥"
elif task_type == "åˆ†ç±»ä»»åŠ¡" and st.session_state.classification_result:
    has_result = True
    current_result = st.session_state.classification_result
    placeholder_text = "å¾…åˆ†ç±»çš„æ–‡æœ¬"
elif task_type == "æ‘˜è¦ä»»åŠ¡" and st.session_state.summarization_result:
    has_result = True
    current_result = st.session_state.summarization_result
    placeholder_text = "å¾…æ‘˜è¦çš„æ–‡æœ¬"
elif task_type == "ç¿»è¯‘ä»»åŠ¡" and st.session_state.translation_result:
    has_result = True
    current_result = st.session_state.translation_result
    placeholder_text = "å¾…ç¿»è¯‘çš„æ–‡æœ¬"

if not has_result:
    st.info("ğŸ’¡ è¯·å…ˆåœ¨ä¸Šæ–¹å®Œæˆ Prompt ä¼˜åŒ–ï¼Œç„¶åå†è¿›è¡Œæ•ˆæœéªŒè¯ã€‚")
else:
    st.success(f"âœ… æ£€æµ‹åˆ°å·²ä¼˜åŒ–çš„ {task_type} Promptï¼Œå¯ä»¥å¼€å§‹éªŒè¯ï¼")
    
    # éªŒè¯åŒºåŸŸ
    col_test1, col_test2 = st.columns(2)
    
    with col_test1:
        st.markdown("**ğŸ“ æµ‹è¯•è¾“å…¥**")
        
        # æ ¹æ®ä»»åŠ¡ç±»å‹æ˜¾ç¤ºä¸åŒçš„æç¤º
        if task_type == "åˆ†ç±»ä»»åŠ¡":
            placeholder_hint = """ç¤ºä¾‹ï¼ˆæ¯è¡Œä¸€ä¸ªæµ‹è¯•æ ·æœ¬ï¼‰ï¼š
è¿™ä¸ªäº§å“çœŸçš„å¾ˆå¥½ç”¨ï¼Œéå¸¸æ»¡æ„ï¼
ä»·æ ¼å¤ªè´µäº†ï¼Œæ€§ä»·æ¯”ä¸é«˜ã€‚
è¿˜å¯ä»¥å§ï¼Œæ²¡æœ‰ç‰¹åˆ«çš„æ„Ÿè§‰ã€‚"""
            help_text = "åˆ†ç±»ä»»åŠ¡æ”¯æŒæ‰¹é‡æµ‹è¯•ï¼šæ¯è¡Œä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ï¼Œç³»ç»Ÿä¼šä¾æ¬¡åˆ†ç±»å¹¶è®¡ç®—æ•´ä½“å‡†ç¡®ç‡"
        elif task_type == "æ‘˜è¦ä»»åŠ¡":
            placeholder_hint = f"è¾“å…¥{placeholder_text}..."
            help_text = "æ‘˜è¦ä»»åŠ¡è¾“å…¥å•ä¸ªé•¿æ–‡æœ¬è¿›è¡Œæµ‹è¯•"
        elif task_type == "ç¿»è¯‘ä»»åŠ¡":
            placeholder_hint = f"è¾“å…¥{placeholder_text}..."
            help_text = "ç¿»è¯‘ä»»åŠ¡è¾“å…¥å•ä¸ªæ–‡æœ¬è¿›è¡Œæµ‹è¯•"
        else:
            placeholder_hint = f"è¾“å…¥{placeholder_text}..."
            help_text = "è¾“å…¥éœ€è¦æµ‹è¯•çš„æ•°æ®"
        
        test_input = st.text_area(
            "è¾“å…¥æµ‹è¯•æ•°æ®",
            height=150,
            placeholder=placeholder_hint,
            key="test_input",
            help=help_text
        )
        
        # è¯­è¨€è®¾ç½®ï¼ˆç”¨äº ROUGE å’Œ BLEUï¼‰
        if task_type in ["æ‘˜è¦ä»»åŠ¡", "ç¿»è¯‘ä»»åŠ¡"]:
            test_lang = st.selectbox(
                "æµ‹è¯•æ•°æ®è¯­è¨€",
                ["ä¸­æ–‡", "è‹±æ–‡"],
                key="test_lang",
                help="ç”¨äºæ­£ç¡®è®¡ç®— ROUGE/BLEU åˆ†æ•°ï¼ˆä¸­æ–‡éœ€è¦åˆ†è¯ï¼‰"
            )
    
    with col_test2:
        st.markdown("**âœ… æ ‡å‡†å‚è€ƒç­”æ¡ˆ**")
        
        # æ ¹æ®ä»»åŠ¡ç±»å‹æ˜¾ç¤ºä¸åŒçš„æç¤º
        if task_type == "åˆ†ç±»ä»»åŠ¡":
            ref_placeholder = """ç¤ºä¾‹ï¼ˆæ¯è¡Œä¸€ä¸ªæ ‡ç­¾ï¼Œä¸æµ‹è¯•æ•°æ®ä¸€ä¸€å¯¹åº”ï¼‰ï¼š
ç§¯æ
æ¶ˆæ
ä¸­ç«‹"""
            ref_help = "æ¯è¡Œä¸€ä¸ªæ ‡ç­¾ï¼Œé¡ºåºä¸å·¦ä¾§æµ‹è¯•æ•°æ®å¯¹åº”"
        elif task_type == "æ‘˜è¦ä»»åŠ¡":
            ref_placeholder = "è¾“å…¥äººå·¥æ’°å†™çš„æ ‡å‡†æ‘˜è¦..."
            ref_help = "ç”¨äºè®¡ç®— ROUGE åˆ†æ•°çš„å‚è€ƒæ‘˜è¦"
        elif task_type == "ç¿»è¯‘ä»»åŠ¡":
            ref_placeholder = "è¾“å…¥äººå·¥ç¿»è¯‘çš„æ ‡å‡†è¯‘æ–‡..."
            ref_help = "ç”¨äºè®¡ç®— BLEU åˆ†æ•°çš„å‚è€ƒè¯‘æ–‡"
        else:
            ref_placeholder = "è¾“å…¥æ ‡å‡†ç­”æ¡ˆæˆ–æœŸæœ›è¾“å‡º..."
            ref_help = "ç”¨äºè®¡ç®—è¯„ä¼°æŒ‡æ ‡çš„å‚è€ƒç­”æ¡ˆ"
        
        reference_output = st.text_area(
            "å‚è€ƒç­”æ¡ˆ",
            height=150,
            placeholder=ref_placeholder,
            key="reference_output",
            help=ref_help
        )
        
        st.caption("ğŸ’¡ **ä¸ºä»€ä¹ˆéœ€è¦å‚è€ƒç­”æ¡ˆï¼Ÿ**")
        if task_type == "åˆ†ç±»ä»»åŠ¡":
            st.caption("Accuracy éœ€è¦å¯¹æ¯”ã€Œæ¨¡å‹é¢„æµ‹ã€å’Œã€Œæ­£ç¡®æ ‡ç­¾ã€ã€‚æ”¯æŒæ‰¹é‡æµ‹è¯•ï¼Œæ›´å‡†ç¡®è¯„ä¼°åˆ†ç±»æ•ˆæœã€‚")
        else:
            st.caption("Accuracy/BLEU/ROUGE ç­‰æ•°å­¦æŒ‡æ ‡éœ€è¦å¯¹æ¯”ã€Œæ¨¡å‹è¾“å‡ºã€å’Œã€Œæ ‡å‡†ç­”æ¡ˆã€æ¥è®¡ç®—åˆ†æ•°ã€‚")
    
    # è¿è¡Œè¯„ä¼°æŒ‰é’®
    if st.button("ğŸš€ è¿è¡Œ Prompt å¹¶è®¡ç®—æŒ‡æ ‡", type="primary", use_container_width=True):
        if not test_input or not reference_output:
            st.error("âŒ è¯·åŒæ—¶æä¾›æµ‹è¯•è¾“å…¥å’Œå‚è€ƒç­”æ¡ˆï¼")
        elif not api_key_input or api_key_input.strip() == "":
            st.error("âŒ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® API Key")
        else:
            # æ·»åŠ è¯¦ç»†æ—¥å¿—
            print(f"\n{'='*60}")
            print(f"ğŸ§ª å¼€å§‹æ•ˆæœéªŒè¯")
            print(f"{'='*60}")
            print(f"ğŸ“‹ ä»»åŠ¡ç±»å‹: {task_type}")
            print(f"ğŸ“ æµ‹è¯•è¾“å…¥é•¿åº¦: {len(test_input)} å­—ç¬¦")
            print(f"âœ… å‚è€ƒç­”æ¡ˆé•¿åº¦: {len(reference_output)} å­—ç¬¦")
            print(f"ğŸ”Œ API æä¾›å•†: {api_provider}")
            print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model_choice}")
            print(f"{'='*60}\n")
            
            with st.spinner("ğŸ”® æ¨¡å‹æ­£åœ¨æ ¹æ®ä¼˜åŒ–åçš„ Prompt ç”Ÿæˆç»“æœ..."):
                try:
                    print("ğŸ”§ æ­¥éª¤ 1: åˆ›å»ºä¼˜åŒ–å™¨...")
                    # åˆ›å»ºä¼˜åŒ–å™¨ï¼ˆä½¿ç”¨ç›¸åŒçš„é…ç½®ï¼‰
                    optimizer = PromptOptimizer(
                        api_key=api_key_input,
                        model=model_choice,
                        base_url=base_url if base_url else None,
                        provider=api_provider.lower()
                    )
                    print("âœ… ä¼˜åŒ–å™¨åˆ›å»ºæˆåŠŸ")
                    
                    print("\nğŸ”§ æ­¥éª¤ 2: æ„å»ºæœ€ç»ˆ Prompt...")
                    
                    # æ™ºèƒ½æ›¿æ¢å‡½æ•°ï¼šå°è¯•å¤šç§å ä½ç¬¦æ ¼å¼
                    def smart_replace(template: str, text: str, task_type_name: str = "") -> str:
                        """æ™ºèƒ½æ›¿æ¢å„ç§å¯èƒ½çš„å ä½ç¬¦æ ¼å¼"""
                        # è®°å½•åŸå§‹æ¨¡æ¿
                        original = template
                        
                        # å°è¯•å„ç§å ä½ç¬¦æ ¼å¼ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
                        replacements = [
                            # æ ‡å‡†å ä½ç¬¦
                            ("{{text}}", text),
                            ("{text}", text),
                            ("{{input}}", text),
                            ("{input}", text),
                            
                            # ä¸­æ–‡æ–¹æ‹¬å·å ä½ç¬¦
                            ("[è¾“å…¥è¯„è®º]", text),
                            ("[å¾…åˆ†ç±»æ–‡æœ¬]", text),
                            ("[å¾…ç¿»è¯‘æ–‡æœ¬]", text),
                            ("[å¾…æ‘˜è¦æ–‡æœ¬]", text),
                            ("[è¾“å…¥æ–‡æœ¬]", text),
                            ("[æ–‡æœ¬å†…å®¹]", text),
                            ("[ç”¨æˆ·è¾“å…¥]", text),
                            
                            # ä¸­æ–‡èŠ±æ‹¬å·å ä½ç¬¦
                            ("ã€è¾“å…¥è¯„è®ºã€‘", text),
                            ("ã€å¾…åˆ†ç±»æ–‡æœ¬ã€‘", text),
                            ("ã€å¾…ç¿»è¯‘æ–‡æœ¬ã€‘", text),
                            ("ã€å¾…æ‘˜è¦æ–‡æœ¬ã€‘", text),
                            ("ã€è¾“å…¥æ–‡æœ¬ã€‘", text),
                            ("ã€æ–‡æœ¬å†…å®¹ã€‘", text),
                            ("ã€å¾…å¤„ç†æ–‡æœ¬ã€‘", text),
                            
                            # è‹±æ–‡æè¿°æ€§å ä½ç¬¦
                            ("[INPUT]", text),
                            ("[TEXT]", text),
                            ("[CONTENT]", text),
                            ("{INPUT}", text),
                            ("{TEXT}", text),
                            
                            # å…¶ä»–å¸¸è§æ ¼å¼
                            ("<text>", text),
                            ("<input>", text),
                            ("$text", text),
                            ("$input", text),
                        ]
                        
                        result = template
                        replaced_count = 0
                        replaced_placeholders = []
                        
                        for placeholder, replacement in replacements:
                            if placeholder in result:
                                old_result = result
                                result = result.replace(placeholder, replacement)
                                if result != old_result:
                                    replaced_count += 1
                                    replaced_placeholders.append(placeholder)
                                    print(f"   âœ… æ›¿æ¢ '{placeholder}' -> å®é™…æ–‡æœ¬")
                        
                        if replaced_count == 0:
                            print(f"   âš ï¸ è­¦å‘Šï¼šæœªæ‰¾åˆ°ä»»ä½•å ä½ç¬¦ï¼")
                            print(f"   ğŸ“‹ å®Œæ•´æ¨¡æ¿å†…å®¹ï¼š")
                            print(f"   {template}")
                            print(f"   ğŸ’¡ æç¤ºï¼šè¯·æ£€æŸ¥æ¨¡æ¿ä¸­ä½¿ç”¨çš„å ä½ç¬¦æ ¼å¼")
                            print(f"   ğŸ”§ å°è¯•è‡ªåŠ¨ä¿®å¤ï¼šåœ¨ Prompt æœ«å°¾æ·»åŠ æ–‡æœ¬æ’å…¥ä½ç½®...")
                            
                            # æ ¹æ®ä»»åŠ¡ç±»å‹æ·»åŠ åˆé€‚çš„æç¤ºè¯­
                            if "åˆ†ç±»" in task_type_name:
                                result = template + f"\n\nå¾…åˆ†ç±»æ–‡æœ¬ï¼š{text}\n\nè¯·åˆ†æä¸Šè¿°æ–‡æœ¬å¹¶è¾“å‡ºåˆ†ç±»ç»“æœã€‚"
                            elif "æ‘˜è¦" in task_type_name:
                                result = template + f"\n\nå¾…æ‘˜è¦æ–‡æœ¬ï¼š\n{text}\n\nè¯·æ ¹æ®ä¸Šè¿°è¦æ±‚ç”Ÿæˆæ‘˜è¦ã€‚"
                            elif "ç¿»è¯‘" in task_type_name:
                                result = template + f"\n\nå¾…ç¿»è¯‘æ–‡æœ¬ï¼š\n{text}\n\nè¯·ç¿»è¯‘ä¸Šè¿°æ–‡æœ¬ã€‚"
                            else:
                                result = template + f"\n\nè¾“å…¥å†…å®¹ï¼š{text}"
                            
                            print(f"   âœ… å·²è‡ªåŠ¨æ·»åŠ æ–‡æœ¬åˆ° Prompt æœ«å°¾ï¼ˆä»»åŠ¡ç±»å‹ï¼š{task_type_name}ï¼‰")
                        else:
                            print(f"   âœ… æˆåŠŸæ›¿æ¢ {replaced_count} ä¸ªå ä½ç¬¦: {', '.join(replaced_placeholders)}")
                        
                        return result
                    
                    # æ ¹æ®ä»»åŠ¡ç±»å‹æ„å»ºæœ€ç»ˆ Prompt
                    if task_type == "ç”Ÿæˆä»»åŠ¡":
                        # ç”Ÿæˆä»»åŠ¡ç›´æ¥ä½¿ç”¨ä¼˜åŒ–åçš„ prompt
                        print("ğŸ“„ ä½¿ç”¨ç”Ÿæˆä»»åŠ¡ Prompt æ¨¡æ¿")
                        template = current_result.improved_prompt
                        print(f"ğŸ“‹ æ¨¡æ¿é•¿åº¦: {len(template)} å­—ç¬¦")
                        if len(template) < 100:
                            print(f"   âš ï¸ è­¦å‘Šï¼šPrompt å¤ªçŸ­ï¼Œå¯èƒ½ä¸å®Œæ•´ï¼")
                        print(f"ğŸ“‹ æ¨¡æ¿å‰500å­—ç¬¦: {template[:500]}...")
                        final_prompt = smart_replace(template, test_input, task_type)
                        
                    elif task_type == "åˆ†ç±»ä»»åŠ¡":
                        print("ğŸ“„ ä½¿ç”¨åˆ†ç±»ä»»åŠ¡ Prompt æ¨¡æ¿")
                        template = current_result.final_prompt
                        print(f"ğŸ“‹ æ¨¡æ¿é•¿åº¦: {len(template)} å­—ç¬¦")
                        
                        # æ£€æŸ¥ Prompt è´¨é‡
                        if len(template) < 200:
                            print(f"   âš ï¸ è­¦å‘Šï¼šPrompt å¤ªçŸ­ï¼ˆ< 200å­—ç¬¦ï¼‰ï¼Œå¯èƒ½ä¸å®Œæ•´ï¼")
                            print(f"   ğŸ’¡ å»ºè®®ï¼šæ£€æŸ¥ LLM æ˜¯å¦æ­£ç¡®ç”Ÿæˆäº†å®Œæ•´çš„ final_prompt")
                            st.warning("âš ï¸ æ£€æµ‹åˆ°ç”Ÿæˆçš„ Prompt è¾ƒçŸ­ï¼Œå¯èƒ½å½±å“åˆ†ç±»æ•ˆæœã€‚å»ºè®®é‡æ–°ç”Ÿæˆ Promptã€‚")
                        
                        print(f"ğŸ“‹ æ¨¡æ¿å‰500å­—ç¬¦:\n{template[:500]}...")
                        if len(template) > 500:
                            print(f"ğŸ“‹ æ¨¡æ¿å200å­—ç¬¦:\n...{template[-200:]}")
                        
                        final_prompt = smart_replace(template, test_input, task_type)
                        
                    elif task_type == "æ‘˜è¦ä»»åŠ¡":
                        print("ğŸ“„ ä½¿ç”¨æ‘˜è¦ä»»åŠ¡ Prompt æ¨¡æ¿")
                        template = current_result.final_prompt
                        print(f"ğŸ“‹ æ¨¡æ¿é•¿åº¦: {len(template)} å­—ç¬¦")
                        if len(template) < 200:
                            print(f"   âš ï¸ è­¦å‘Šï¼šPrompt å¤ªçŸ­ï¼Œå¯èƒ½ä¸å®Œæ•´ï¼")
                        print(f"ğŸ“‹ æ¨¡æ¿å‰500å­—ç¬¦: {template[:500]}...")
                        final_prompt = smart_replace(template, test_input, task_type)
                        
                    elif task_type == "ç¿»è¯‘ä»»åŠ¡":
                        print("ğŸ“„ ä½¿ç”¨ç¿»è¯‘ä»»åŠ¡ Prompt æ¨¡æ¿")
                        template = current_result.final_prompt
                        print(f"ğŸ“‹ æ¨¡æ¿é•¿åº¦: {len(template)} å­—ç¬¦")
                        if len(template) < 200:
                            print(f"   âš ï¸ è­¦å‘Šï¼šPrompt å¤ªçŸ­ï¼Œå¯èƒ½ä¸å®Œæ•´ï¼")
                        print(f"ğŸ“‹ æ¨¡æ¿å‰500å­—ç¬¦: {template[:500]}...")
                        final_prompt = smart_replace(template, test_input, task_type)
                    
                    print(f"\nâœ… Prompt æ„å»ºå®Œæˆ")
                    print(f"ğŸ“ æœ€ç»ˆ Prompt é•¿åº¦: {len(final_prompt)} å­—ç¬¦")
                    print(f"ğŸ“‹ æœ€ç»ˆ Promptï¼ˆå‰300å­—ç¬¦ï¼‰:\n{final_prompt[:300]}...")
                    print(f"\nğŸ” æ£€æŸ¥å ä½ç¬¦æ˜¯å¦è¢«æ›¿æ¢:")
                    print(f"   - æ˜¯å¦è¿˜åŒ…å« '{{{{text}}}}': {'{{text}}' in final_prompt}")
                    print(f"   - æ˜¯å¦è¿˜åŒ…å« '{{text}}': {'{text}' in final_prompt}")
                    print(f"   - æ˜¯å¦åŒ…å«æµ‹è¯•è¾“å…¥: {test_input[:20] in final_prompt if len(test_input) > 20 else test_input in final_prompt}")
                    
                    print("\nğŸ”§ æ­¥éª¤ 3: è°ƒç”¨ LLM...")
                    # è°ƒç”¨ LLM
                    response = optimizer.llm.invoke(final_prompt)
                    prediction = response.content
                    print(f"âœ… LLM å“åº”æˆåŠŸ")
                    print(f"ğŸ“ é¢„æµ‹ç»“æœé•¿åº¦: {len(prediction)} å­—ç¬¦")
                    print(f"ğŸ“‹ é¢„æµ‹ç»“æœï¼ˆå‰200å­—ç¬¦ï¼‰: {prediction[:200]}...")
                    
                    # ä¿å­˜é¢„æµ‹ç»“æœ
                    st.session_state.prediction = prediction
                    st.session_state.test_reference = reference_output
                    
                    # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
                    st.markdown("---")
                    st.subheader("ğŸ¤– æ¨¡å‹é¢„æµ‹ç»“æœ")
                    st.info(prediction)
                    
                    print("\nğŸ”§ æ­¥éª¤ 4: è®¡ç®—è¯„ä¼°æŒ‡æ ‡...")
                    # è®¡ç®—æŒ‡æ ‡
                    st.markdown("---")
                    st.subheader("ğŸ“Š æ€§èƒ½è¯„åˆ†")
                    
                    calc = MetricsCalculator()
                    print(f"ğŸ“Š ä»»åŠ¡ç±»å‹: {task_type}")
                    
                    # æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©æŒ‡æ ‡
                    if task_type == "åˆ†ç±»ä»»åŠ¡":
                        print("ğŸ“ˆ è®¡ç®—åˆ†ç±»ä»»åŠ¡ Accuracy...")
                        
                        # åˆ†ç±»ä»»åŠ¡æ”¯æŒæ‰¹é‡æµ‹è¯•ï¼šæŒ‰è¡Œåˆ†å‰²
                        test_samples = [line.strip() for line in test_input.strip().split('\n') if line.strip()]
                        reference_labels = [line.strip() for line in reference_output.strip().split('\n') if line.strip()]
                        
                        print(f"   ğŸ”¹ æµ‹è¯•æ ·æœ¬æ•°: {len(test_samples)}")
                        print(f"   ğŸ”¹ å‚è€ƒæ ‡ç­¾æ•°: {len(reference_labels)}")
                        
                        # æ£€æŸ¥æ•°é‡æ˜¯å¦åŒ¹é…
                        if len(test_samples) != len(reference_labels):
                            st.error(f"âŒ æµ‹è¯•æ ·æœ¬æ•°é‡ ({len(test_samples)}) ä¸å‚è€ƒæ ‡ç­¾æ•°é‡ ({len(reference_labels)}) ä¸åŒ¹é…ï¼")
                            print(f"   âŒ æ•°é‡ä¸åŒ¹é…ï¼")
                        else:
                            # å¦‚æœåªæœ‰ä¸€ä¸ªæ ·æœ¬ï¼Œç›´æ¥ä½¿ç”¨ä¹‹å‰çš„é¢„æµ‹ç»“æœ
                            if len(test_samples) == 1:
                                pred_clean = prediction.strip().split('\n')[0].strip()
                                predictions = [pred_clean]
                                print(f"   ğŸ”¹ å•æ ·æœ¬æµ‹è¯•")
                                print(f"   ğŸ”¹ é¢„æµ‹: {pred_clean}")
                                print(f"   ğŸ”¹ å‚è€ƒ: {reference_labels[0]}")
                            else:
                                # æ‰¹é‡é¢„æµ‹ï¼šå¯¹æ¯ä¸ªæ ·æœ¬è°ƒç”¨ä¸€æ¬¡
                                predictions = []
                                print(f"   ğŸ”¹ æ‰¹é‡æµ‹è¯•æ¨¡å¼")
                                
                                progress_bar = st.progress(0)
                                status_text = st.empty()
                                
                                for idx, sample in enumerate(test_samples):
                                    status_text.text(f"æ­£åœ¨å¤„ç† {idx+1}/{len(test_samples)} ...")
                                    
                                    # æ„å»ºå•ä¸ªæ ·æœ¬çš„ Prompt
                                    sample_prompt = smart_replace(template, sample, task_type)
                                    
                                    # è°ƒç”¨ LLM
                                    response = optimizer.llm.invoke(sample_prompt)
                                    pred = response.content.strip().split('\n')[0].strip()
                                    predictions.append(pred)
                                    
                                    print(f"   æ ·æœ¬ {idx+1}: {sample[:30]}... -> é¢„æµ‹: {pred}")
                                    
                                    progress_bar.progress((idx + 1) / len(test_samples))
                                
                                status_text.empty()
                                progress_bar.empty()
                            
                            # è®¡ç®—å‡†ç¡®ç‡
                            score = calc.calculate_accuracy(predictions, reference_labels)
                            print(f"   âœ… Accuracy åˆ†æ•°: {score}%")
                            
                            metric_name = "Accuracy (å‡†ç¡®ç‡)"
                            metric_key = "accuracy"
                            
                            col_m1, col_m2 = st.columns([1, 2])
                            with col_m1:
                                st.metric(label=metric_name, value=f"{score}%")
                                st.caption(f"æµ‹è¯•æ ·æœ¬: {len(test_samples)} ä¸ª")
                                st.caption(f"é¢„æµ‹æ­£ç¡®: {int(score * len(test_samples) / 100)} ä¸ª")
                            with col_m2:
                                level, color, advice = calc.get_metric_interpretation(metric_key, score)
                                st.markdown(f"**è¯„çº§ï¼š** {level}")
                                if color == "success":
                                    st.success(advice)
                                elif color == "warning":
                                    st.warning(advice)
                                elif color == "error":
                                    st.error(advice)
                                else:
                                    st.info(advice)
                            
                            # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
                            with st.expander("ğŸ“‹ æŸ¥çœ‹æ¯ä¸ªæ ·æœ¬çš„é¢„æµ‹ç»“æœ", expanded=False):
                                result_df_data = []
                                for i, (sample, pred, ref) in enumerate(zip(test_samples, predictions, reference_labels), 1):
                                    is_correct = pred.lower() == ref.lower()
                                    result_df_data.append({
                                        "åºå·": i,
                                        "æµ‹è¯•æ–‡æœ¬": sample[:50] + "..." if len(sample) > 50 else sample,
                                        "é¢„æµ‹æ ‡ç­¾": pred,
                                        "æ­£ç¡®æ ‡ç­¾": ref,
                                        "ç»“æœ": "âœ… æ­£ç¡®" if is_correct else "âŒ é”™è¯¯"
                                    })
                                
                                import pandas as pd
                                result_df = pd.DataFrame(result_df_data)
                                st.dataframe(result_df, use_container_width=True)
                    
                    elif task_type == "æ‘˜è¦ä»»åŠ¡":
                        print("ğŸ“ˆ è®¡ç®—æ‘˜è¦ä»»åŠ¡ ROUGE...")
                        # æ‘˜è¦ä»»åŠ¡ï¼šè®¡ç®— ROUGE
                        lang_code = "zh" if test_lang == "ä¸­æ–‡" else "en"
                        print(f"   ğŸ”¹ è¯­è¨€è®¾ç½®: {lang_code}")
                        print(f"   ğŸ”¹ é¢„æµ‹é•¿åº¦: {len(prediction)} å­—ç¬¦")
                        print(f"   ğŸ”¹ å‚è€ƒé•¿åº¦: {len(reference_output)} å­—ç¬¦")
                        
                        rouge_scores = calc.calculate_rouge(prediction, reference_output, lang=lang_code)
                        print(f"   âœ… ROUGE åˆ†æ•°: {rouge_scores}")
                        
                        st.markdown("**ROUGE åˆ†æ•°ï¼š**")
                        col_r1, col_r2, col_r3 = st.columns(3)
                        with col_r1:
                            st.metric("ROUGE-1", f"{rouge_scores['rouge1']}%", help="å•è¯é‡åˆåº¦")
                        with col_r2:
                            st.metric("ROUGE-2", f"{rouge_scores['rouge2']}%", help="åŒè¯ç»„é‡åˆåº¦")
                        with col_r3:
                            st.metric("ROUGE-L", f"{rouge_scores['rougeL']}%", help="æœ€é•¿å…¬å…±å­åºåˆ—")
                        
                        # ä½¿ç”¨ ROUGE-L ä½œä¸ºä¸»è¦è¯„ä»·æŒ‡æ ‡
                        level, color, advice = calc.get_metric_interpretation("rouge", rouge_scores['rougeL'])
                        st.markdown(f"**ç»¼åˆè¯„çº§ï¼ˆåŸºäº ROUGE-Lï¼‰ï¼š** {level}")
                        if color == "success":
                            st.success(advice)
                        elif color == "warning":
                            st.warning(advice)
                        elif color == "error":
                            st.error(advice)
                        else:
                            st.info(advice)
                    
                    elif task_type == "ç¿»è¯‘ä»»åŠ¡":
                        print("ğŸ“ˆ è®¡ç®—ç¿»è¯‘ä»»åŠ¡ BLEU...")
                        # ç¿»è¯‘ä»»åŠ¡ï¼šè®¡ç®— BLEU
                        lang_code = "zh" if test_lang == "ä¸­æ–‡" else "en"
                        print(f"   ğŸ”¹ è¯­è¨€è®¾ç½®: {lang_code}")
                        print(f"   ğŸ”¹ é¢„æµ‹ç¿»è¯‘: {prediction[:100]}...")
                        print(f"   ğŸ”¹ å‚è€ƒç¿»è¯‘: {reference_output[:100]}...")
                        
                        bleu_score = calc.calculate_bleu(prediction, reference_output, lang=lang_code)
                        print(f"   âœ… BLEU åˆ†æ•°: {bleu_score}%")
                        
                        col_b1, col_b2 = st.columns([1, 2])
                        with col_b1:
                            st.metric("BLEU Score", f"{bleu_score}%")
                        with col_b2:
                            level, color, advice = calc.get_metric_interpretation("bleu", bleu_score)
                            st.markdown(f"**è¯„çº§ï¼š** {level}")
                            if color == "success":
                                st.success(advice)
                            elif color == "warning":
                                st.warning(advice)
                            elif color == "error":
                                st.error(advice)
                            else:
                                st.info(advice)
                    
                    elif task_type == "ç”Ÿæˆä»»åŠ¡":
                        print("â„¹ï¸ ç”Ÿæˆä»»åŠ¡ä½¿ç”¨å®šæ€§è¯„ä¼°")
                        # ç”Ÿæˆä»»åŠ¡æ²¡æœ‰æ ‡å‡†æŒ‡æ ‡ï¼Œä½¿ç”¨å®šæ€§è¯„ä¼°
                        st.info("ğŸ’¡ ç”Ÿæˆä»»åŠ¡é€šå¸¸ä½¿ç”¨äººå·¥è¯„ä¼°æˆ– LLM-as-a-Judge è¿›è¡Œè¯„ä»·ï¼Œæš‚ä¸æ”¯æŒè‡ªåŠ¨åŒ–æŒ‡æ ‡ã€‚")
                        st.markdown("**å»ºè®®è¯„ä¼°ç»´åº¦ï¼š**")
                        st.markdown("- âœ… æ˜¯å¦éµå¾ªäº† Prompt çš„è¦æ±‚ï¼Ÿ")
                        st.markdown("- âœ… è¾“å‡ºæ ¼å¼æ˜¯å¦æ­£ç¡®ï¼Ÿ")
                        st.markdown("- âœ… å†…å®¹æ˜¯å¦å‡†ç¡®ã€å®Œæ•´ï¼Ÿ")
                    
                    print("\nâœ… æ•ˆæœéªŒè¯å®Œæˆï¼")
                    print(f"{'='*60}\n")
                    # å¯¹æ¯”å±•ç¤º
                    with st.expander("ğŸ” è¯¦ç»†å¯¹æ¯”", expanded=False):
                        comp_col1, comp_col2 = st.columns(2)
                        with comp_col1:
                            st.markdown("**ğŸ¤– æ¨¡å‹è¾“å‡ºï¼š**")
                            st.code(prediction, language=None)
                        with comp_col2:
                            st.markdown("**âœ… å‚è€ƒç­”æ¡ˆï¼š**")
                            st.code(reference_output, language=None)
                    
                except Exception as e:
                    print(f"\nâŒ éªŒè¯è¿‡ç¨‹å‘ç”Ÿé”™è¯¯ï¼")
                    print(f"{'='*60}")
                    error_msg = str(e)
                    print(f"ğŸ› é”™è¯¯ç±»å‹: {type(e).__name__}")
                    print(f"ğŸ“ é”™è¯¯ä¿¡æ¯: {error_msg}")
                    
                    import traceback
                    print(f"\nğŸ“„ å®Œæ•´å †æ ˆä¿¡æ¯ï¼š")
                    traceback.print_exc()
                    print(f"{'='*60}\n")
                    
                    st.error(f"âŒ è¯„ä¼°å¤±è´¥ï¼š{str(e)}")
                    import traceback
                    with st.expander("æŸ¥çœ‹é”™è¯¯è¯¦æƒ…"):
                        st.code(traceback.format_exc())

col_foot1, col_foot2, col_foot3 = st.columns(3)

with col_foot1:
    st.metric("æ ¸å¿ƒæŠ€æœ¯", "LLM-as-Optimizer", "ğŸ¤–")
with col_foot2:
    st.metric("ä¼˜åŒ–ç­–ç•¥", "3å¤§æ ¸å¿ƒæ–¹æ³•", "ğŸ¯")
with col_foot3:
    st.metric("æ¡†æ¶æ”¯æŒ", "4ç§æ¨¡æ¿", "ğŸ“")

# é¡µè„š
st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: #888;'>"
    "ğŸš€ AI Prompt è‡ªåŠ¨ä¼˜åŒ–ç³»ç»Ÿ"
    "</div>",
    unsafe_allow_html=True
)
