"""
AI Prompt è‡ªåŠ¨ä¼˜åŒ–ç³»ç»Ÿ - Streamlit ç•Œé¢
"""
import streamlit as st
import os
from dotenv import load_dotenv
from optimizer import PromptOptimizer, OptimizedPrompt, ClassificationPrompt, SummarizationPrompt, TranslationPrompt
from nvidia_models import get_model_list
from metrics import MetricsCalculator

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="AI Prompt è‡ªåŠ¨ä¼˜åŒ–å¤§å¸ˆ",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰æ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 1rem;
    }
    .sub-header {
        color: #666;
        font-size: 1.1rem;
        margin-bottom: 2rem;
    }
    .stButton>button {
        width: 100%;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        color: white;
        font-weight: bold;
        border-radius: 10px;
        padding: 0.5rem 1rem;
        border: none;
    }
    .stButton>button:hover {
        background: linear-gradient(90deg, #764ba2 0%, #667eea 100%);
    }
    .technique-badge {
        display: inline-block;
        background-color: #e0e7ff;
        color: #4c51bf;
        padding: 0.25rem 0.75rem;
        border-radius: 15px;
        margin: 0.25rem;
        font-size: 0.9rem;
    }
    .keyword-badge {
        display: inline-block;
        background-color: #fef3c7;
        color: #d97706;
        padding: 0.25rem 0.75rem;
        border-radius: 15px;
        margin: 0.25rem;
        font-size: 0.9rem;
    }
</style>
""", unsafe_allow_html=True)

# æ ‡é¢˜åŒºåŸŸ
st.markdown('<p class="main-header">ğŸš€ AI Prompt è‡ªåŠ¨ä¼˜åŒ–å¤§å¸ˆ</p>', unsafe_allow_html=True)
st.markdown('<p class="sub-header">è¾“å…¥ç®€å•çš„æƒ³æ³•ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨åˆ©ç”¨ <b>ç»“æ„åŒ–æ¨¡æ¿ã€è¯­ä¹‰æ‰©å±•ã€å…³é”®è¯å¢å¼º</b> æŠ€æœ¯ä¸ºæ‚¨ç”Ÿæˆä¸“å®¶çº§ Prompt</p>', unsafe_allow_html=True)

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("âš™ï¸ ç³»ç»Ÿé…ç½®")
    
    # ä»»åŠ¡ç±»å‹é€‰æ‹©ï¼ˆæ–°å¢ï¼‰
    task_type = st.radio(
        "ğŸ“‹ ä»»åŠ¡ç±»å‹",
        ["ç”Ÿæˆä»»åŠ¡", "åˆ†ç±»ä»»åŠ¡", "æ‘˜è¦ä»»åŠ¡", "ç¿»è¯‘ä»»åŠ¡"],
        help="é€‰æ‹©è¦ä¼˜åŒ–çš„ Prompt ç±»å‹"
    )
    
    st.divider()
    
    # API æä¾›å•†é€‰æ‹©
    api_provider = st.selectbox(
        "ğŸ”Œ API æä¾›å•†",
        ["NVIDIA", "OpenAI"],
        index=0,
        help="é€‰æ‹©ä½¿ç”¨çš„ API æœåŠ¡æä¾›å•†"
    )
    
    st.divider()
    
    # æ ¹æ®æä¾›å•†æ˜¾ç¤ºä¸åŒçš„é…ç½®
    if api_provider == "NVIDIA":
        st.markdown("âœ¨ **NVIDIA API é…ç½®**")
        
        # åªåœ¨ç¯å¢ƒå˜é‡çœŸæœ‰æœ‰æ•ˆå€¼æ—¶æ‰ä½¿ç”¨
        env_key = os.getenv("NVIDIA_API_KEY", "")
        default_value = env_key if env_key and env_key.startswith("nvapi-") and len(env_key) > 10 else ""
        
        api_key_input = st.text_input(
            "NVIDIA API Key",
            type="password",
            value=default_value,
            help="ä» NVIDIA AI Endpoints è·å– API Key"
        )
        
        # API Key éªŒè¯æç¤º
        if api_key_input:
            if not api_key_input.startswith("nvapi-"):
                st.warning("âš ï¸ NVIDIA API Key åº”è¯¥ä»¥ 'nvapi-' å¼€å¤´")
            else:
                st.success("âœ… API Key æ ¼å¼æ­£ç¡®")
        else:
            st.error("ğŸ”‘ è¯·è¾“å…¥ NVIDIA API Key")
            st.info("ğŸ’¡ **è·å–å…è´¹ API Key**ï¼š[NVIDIA Build](https://build.nvidia.com/) â†’ ç™»å½• â†’ é€‰æ‹©æ¨¡å‹ â†’ Get API Key")
        
        base_url = st.text_input(
            "NVIDIA Base URL",
            value=os.getenv("NVIDIA_BASE_URL", "https://integrate.api.nvidia.com/v1"),
            help="NVIDIA API ç«¯ç‚¹"
        )
        
        # NVIDIA æ¨¡å‹é€‰æ‹©ï¼ˆä½¿ç”¨å®Œæ•´æ¨¡å‹åˆ—è¡¨ï¼‰
        nvidia_models = get_model_list("æ¨èæ¨¡å‹")
        
        model_choice = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            nvidia_models,
            index=0,
            help="æ¨èä½¿ç”¨ Llama 3.1 405B æˆ– Mistral Large ä»¥è·å¾—æœ€ä½³ä¼˜åŒ–æ•ˆæœ"
        )
        
        # é«˜çº§é€‰é¡¹ï¼šæ˜¾ç¤ºæ‰€æœ‰æ¨¡å‹
        with st.expander("ğŸ”§ æŸ¥çœ‹æ‰€æœ‰å¯ç”¨æ¨¡å‹", expanded=False):
            all_models = get_model_list("all")
            st.info(f"å…±æœ‰ {len(all_models)} ä¸ªå¯ç”¨æ¨¡å‹")
            model_choice_advanced = st.selectbox(
                "ä»å…¨éƒ¨æ¨¡å‹ä¸­é€‰æ‹©",
                all_models,
                key="advanced_model"
            )
            if st.button("ä½¿ç”¨æ­¤æ¨¡å‹"):
                model_choice = model_choice_advanced
                st.success(f"å·²åˆ‡æ¢åˆ°ï¼š{model_choice}")

        
    else:  # OpenAI
        st.markdown("âœ¨ **OpenAI API é…ç½®**")
        
        # åªåœ¨ç¯å¢ƒå˜é‡çœŸæœ‰æœ‰æ•ˆå€¼æ—¶æ‰ä½¿ç”¨
        env_key = os.getenv("OPENAI_API_KEY", "")
        default_value = env_key if env_key and env_key.startswith("sk-") and len(env_key) > 10 else ""
        
        api_key_input = st.text_input(
            "OpenAI API Key",
            type="password",
            value=default_value,
            help="ä» OpenAI å®˜ç½‘è·å– API Key"
        )
        
        # API Key éªŒè¯æç¤º
        if api_key_input:
            if not api_key_input.startswith("sk-"):
                st.warning("âš ï¸ OpenAI API Key åº”è¯¥ä»¥ 'sk-' å¼€å¤´")
            else:
                st.success("âœ… API Key æ ¼å¼æ­£ç¡®")
        else:
            st.error("ğŸ”‘ è¯·è¾“å…¥ OpenAI API Key")
            st.info("ğŸ’¡ **è·å– API Key**ï¼š[OpenAI Platform](https://platform.openai.com/) â†’ API Keys")
        
        base_url = st.text_input(
            "API Base URL (å¯é€‰)",
            value=os.getenv("OPENAI_BASE_URL", ""),
            help="å¦‚ä½¿ç”¨ä»£ç†æˆ–ç¬¬ä¸‰æ–¹æœåŠ¡ï¼Œè¯·å¡«å†™å®Œæ•´çš„ base URL"
        )
        
        model_choice = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            ["gpt-4o", "gpt-4o-mini", "gpt-4-turbo", "gpt-3.5-turbo"],
            index=0,
            help="æ¨èä½¿ç”¨ GPT-4o ä»¥è·å¾—æœ€ä½³ä¼˜åŒ–æ•ˆæœ"
        )
    
    # ä¼˜åŒ–æ¨¡å¼ï¼ˆä»…ç”Ÿæˆä»»åŠ¡æ˜¾ç¤ºï¼‰
    if task_type == "ç”Ÿæˆä»»åŠ¡":
        optimization_mode = st.selectbox(
            "ğŸ¯ ä¼˜åŒ–æ¨¡å¼",
            [
                "é€šç”¨å¢å¼º (General)",
                "ä»£ç ç”Ÿæˆ (Coding)",
                "åˆ›æ„å†™ä½œ (Creative)",
                "å­¦æœ¯åˆ†æ (Academic)"
            ],
            help="æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©åˆé€‚çš„ä¼˜åŒ–ç­–ç•¥"
        )
    
    st.divider()
    
    # ä½¿ç”¨è¯´æ˜
    with st.expander("ğŸ“– ä½¿ç”¨è¯´æ˜", expanded=False):
        st.markdown("""
        **å¿«é€Ÿä¸Šæ‰‹**ï¼š
        1. åœ¨å·¦ä¾§è¾“å…¥æ‚¨çš„ API Key
        2. åœ¨ä¸»ç•Œé¢è¾“å…¥ç®€å•çš„ Prompt
        3. ï¼ˆå¯é€‰ï¼‰æ·»åŠ åœºæ™¯æè¿°
        4. ç‚¹å‡»"å¼€å§‹é­”æ³•ä¼˜åŒ–"
        
        **ä¼˜åŒ–æ¨¡å¼è¯´æ˜**ï¼š
        - **é€šç”¨å¢å¼º**ï¼šé€‚ç”¨äºå„ç±»æ—¥å¸¸ä»»åŠ¡
        - **ä»£ç ç”Ÿæˆ**ï¼šä¸“é—¨ä¼˜åŒ–ç¼–ç¨‹ç›¸å…³ä»»åŠ¡
        - **åˆ›æ„å†™ä½œ**ï¼šæ–‡æ¡ˆã€æ•…äº‹ã€è¥é”€å†…å®¹
        - **å­¦æœ¯åˆ†æ**ï¼šç ”ç©¶ã€è®ºæ–‡ã€æ•°æ®åˆ†æ
        
        **æ ¸å¿ƒæŠ€æœ¯**ï¼š
        - ğŸ” è¯­ä¹‰æ‰©å±•ï¼šè¡¥å……éšå«éœ€æ±‚
        - ğŸ¯ å…³é”®è¯å¢å¼ºï¼šåŠ å…¥ä¸“ä¸šæœ¯è¯­
        - ğŸ“ æ¨¡æ¿åº”ç”¨ï¼šCO-STAR/BROKE æ¡†æ¶
        """)
    
    # ç¤ºä¾‹ Prompt
    with st.expander("ğŸ’¡ ç¤ºä¾‹ Prompt", expanded=False):
        st.markdown("""
        **ä»£ç ç±»**ï¼š
        - "å†™ä¸ªè´ªåƒè›‡æ¸¸æˆ"
        - "å¸®æˆ‘å®ç°ä¸€ä¸ªç™»å½•ç³»ç»Ÿ"
        
        **æ–‡æ¡ˆç±»**ï¼š
        - "å†™ä¸ªäº§å“ä»‹ç»"
        - "åˆ›ä½œä¸€ä¸ªå“ç‰Œæ•…äº‹"
        
        **åˆ†æç±»**ï¼š
        - "åˆ†æå¸‚åœºè¶‹åŠ¿"
        - "æ€»ç»“è®ºæ–‡è¦ç‚¹"
        """)

# åˆå§‹åŒ– session state
if 'result' not in st.session_state:
    st.session_state.result = None
if 'comparison_done' not in st.session_state:
    st.session_state.comparison_done = False
if 'comparison_results' not in st.session_state:
    st.session_state.comparison_results = None
if 'classification_result' not in st.session_state:
    st.session_state.classification_result = None
if 'summarization_result' not in st.session_state:
    st.session_state.summarization_result = None
if 'translation_result' not in st.session_state:
    st.session_state.translation_result = None

# ä¸»ç•Œé¢å¸ƒå±€
col1, col2 = st.columns([1, 1])

# ========== æ ¹æ®ä»»åŠ¡ç±»å‹æ˜¾ç¤ºä¸åŒç•Œé¢ ==========
if task_type == "ç”Ÿæˆä»»åŠ¡":
    with col1:
        st.subheader("ğŸ“ åŸå§‹è¾“å…¥")
        
        # ç”¨æˆ·è¾“å…¥åŒºåŸŸ
        user_input = st.text_area(
            "è¾“å…¥æ‚¨çš„ç®€å• Prompt",
            height=150,
            placeholder="ä¾‹å¦‚ï¼šå¸®æˆ‘å†™ä¸ªè´ªåƒè›‡æ¸¸æˆ",
            help="æè¿°æ‚¨æƒ³åšä»€ä¹ˆï¼Œå¯ä»¥å¾ˆç®€å•"
        )
        
        scene_input = st.text_input(
            "åœºæ™¯/è¡¥å……æè¿°ï¼ˆå¯é€‰ï¼‰",
            placeholder="ä¾‹å¦‚ï¼šPython, ç»™å°å­©å­¦ç¼–ç¨‹ç”¨",
            help="æä¾›æ›´å¤šèƒŒæ™¯ä¿¡æ¯ï¼Œå¦‚ç¼–ç¨‹è¯­è¨€ã€ç›®æ ‡å—ä¼—ç­‰"
        )
        
        # ä¼˜åŒ–æŒ‰é’®
        start_btn = st.button("âœ¨ å¼€å§‹é­”æ³•ä¼˜åŒ–", type="primary", use_container_width=True)

    # ç”Ÿæˆä»»åŠ¡ä¼˜åŒ–é€»è¾‘
    if start_btn:
        if not user_input or user_input.strip() == "":
            st.error("âŒ è¯·å…ˆè¾“å…¥ Prompt")
        elif not api_key_input or api_key_input.strip() == "":
            st.error("âŒ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® API Key")
        else:
            with st.spinner("ğŸ”® æ­£åœ¨åˆ†æè¯­ä¹‰ã€æå–å…³é”®è¯ã€æ„å»ºç»“æ„åŒ–æ¨¡æ¿..."):
                try:
                    # åˆ›å»ºä¼˜åŒ–å™¨
                    optimizer = PromptOptimizer(
                        api_key=api_key_input,
                        model=model_choice,
                        base_url=base_url if base_url else None,
                        provider=api_provider.lower()
                    )
                    
                    # æ‰§è¡Œä¼˜åŒ–
                    result = optimizer.optimize(
                        user_prompt=user_input,
                        scene_desc=scene_input,
                        optimization_mode=optimization_mode
                    )
                    
                    # ä¿å­˜ç»“æœåˆ° session state
                    st.session_state.result = result
                    st.session_state.comparison_done = False
                    st.session_state.comparison_results = None
                    
                    st.success("âœ… ä¼˜åŒ–å®Œæˆï¼")
                    
                except Exception as e:
                    error_msg = str(e)
                    st.error(f"âŒ ä¼˜åŒ–å¤±è´¥ï¼š{error_msg}")
                    
                    # æ ¹æ®é”™è¯¯ç±»å‹æä¾›å…·ä½“çš„è§£å†³æ–¹æ¡ˆ
                    if "404" in error_msg or "401" in error_msg:
                        st.warning("""**å¯èƒ½çš„åŸå› å’Œè§£å†³æ–¹æ¡ˆï¼š**""")
                        if api_provider == "NVIDIA":
                            st.markdown("""
                            1. **API Key æ— æ•ˆæˆ–æœªé…ç½®**
                               - è¯·è®¿é—® [NVIDIA Build](https://build.nvidia.com/) è·å– API Key
                               - ç¡®ä¿ API Key æ ¼å¼æ­£ç¡®ï¼ˆä»¥ `nvapi-` å¼€å¤´ï¼‰
                               - åœ¨ä¾§è¾¹æ è¾“å…¥æœ‰æ•ˆçš„ API Key
                            
                            2. **æ¨¡å‹åç§°ä¸æ­£ç¡®**
                               - è¯·ä»ä¸‹æ‹‰åˆ—è¡¨ä¸­é€‰æ‹©æ¨¡å‹
                               - ä¸è¦æ‰‹åŠ¨è¾“å…¥æ¨¡å‹åç§°
                            
                            3. **ç½‘ç»œé—®é¢˜**
                               - NVIDIA API å¯èƒ½éœ€è¦ç§‘å­¦ä¸Šç½‘
                               - æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸
                            """)
                        else:
                            st.markdown("""
                            1. **API Key æ— æ•ˆ**
                               - è¯·è®¿é—® [OpenAI Platform](https://platform.openai.com/) æ£€æŸ¥ API Key
                               - ç¡®ä¿è´¦æˆ·æœ‰è¶³å¤Ÿä½™é¢
                            
                            2. **Base URL é…ç½®é”™è¯¯**
                               - å¦‚æœä½¿ç”¨ä»£ç†ï¼Œè¯·æ£€æŸ¥ Base URL æ˜¯å¦æ­£ç¡®
                            """)
                    elif "rate_limit" in error_msg.lower():
                        st.info("ğŸ’¡ API è¯·æ±‚é¢‘ç‡è¶…é™ï¼Œè¯·ç­‰å¾…å‡ ç§’åé‡è¯•")
                    else:
                        st.info("ğŸ’¡ æç¤ºï¼šè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œ API é…ç½®")
                    
                    # æä¾›æµ‹è¯•è¿æ¥çš„å»ºè®®
                    st.info("ğŸ”§ å»ºè®®ï¼šè¿è¡Œ `python test_nvidia.py` æµ‹è¯• API è¿æ¥")

    # ç”Ÿæˆä»»åŠ¡ç»“æœå±•ç¤ºåŒºåŸŸ
    if st.session_state.result:
        result = st.session_state.result
        
        with col2:
            st.subheader("ğŸŒŸ ä¼˜åŒ–ç»“æœ")
        
        # ä¼˜åŒ–æ€è·¯å±•ç¤º
        with st.expander("ğŸ§  æŸ¥çœ‹ä¼˜åŒ–æ€è·¯ (Thinking Process)", expanded=True):
            st.write(result.thinking_process)
            
            # åº”ç”¨çš„æŠ€æœ¯
            st.markdown("**ğŸ› ï¸ åº”ç”¨çš„ä¼˜åŒ–æŠ€æœ¯ï¼š**")
            techniques_html = "".join([
                f'<span class="technique-badge">{tech}</span>'
                for tech in result.enhancement_techniques
            ])
            st.markdown(techniques_html, unsafe_allow_html=True)
            
            # æ–°å¢çš„å…³é”®è¯
            if result.keywords_added:
                st.markdown("**ğŸ”‘ æ–°å¢çš„å…³é”®è¯ï¼š**")
                keywords_html = "".join([
                    f'<span class="keyword-badge">{kw}</span>'
                    for kw in result.keywords_added
                ])
                st.markdown(keywords_html, unsafe_allow_html=True)
            
            # åº”ç”¨çš„æ¡†æ¶
            st.markdown(f"**ğŸ“ åº”ç”¨çš„æ¡†æ¶ï¼š** `{result.structure_applied}`")
        
        # ä¼˜åŒ–åçš„ Prompt
        st.markdown("**âœ¨ ä¼˜åŒ–åçš„ Promptï¼ˆå¯ç›´æ¥å¤åˆ¶ï¼‰ï¼š**")
        st.text_area(
            "ä¼˜åŒ–ç»“æœ",
            value=result.improved_prompt,
            height=300,
            label_visibility="collapsed"
        )
        
        # å¤åˆ¶æŒ‰é’®
        if st.button("ğŸ“‹ å¤åˆ¶åˆ°å‰ªè´´æ¿", use_container_width=True):
            st.code(result.improved_prompt, language=None)
            st.success("âœ… å·²æ˜¾ç¤ºåœ¨ä»£ç æ¡†ä¸­ï¼Œè¯·æ‰‹åŠ¨å¤åˆ¶")

# A/B å¯¹æ¯”æµ‹è¯•åŒºåŸŸ
if st.session_state.result:
    st.divider()
    st.subheader("ğŸ”¬ A/B æ•ˆæœå¯¹æ¯”æµ‹è¯•")
    st.markdown("*è®© AI åˆ†åˆ«ä½¿ç”¨åŸå§‹ Prompt å’Œä¼˜åŒ–åçš„ Prompt æ‰§è¡Œä»»åŠ¡ï¼Œç›´è§‚å¯¹æ¯”ä¼˜åŒ–æ•ˆæœ*")
    
    col_test1, col_test2, col_test3 = st.columns([2, 1, 2])
    
    with col_test2:
        if st.button("ğŸš€ è¿è¡Œå¯¹æ¯”æµ‹è¯•", type="primary", use_container_width=True):
            if not st.session_state.comparison_done:
                with st.spinner("â³ æ­£åœ¨è¿è¡Œä¸¤ä¸ªç‰ˆæœ¬çš„ Promptï¼Œè¯·ç¨å€™..."):
                    try:
                        optimizer = PromptOptimizer(
                            api_key=api_key_input,
                            model=model_choice,
                            base_url=base_url if base_url else None,
                            provider=api_provider.lower()
                        )
                        
                        res_orig, res_opt = optimizer.compare_results(
                            original_prompt=user_input,
                            optimized_prompt=result.improved_prompt
                        )
                        
                        st.session_state.comparison_results = (res_orig, res_opt)
                        st.session_state.comparison_done = True
                        
                    except Exception as e:
                        st.error(f"âŒ å¯¹æ¯”æµ‹è¯•å¤±è´¥ï¼š{str(e)}")
    
    # æ˜¾ç¤ºå¯¹æ¯”ç»“æœ
    if st.session_state.comparison_done and st.session_state.comparison_results:
        res_orig, res_opt = st.session_state.comparison_results
        
        col_result1, col_result2 = st.columns(2)
        
        with col_result1:
            st.markdown("#### ğŸ“„ åŸå§‹ Prompt äº§å‡º")
            st.info(res_orig)
            
        with col_result2:
            st.markdown("#### âœ¨ ä¼˜åŒ–å Prompt äº§å‡º")
            st.success(res_opt)

# ========== åˆ†ç±»ä»»åŠ¡ç•Œé¢ ==========
elif task_type == "åˆ†ç±»ä»»åŠ¡":
    with col1:
        st.subheader("ğŸ·ï¸ åˆ†ç±»ä»»åŠ¡é…ç½®")
        st.info("ğŸ“Œ åˆ†ç±»ä»»åŠ¡éœ€è¦æ˜ç¡®çš„æ ‡ç­¾å®šä¹‰å’Œç¤ºä¾‹ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨ç”Ÿæˆè¿™äº›è¦ç´ ã€‚")
        
        # ä»»åŠ¡æè¿°
        task_description = st.text_area(
            "ä»»åŠ¡æè¿°",
            height=100,
            placeholder="ä¾‹å¦‚ï¼šåˆ¤æ–­ç”¨æˆ·è¯„è®ºçš„æƒ…æ„Ÿå€¾å‘\næˆ–ï¼šè¯†åˆ«å®¢æœå¯¹è¯ä¸­çš„ç”¨æˆ·æ„å›¾",
            help="æ¸…æ™°æè¿°è¿™æ˜¯ä¸€ä¸ªä»€ä¹ˆæ ·çš„åˆ†ç±»ä»»åŠ¡"
        )
        
        # æ ‡ç­¾è¾“å…¥
        labels_input = st.text_input(
            "ç›®æ ‡æ ‡ç­¾ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰",
            placeholder="ä¾‹å¦‚ï¼šPositive, Negative, Neutral",
            help="è¾“å…¥æ‰€æœ‰å¯èƒ½çš„åˆ†ç±»æ ‡ç­¾ï¼Œç”¨é€—å·åˆ†éš”"
        )
        
        # å¯é€‰ï¼šç¤ºä¾‹æ–‡æœ¬
        with st.expander("ğŸ’¡ æä¾›ç¤ºä¾‹æ–‡æœ¬ï¼ˆå¯é€‰ï¼‰", expanded=False):
            st.caption("å¦‚æœæä¾›ç¤ºä¾‹ï¼Œç³»ç»Ÿä¼šåŸºäºè¿™äº›ç¤ºä¾‹ç”Ÿæˆ Few-Shot æ ·æœ¬")
            example_text_1 = st.text_input("ç¤ºä¾‹ 1ï¼ˆå¯é€‰ï¼‰", placeholder="ä¾‹å¦‚ï¼šè¿™ä¸ªäº§å“å¤ªæ£’äº†ï¼")
            example_text_2 = st.text_input("ç¤ºä¾‹ 2ï¼ˆå¯é€‰ï¼‰", placeholder="ä¾‹å¦‚ï¼šè´¨é‡å¾ˆå·®ï¼Œä¸æ¨èè´­ä¹°")
            example_text_3 = st.text_input("ç¤ºä¾‹ 3ï¼ˆå¯é€‰ï¼‰", placeholder="ä¾‹å¦‚ï¼šä¸€èˆ¬èˆ¬ï¼Œæ²¡ä»€ä¹ˆç‰¹åˆ«çš„")
        
        # æ„å»ºåˆ†ç±»å™¨æŒ‰é’®
        build_btn = st.button("ğŸ”¨ æ„å»ºåˆ†ç±»å™¨ Prompt", type="primary", use_container_width=True)
    
    # åˆ†ç±»ä»»åŠ¡ä¼˜åŒ–é€»è¾‘
    if build_btn:
        if not task_description or not labels_input:
            st.error("âŒ è¯·å¡«å†™ä»»åŠ¡æè¿°å’Œç›®æ ‡æ ‡ç­¾ï¼")
        elif not api_key_input or api_key_input.strip() == "":
            st.error("âŒ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® API Key")
        else:
            # è§£ææ ‡ç­¾
            labels_list = [label.strip() for label in labels_input.split(",") if label.strip()]
            
            if len(labels_list) < 2:
                st.error("âŒ è‡³å°‘éœ€è¦ 2 ä¸ªæ ‡ç­¾")
            else:
                with st.spinner("ğŸ”® æ­£åœ¨ç”Ÿæˆæ ‡ç­¾å®šä¹‰ã€åˆæˆè®­ç»ƒæ ·æœ¬ã€æ„å»ºåˆ†ç±»å™¨..."):
                    try:
                        # åˆ›å»ºä¼˜åŒ–å™¨
                        optimizer = PromptOptimizer(
                            api_key=api_key_input,
                            model=model_choice,
                            base_url=base_url if base_url else None,
                            provider=api_provider.lower()
                        )
                        
                        # æ”¶é›†ç¤ºä¾‹æ–‡æœ¬
                        example_texts = []
                        if example_text_1:
                            example_texts.append(example_text_1)
                        if example_text_2:
                            example_texts.append(example_text_2)
                        if example_text_3:
                            example_texts.append(example_text_3)
                        
                        # æ‰§è¡Œåˆ†ç±»ä»»åŠ¡ä¼˜åŒ–
                        result = optimizer.optimize_classification(
                            task_description=task_description,
                            labels=labels_list,
                            example_texts=example_texts if example_texts else None
                        )
                        
                        # ä¿å­˜ç»“æœ
                        st.session_state.classification_result = result
                        
                        st.success("âœ… åˆ†ç±»å™¨ Prompt æ„å»ºå®Œæˆï¼")
                        
                    except Exception as e:
                        error_msg = str(e)
                        st.error(f"âŒ æ„å»ºå¤±è´¥ï¼š{error_msg}")
                        
                        # æä¾›è§£å†³æ–¹æ¡ˆ
                        if "404" in error_msg or "401" in error_msg:
                            st.warning("""**å¯èƒ½çš„åŸå› å’Œè§£å†³æ–¹æ¡ˆï¼š**""")
                            if api_provider == "NVIDIA":
                                st.markdown("""
                                1. **API Key æ— æ•ˆæˆ–æœªé…ç½®**
                                   - è¯·è®¿é—® [NVIDIA Build](https://build.nvidia.com/) è·å– API Key
                                2. **æ¨¡å‹ä¸æ”¯æŒ**
                                   - æ¨èä½¿ç”¨ meta/llama-3.1-405b-instruct
                                """)
                        
                        st.info("ğŸ”§ å»ºè®®ï¼šè¿è¡Œ `python test_nvidia.py` æµ‹è¯• API è¿æ¥")
    
    # æ˜¾ç¤ºåˆ†ç±»ä»»åŠ¡ä¼˜åŒ–ç»“æœ
    if st.session_state.classification_result:
        result = st.session_state.classification_result
        
        with col2:
            st.subheader("ğŸ¯ åˆ†ç±»å™¨ Prompt")
            
            # 1. ä¼˜åŒ–æ€è·¯
            with st.expander("ğŸ§  æŸ¥çœ‹ä¼˜åŒ–æ€è·¯", expanded=True):
                st.write(result.thinking_process)
            
            # 2. è§’è‰²å®šä¹‰
            with st.expander("ğŸ‘¤ è§’è‰²è®¾å®š", expanded=False):
                st.info(result.role_definition)
            
            # 3. æ ‡ç­¾å®šä¹‰
            with st.expander("ğŸ·ï¸ æ ‡ç­¾è¯¦ç»†å®šä¹‰", expanded=True):
                for label, definition in result.label_definitions.items():
                    st.markdown(f"**{label}**")
                    st.write(definition)
                    st.divider()
                st.caption("ğŸ’¡ ç³»ç»Ÿè‡ªåŠ¨è¡¥å……äº†æ¯ä¸ªæ ‡ç­¾çš„å…·ä½“æ ‡å‡†ï¼Œé˜²æ­¢æ¨¡å‹æ··æ·†ã€‚")
            
            # 4. Few-Shot ç¤ºä¾‹
            with st.expander("ğŸ“ è‡ªåŠ¨åˆæˆçš„ Few-Shot ç¤ºä¾‹", expanded=True):
                for idx, example in enumerate(result.few_shot_examples, 1):
                    st.markdown(f"**ç¤ºä¾‹ {idx}:**")
                    st.code(f"Input: {example.get('input', example.get('text', 'N/A'))}\nLabel: {example.get('label', 'N/A')}")
                st.caption("ğŸ’¡ è¿™äº›ç¤ºä¾‹å¸®åŠ©æ¨¡å‹ç†è§£åˆ†ç±»æ ‡å‡†")
            
            # 5. æ€ç»´é“¾å¼•å¯¼
            with st.expander("ğŸ§  æ€ç»´é“¾å¼•å¯¼", expanded=False):
                st.write(result.reasoning_guidance)
            
            # 6. è¾“å‡ºæ ¼å¼
            with st.expander("ğŸ“ è¾“å‡ºæ ¼å¼è¦æ±‚", expanded=False):
                st.code(result.output_format)
            
            # 7. æœ€ç»ˆ Prompt
            st.markdown("**âœ¨ æœ€ç»ˆå®Œæ•´çš„åˆ†ç±» Promptï¼ˆå¯ç›´æ¥å¤åˆ¶ï¼‰ï¼š**")
            st.text_area(
                "åˆ†ç±»å™¨ Prompt",
                value=result.final_prompt,
                height=400,
                label_visibility="collapsed"
            )
            
            # å¤åˆ¶æŒ‰é’®
            if st.button("ğŸ“‹ å¤åˆ¶åˆ°å‰ªè´´æ¿", use_container_width=True, key="copy_classification"):
                st.code(result.final_prompt, language=None)
                st.success("âœ… å·²æ˜¾ç¤ºåœ¨ä»£ç æ¡†ä¸­ï¼Œè¯·æ‰‹åŠ¨å¤åˆ¶")

elif task_type == "æ‘˜è¦ä»»åŠ¡":
    with col1:
        st.subheader("ğŸ“„ æ‘˜è¦ä»»åŠ¡é…ç½®")
        st.info("ğŸ“Œ æ‘˜è¦ä»»åŠ¡éœ€è¦æ˜ç¡®ä¿¡æ¯æå–è§„åˆ™ï¼Œç³»ç»Ÿå°†è®¾è®¡æœ€ä¼˜çš„æå–ç­–ç•¥ã€‚")
        
        # ä»»åŠ¡æè¿°
        task_description = st.text_area(
            "ä»»åŠ¡æè¿°",
            height=100,
            placeholder="ä¾‹å¦‚ï¼šæ€»ç»“æŠ€æœ¯ä¼šè®®çš„æ ¸å¿ƒå†³ç­–å’Œè¡ŒåŠ¨è®¡åˆ’\næˆ–ï¼šæå–å­¦æœ¯è®ºæ–‡çš„ç ”ç©¶è´¡çŒ®å’Œåˆ›æ–°ç‚¹",
            help="æ¸…æ™°æè¿°æ‘˜è¦çš„ç›®çš„"
        )
        
        # æºæ–‡æœ¬ç±»å‹
        source_type = st.selectbox(
            "ğŸ“ æºæ–‡æœ¬ç±»å‹",
            [
                "ä¼šè®®è®°å½•",
                "å­¦æœ¯è®ºæ–‡",
                "æ–°é—»æŠ¥é“",
                "æŠ€æœ¯æ–‡æ¡£",
                "å®¢æˆ·åé¦ˆ",
                "äº§å“è¯„è®º",
                "ç ”ç©¶æŠ¥å‘Š",
                "é‚®ä»¶å†…å®¹",
                "å…¶ä»–"
            ],
            help="é€‰æ‹©éœ€è¦æ‘˜è¦çš„æ–‡æœ¬ç±»å‹"
        )
        
        # ç›®æ ‡å—ä¼—
        target_audience = st.text_input(
            "ğŸ‘¥ ç›®æ ‡å—ä¼—",
            placeholder="ä¾‹å¦‚ï¼šæŠ€æœ¯ç»ç†ã€ç ”å‘æ€»ç›‘ã€æ™®é€šç”¨æˆ·ã€æŠ•èµ„äºº",
            help="æ‘˜è¦å°†å‘ˆç°ç»™è°çœ‹ï¼Ÿè¿™ä¼šå½±å“è¯­è¨€é£æ ¼å’Œè¯¦ç»†ç¨‹åº¦"
        )
        
        # æ ¸å¿ƒå…³æ³¨ç‚¹
        focus_points = st.text_area(
            "ğŸ¯ æ ¸å¿ƒå…³æ³¨ç‚¹",
            height=100,
            placeholder="ä¾‹å¦‚ï¼š\n- Bug çš„æ ¹æœ¬åŸå› \n- æå‡ºçš„è§£å†³æ–¹æ¡ˆ\n- è´Ÿè´£äººå’Œæˆªæ­¢æ—¶é—´\n- èµ„æºéœ€æ±‚",
            help="æ‘˜è¦ä¸­å¿…é¡»ä¿ç•™å“ªäº›ä¿¡æ¯ï¼Ÿ"
        )
        
        # ç¯‡å¹…é™åˆ¶ï¼ˆå¯é€‰ï¼‰
        with st.expander("ğŸ“ ç¯‡å¹…é™åˆ¶ï¼ˆå¯é€‰ï¼‰", expanded=False):
            length_constraint = st.selectbox(
                "æ‘˜è¦é•¿åº¦",
                ["ä¸é™åˆ¶", "100å­—ä»¥å†…", "200å­—ä»¥å†…", "3-5ä¸ªè¦ç‚¹", "æ¯ä¸ªå…³æ³¨ç‚¹ä¸è¶…è¿‡50å­—"],
                help="æ§åˆ¶æ‘˜è¦çš„ç¯‡å¹…"
            )
            if length_constraint == "ä¸é™åˆ¶":
                length_constraint = None
        
        # æ„å»ºæ‘˜è¦å™¨æŒ‰é’®
        build_summarization_btn = st.button("ğŸ”¨ æ„å»ºæ‘˜è¦å™¨ Prompt", type="primary", use_container_width=True)
    
    # æ‘˜è¦ä»»åŠ¡ä¼˜åŒ–é€»è¾‘
    if build_summarization_btn:
        if not task_description or not target_audience or not focus_points:
            st.error("âŒ è¯·å¡«å†™ä»»åŠ¡æè¿°ã€ç›®æ ‡å—ä¼—å’Œæ ¸å¿ƒå…³æ³¨ç‚¹ï¼")
        elif not api_key_input or api_key_input.strip() == "":
            st.error("âŒ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® API Key")
        else:
            with st.spinner("ğŸ”® æ­£åœ¨ç”Ÿæˆæå–è§„åˆ™ã€è®¾è®¡è¾“å‡ºæ ¼å¼ã€æ„å»ºæ‘˜è¦å™¨..."):
                try:
                    # åˆ›å»ºä¼˜åŒ–å™¨
                    optimizer = PromptOptimizer(
                        api_key=api_key_input,
                        model=model_choice,
                        base_url=base_url if base_url else None,
                        provider=api_provider.lower()
                    )
                    
                    # æ‰§è¡Œæ‘˜è¦ä»»åŠ¡ä¼˜åŒ–
                    result = optimizer.optimize_summarization(
                        task_description=task_description,
                        source_type=source_type,
                        target_audience=target_audience,
                        focus_points=focus_points,
                        length_constraint=length_constraint
                    )
                    
                    # ä¿å­˜ç»“æœ
                    st.session_state.summarization_result = result
                    
                    st.success("âœ… æ‘˜è¦å™¨ Prompt æ„å»ºå®Œæˆï¼")
                    
                except Exception as e:
                    error_msg = str(e)
                    st.error(f"âŒ æ„å»ºå¤±è´¥ï¼š{error_msg}")
                    
                    # æä¾›è§£å†³æ–¹æ¡ˆ
                    if "404" in error_msg or "401" in error_msg:
                        st.warning("""**å¯èƒ½çš„åŸå› å’Œè§£å†³æ–¹æ¡ˆï¼š**""")
                        if api_provider == "NVIDIA":
                            st.markdown("""
                            1. **API Key æ— æ•ˆæˆ–æœªé…ç½®**
                               - è¯·è®¿é—® [NVIDIA Build](https://build.nvidia.com/) è·å– API Key
                            2. **æ¨¡å‹ä¸æ”¯æŒ**
                               - æ¨èä½¿ç”¨ meta/llama-3.1-405b-instruct
                            """)
                    
                    st.info("ğŸ”§ å»ºè®®ï¼šè¿è¡Œ `python test_nvidia.py` æµ‹è¯• API è¿æ¥")
    
    # æ˜¾ç¤ºæ‘˜è¦ä»»åŠ¡ä¼˜åŒ–ç»“æœ
    if st.session_state.summarization_result:
        result = st.session_state.summarization_result
        
        with col2:
            st.subheader("ğŸ“ æ‘˜è¦å™¨ Prompt")
            
            # 1. ä¼˜åŒ–æ€è·¯
            with st.expander("ğŸ§  æŸ¥çœ‹ä¼˜åŒ–æ€è·¯", expanded=True):
                st.write(result.thinking_process)
            
            # 2. è§’è‰²è®¾å®š
            with st.expander("ğŸ‘¤ è§’è‰²è®¾å®š", expanded=False):
                st.info(result.role_setting)
            
            # 3. æå–è§„åˆ™
            with st.expander("ğŸ“‹ ä¿¡æ¯æå–è§„åˆ™", expanded=True):
                for idx, rule in enumerate(result.extraction_rules, 1):
                    st.markdown(f"**è§„åˆ™ {idx}:** {rule}")
                st.caption("ğŸ’¡ æ˜ç¡®çš„æå–è§„åˆ™å¸®åŠ©æ¨¡å‹è¯†åˆ«å…³é”®ä¿¡æ¯")
            
            # 4. è´Ÿé¢çº¦æŸ
            with st.expander("ğŸš« è´Ÿé¢çº¦æŸï¼ˆé˜²æ­¢æ¨¡å‹å¹»è§‰ï¼‰", expanded=True):
                for idx, constraint in enumerate(result.negative_constraints, 1):
                    st.markdown(f"**çº¦æŸ {idx}:** {constraint}")
                st.caption("ğŸ’¡ å‘Šè¯‰æ¨¡å‹ã€Œä¸è¦åšä»€ä¹ˆã€ï¼Œé˜²æ­¢æ·»åŠ åŸæ–‡æ²¡æœ‰çš„å†…å®¹")
            
            # 5. è¾“å‡ºæ ¼å¼
            with st.expander("ğŸ“ è¾“å‡ºæ ¼å¼æ¨¡æ¿", expanded=True):
                st.markdown(result.format_template)
                st.caption("ğŸ’¡ ç»“æ„åŒ–æ ¼å¼è®©æ‘˜è¦æ›´æ¸…æ™°æ˜“è¯»")
            
            # 6. å¤„ç†æ­¥éª¤
            with st.expander("ğŸ”„ æ€è€ƒæ­¥éª¤å¼•å¯¼", expanded=False):
                st.write(result.step_by_step_guide)
            
            # 7. å…³æ³¨ç‚¹
            with st.expander("ğŸ¯ æ ¸å¿ƒå…³æ³¨é¢†åŸŸ", expanded=False):
                for idx, area in enumerate(result.focus_areas, 1):
                    st.markdown(f"**å…³æ³¨ç‚¹ {idx}:** {area}")
            
            # 8. æœ€ç»ˆ Prompt
            st.markdown("**âœ¨ æœ€ç»ˆå®Œæ•´çš„æ‘˜è¦ Promptï¼ˆå¯ç›´æ¥å¤åˆ¶ï¼‰ï¼š**")
            st.caption("ğŸ’¡ ç”¨ {{text}} å ä½ç¬¦è¡¨ç¤ºå¾…æ‘˜è¦çš„æ–‡æœ¬")
            st.text_area(
                "æ‘˜è¦å™¨ Prompt",
                value=result.final_prompt,
                height=400,
                label_visibility="collapsed"
            )
            
            # å¤åˆ¶æŒ‰é’®
            if st.button("ğŸ“‹ å¤åˆ¶åˆ°å‰ªè´´æ¿", use_container_width=True, key="copy_summarization"):
                st.code(result.final_prompt, language=None)
                st.success("âœ… å·²æ˜¾ç¤ºåœ¨ä»£ç æ¡†ä¸­ï¼Œè¯·æ‰‹åŠ¨å¤åˆ¶")

# ç¿»è¯‘ä»»åŠ¡åˆ†æ”¯
elif task_type == "ç¿»è¯‘ä»»åŠ¡":
    with col1:
        st.subheader("ğŸŒ ç¿»è¯‘ä»»åŠ¡é…ç½®")
        st.info("ğŸ“Œ é«˜è´¨é‡ç¿»è¯‘éœ€è¦ï¼šå‡†ç¡®çš„æœ¯è¯­ + ç¬¦åˆæ–‡åŒ–çš„è¡¨è¾¾ã€‚ç³»ç»Ÿå°†ä¸ºæ‚¨æ„å»º'ä¿¡è¾¾é›…'çš„ç¿»è¯‘æŒ‡ä»¤ã€‚")
        
        # è¯­è¨€æ–¹å‘é…ç½®
        st.markdown("**ğŸ”„ ç¿»è¯‘æ–¹å‘**")
        lang_col1, lang_col2 = st.columns(2)
        with lang_col1:
            source_lang = st.selectbox(
                "æºè¯­è¨€",
                ["ä¸­æ–‡", "è‹±æ–‡", "æ—¥æ–‡", "æ³•æ–‡", "å¾·æ–‡", "è¥¿ç­ç‰™æ–‡", "éŸ©æ–‡"],
                help="è¦ç¿»è¯‘çš„åŸå§‹æ–‡æœ¬è¯­è¨€"
            )
        with lang_col2:
            target_lang = st.selectbox(
                "ç›®æ ‡è¯­è¨€",
                ["è‹±æ–‡", "ä¸­æ–‡", "æ—¥æ–‡", "æ³•æ–‡", "å¾·æ–‡", "è¥¿ç­ç‰™æ–‡", "éŸ©æ–‡"],
                index=1,
                help="ç¿»è¯‘åçš„ç›®æ ‡è¯­è¨€"
            )
        
        # é¢†åŸŸé€‰æ‹©
        st.markdown("**ğŸ“š åº”ç”¨é¢†åŸŸ**")
        domain = st.selectbox(
            "é€‰æ‹©ç¿»è¯‘é¢†åŸŸ",
            [
                "é€šç”¨æ—¥å¸¸",
                "IT/æŠ€æœ¯æ–‡æ¡£",
                "æ³•å¾‹åˆåŒ",
                "å­¦æœ¯è®ºæ–‡",
                "å•†åŠ¡é‚®ä»¶",
                "æ–‡å­¦/å°è¯´",
                "åŒ»å­¦æ–‡æ¡£",
                "æ–°é—»æŠ¥é“",
                "è¥é”€æ–‡æ¡ˆ",
                "æ¸¸æˆæœ¬åœ°åŒ–"
            ],
            help="ä¸åŒé¢†åŸŸéœ€è¦ä¸åŒçš„ä¸“ä¸šæœ¯è¯­å’Œè¡¨è¾¾é£æ ¼"
        )
        
        # é£æ ¼é€‰æ‹©
        st.markdown("**ğŸ¨ æœŸæœ›é£æ ¼**")
        tone = st.selectbox(
            "é€‰æ‹©ç¿»è¯‘é£æ ¼",
            [
                "æ ‡å‡†/å‡†ç¡®",
                "åœ°é“/å£è¯­åŒ–",
                "ä¼˜ç¾/æ–‡å­¦æ€§",
                "æç®€/æ‘˜è¦å¼",
                "æ­£å¼/å•†åŠ¡",
                "è½»æ¾/æ´»æ³¼"
            ],
            help="å†³å®šè¯‘æ–‡çš„è¡¨è¾¾æ–¹å¼å’Œè¯­è¨€é£æ ¼"
        )
        
        # æœ¯è¯­è¡¨ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰
        st.markdown("**ğŸ“– æœ¯è¯­åº“ï¼ˆGlossaryï¼‰- å¯é€‰**")
        st.caption("å¼ºåˆ¶æŒ‡å®šæŸäº›è¯çš„è¯‘æ³•ï¼Œç¡®ä¿æœ¯è¯­ä¸€è‡´æ€§ã€‚æ¯è¡Œä¸€ä¸ªï¼Œæ ¼å¼ï¼šåŸæ–‡=è¯‘æ–‡")
        glossary_input = st.text_area(
            "æœ¯è¯­æ˜ å°„",
            height=120,
            placeholder="""ä¾‹å¦‚ï¼ˆITé¢†åŸŸï¼‰ï¼š
Prompt Engineering=æç¤ºè¯å·¥ç¨‹
LLM=å¤§è¯­è¨€æ¨¡å‹
Token=ä»¤ç‰Œ
Fine-tuning=å¾®è°ƒ

ä¾‹å¦‚ï¼ˆæ–‡å­¦ä½œå“ï¼‰ï¼š
ä¿®ç‚¼=Cultivation
ç­‘åŸº=Foundation Establishment
é‡‘ä¸¹=Golden Core""",
            help="ä¸“æœ‰åè¯çš„å¼ºåˆ¶å¯¹åº”å…³ç³»ï¼Œæ¨¡å‹å°†ä¸¥æ ¼éµå®ˆ"
        )
        
        # æ„å»ºç¿»è¯‘å™¨æŒ‰é’®
        build_translation_btn = st.button("ğŸ”¨ æ„å»ºç¿»è¯‘å™¨ Prompt", type="primary", use_container_width=True)
    
    # ç¿»è¯‘ä»»åŠ¡ä¼˜åŒ–é€»è¾‘
    if build_translation_btn:
        if source_lang == target_lang:
            st.error("âŒ æºè¯­è¨€å’Œç›®æ ‡è¯­è¨€ä¸èƒ½ç›¸åŒï¼")
        elif not api_key_input or api_key_input.strip() == "":
            st.error("âŒ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® API Key")
        else:
            with st.spinner("ğŸ”® æ­£åœ¨è®¾è®¡é¢†åŸŸä¸“å®¶è§’è‰²ã€æ¤å…¥æœ¯è¯­åº“ã€æ„å»ºä¸‰æ­¥ç¿»è¯‘æ³•..."):
                try:
                    # åˆ›å»ºä¼˜åŒ–å™¨
                    optimizer = PromptOptimizer(
                        api_key=api_key_input,
                        model=model_choice,
                        base_url=base_url if base_url else None,
                        provider=api_provider.lower()
                    )
                    
                    # æ‰§è¡Œç¿»è¯‘ä»»åŠ¡ä¼˜åŒ–
                    result = optimizer.optimize_translation(
                        source_lang=source_lang,
                        target_lang=target_lang,
                        domain=domain,
                        tone=tone,
                        user_glossary=glossary_input
                    )
                    
                    # ä¿å­˜ç»“æœ
                    st.session_state.translation_result = result
                    
                    st.success("âœ… ç¿»è¯‘å™¨ Prompt æ„å»ºå®Œæˆï¼")
                    
                except Exception as e:
                    error_msg = str(e)
                    st.error(f"âŒ æ„å»ºå¤±è´¥ï¼š{error_msg}")
                    
                    # æä¾›è§£å†³æ–¹æ¡ˆ
                    if "404" in error_msg or "401" in error_msg:
                        st.warning("""**å¯èƒ½çš„åŸå› å’Œè§£å†³æ–¹æ¡ˆï¼š**""")
                        if api_provider == "NVIDIA":
                            st.markdown("""
                            1. **API Key æ— æ•ˆæˆ–æœªé…ç½®**
                               - è¯·è®¿é—® [NVIDIA Build](https://build.nvidia.com/) è·å– API Key
                            2. **æ¨¡å‹ä¸æ”¯æŒ**
                               - æ¨èä½¿ç”¨ meta/llama-3.1-405b-instruct
                            """)
                    
                    st.info("ğŸ”§ å»ºè®®ï¼šè¿è¡Œ `python test_nvidia.py` æµ‹è¯• API è¿æ¥")
    
    # æ˜¾ç¤ºç¿»è¯‘ä»»åŠ¡ä¼˜åŒ–ç»“æœ
    if st.session_state.translation_result:
        result = st.session_state.translation_result
        
        with col2:
            st.subheader("ğŸŒ ç¿»è¯‘å™¨ Prompt")
            
            # 1. ä¼˜åŒ–æ€è·¯
            with st.expander("ğŸ§  æŸ¥çœ‹ä¼˜åŒ–æ€è·¯", expanded=True):
                st.write(result.thinking_process)
            
            # 2. è§’è‰²è®¾å®š
            with st.expander("ğŸ‘¤ é¢†åŸŸä¸“å®¶è§’è‰²", expanded=True):
                st.info(result.role_definition)
                st.caption("ğŸ’¡ æ ¹æ®ç¿»è¯‘é¢†åŸŸè®¾å®šçš„ä¸“ä¸šè§’è‰²ï¼Œç¡®ä¿è¯‘æ–‡ä¸“ä¸šæ€§")
            
            # 3. é£æ ¼æŒ‡å—
            with st.expander("ğŸ¨ é£æ ¼æŒ‡å—", expanded=True):
                for idx, guideline in enumerate(result.style_guidelines, 1):
                    st.markdown(f"**æŒ‡å— {idx}:** {guideline}")
                st.caption("ğŸ’¡ å…·ä½“çš„é£æ ¼è¦æ±‚ï¼Œä½¿è¯‘æ–‡ç¬¦åˆç›®æ ‡è¯­è¨€çš„è¡¨è¾¾ä¹ æƒ¯")
            
            # 4. æœ¯è¯­è¡¨ï¼ˆå¦‚æœæœ‰ï¼‰
            if result.glossary_section and result.glossary_section.strip():
                with st.expander("ğŸ“– æœ¯è¯­å¯¹ç…§è¡¨ï¼ˆå¼ºåˆ¶éµå®ˆï¼‰", expanded=True):
                    st.markdown(result.glossary_section)
                    st.caption("ğŸ’¡ ä¸“æœ‰åè¯çš„é”å®šç¿»è¯‘ï¼Œç¡®ä¿æœ¯è¯­ä¸€è‡´æ€§")
            
            # 5. ç¿»è¯‘æµç¨‹
            with st.expander("ğŸ”„ ä¸‰æ­¥ç¿»è¯‘æ³•", expanded=True):
                st.markdown(result.workflow_steps)
                st.caption("ğŸ’¡ åˆ†æ­¥éª¤çš„ç¿»è¯‘æµç¨‹ï¼Œé¿å…æœºæ¢°ç›´è¯‘")
            
            # 6. æœ€ç»ˆ Prompt
            st.markdown("**âœ¨ æœ€ç»ˆå®Œæ•´çš„ç¿»è¯‘ Promptï¼ˆå¯ç›´æ¥å¤åˆ¶ï¼‰ï¼š**")
            st.caption("ğŸ’¡ ç”¨ {{text}} å ä½ç¬¦è¡¨ç¤ºå¾…ç¿»è¯‘çš„æ–‡æœ¬")
            st.text_area(
                "ç¿»è¯‘å™¨ Prompt",
                value=result.final_prompt,
                height=450,
                label_visibility="collapsed"
            )
            
            # å¤åˆ¶æŒ‰é’®
            if st.button("ğŸ“‹ å¤åˆ¶åˆ°å‰ªè´´æ¿", use_container_width=True, key="copy_translation"):
                st.code(result.final_prompt, language=None)
                st.success("âœ… å·²æ˜¾ç¤ºåœ¨ä»£ç æ¡†ä¸­ï¼Œè¯·æ‰‹åŠ¨å¤åˆ¶")
            
            # ä½¿ç”¨ç¤ºä¾‹
            with st.expander("ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹", expanded=False):
                st.markdown(f"""
**å¦‚ä½•ä½¿ç”¨è¿™ä¸ªç¿»è¯‘ Promptï¼š**

1. å¤åˆ¶ä¸Šé¢çš„å®Œæ•´ Prompt
2. å°† `{{{{text}}}}` æ›¿æ¢ä¸ºæ‚¨è¦ç¿»è¯‘çš„å®é™…æ–‡æœ¬
3. å‘é€ç»™ LLMï¼ˆå¦‚ ChatGPTã€Claudeã€Llama ç­‰ï¼‰

**ç¤ºä¾‹ï¼ˆ{source_lang} â†’ {target_lang}ï¼‰ï¼š**
```
{result.final_prompt[:200]}...
[è¿™é‡Œæ”¾å…¥æ‚¨çš„ {source_lang} æ–‡æœ¬]
```

**ä¸“ä¸šæç¤ºï¼š**
- âœ… æœ¯è¯­è¡¨å¯ä»¥éšæ—¶æ›´æ–°ï¼Œæ¯æ¬¡ç¿»è¯‘æ—¶ä¿æŒä¸€è‡´
- âœ… å¯¹äºä¸“ä¸šæ–‡æ¡£ï¼Œå»ºè®®å…ˆç¿»è¯‘ä¸€å°æ®µæµ‹è¯•æ•ˆæœ
- âœ… å¦‚æœè¯‘æ–‡ä¸å¤Ÿåœ°é“ï¼Œå¯ä»¥è¦æ±‚æ¨¡å‹"å†æ¬¡æ¶¦è‰²"
                """)

# ========== æ•ˆæœéªŒè¯å®éªŒå®¤ ==========
st.markdown("---")
st.header("ğŸ§ª æ•ˆæœéªŒè¯å®éªŒå®¤")
st.markdown("åœ¨æ­¤è¾“å…¥æµ‹è¯•æ•°æ®å’Œæ ‡å‡†ç­”æ¡ˆï¼Œç³»ç»Ÿå°†è‡ªåŠ¨è®¡ç®—æ€§èƒ½æŒ‡æ ‡ï¼ˆAccuracy / BLEU / ROUGEï¼‰ã€‚")

# åˆ¤æ–­æ˜¯å¦å·²ç»ç”Ÿæˆäº†ä¼˜åŒ–åçš„ Prompt
has_result = False
current_result = None
placeholder_text = ""

if task_type == "ç”Ÿæˆä»»åŠ¡" and st.session_state.result:
    has_result = True
    current_result = st.session_state.result
    placeholder_text = "å¾…å¤„ç†çš„è¾“å…¥"
elif task_type == "åˆ†ç±»ä»»åŠ¡" and st.session_state.classification_result:
    has_result = True
    current_result = st.session_state.classification_result
    placeholder_text = "å¾…åˆ†ç±»çš„æ–‡æœ¬"
elif task_type == "æ‘˜è¦ä»»åŠ¡" and st.session_state.summarization_result:
    has_result = True
    current_result = st.session_state.summarization_result
    placeholder_text = "å¾…æ‘˜è¦çš„æ–‡æœ¬"
elif task_type == "ç¿»è¯‘ä»»åŠ¡" and st.session_state.translation_result:
    has_result = True
    current_result = st.session_state.translation_result
    placeholder_text = "å¾…ç¿»è¯‘çš„æ–‡æœ¬"

if not has_result:
    st.info("ğŸ’¡ è¯·å…ˆåœ¨ä¸Šæ–¹å®Œæˆ Prompt ä¼˜åŒ–ï¼Œç„¶åå†è¿›è¡Œæ•ˆæœéªŒè¯ã€‚")
else:
    st.success(f"âœ… æ£€æµ‹åˆ°å·²ä¼˜åŒ–çš„ {task_type} Promptï¼Œå¯ä»¥å¼€å§‹éªŒè¯ï¼")
    
    # éªŒè¯åŒºåŸŸ
    col_test1, col_test2 = st.columns(2)
    
    with col_test1:
        st.markdown("**ğŸ“ æµ‹è¯•è¾“å…¥**")
        
        # æ ¹æ®ä»»åŠ¡ç±»å‹æ˜¾ç¤ºä¸åŒçš„æç¤º
        if task_type == "åˆ†ç±»ä»»åŠ¡":
            placeholder_hint = """ç¤ºä¾‹ï¼ˆæ¯è¡Œä¸€ä¸ªæµ‹è¯•æ ·æœ¬ï¼‰ï¼š
è¿™ä¸ªäº§å“çœŸçš„å¾ˆå¥½ç”¨ï¼Œéå¸¸æ»¡æ„ï¼
ä»·æ ¼å¤ªè´µäº†ï¼Œæ€§ä»·æ¯”ä¸é«˜ã€‚
è¿˜å¯ä»¥å§ï¼Œæ²¡æœ‰ç‰¹åˆ«çš„æ„Ÿè§‰ã€‚"""
            help_text = "åˆ†ç±»ä»»åŠ¡æ”¯æŒæ‰¹é‡æµ‹è¯•ï¼šæ¯è¡Œä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ï¼Œç³»ç»Ÿä¼šä¾æ¬¡åˆ†ç±»å¹¶è®¡ç®—æ•´ä½“å‡†ç¡®ç‡"
        elif task_type == "æ‘˜è¦ä»»åŠ¡":
            placeholder_hint = f"è¾“å…¥{placeholder_text}..."
            help_text = "æ‘˜è¦ä»»åŠ¡è¾“å…¥å•ä¸ªé•¿æ–‡æœ¬è¿›è¡Œæµ‹è¯•"
        elif task_type == "ç¿»è¯‘ä»»åŠ¡":
            placeholder_hint = f"è¾“å…¥{placeholder_text}..."
            help_text = "ç¿»è¯‘ä»»åŠ¡è¾“å…¥å•ä¸ªæ–‡æœ¬è¿›è¡Œæµ‹è¯•"
        else:
            placeholder_hint = f"è¾“å…¥{placeholder_text}..."
            help_text = "è¾“å…¥éœ€è¦æµ‹è¯•çš„æ•°æ®"
        
        test_input = st.text_area(
            "è¾“å…¥æµ‹è¯•æ•°æ®",
            height=150,
            placeholder=placeholder_hint,
            key="test_input",
            help=help_text
        )
        
        # è¯­è¨€è®¾ç½®ï¼ˆç”¨äº ROUGE å’Œ BLEUï¼‰
        if task_type in ["æ‘˜è¦ä»»åŠ¡", "ç¿»è¯‘ä»»åŠ¡"]:
            test_lang = st.selectbox(
                "æµ‹è¯•æ•°æ®è¯­è¨€",
                ["ä¸­æ–‡", "è‹±æ–‡"],
                key="test_lang",
                help="ç”¨äºæ­£ç¡®è®¡ç®— ROUGE/BLEU åˆ†æ•°ï¼ˆä¸­æ–‡éœ€è¦åˆ†è¯ï¼‰"
            )
    
    with col_test2:
        st.markdown("**âœ… æ ‡å‡†å‚è€ƒç­”æ¡ˆ**")
        
        # æ ¹æ®ä»»åŠ¡ç±»å‹æ˜¾ç¤ºä¸åŒçš„æç¤º
        if task_type == "åˆ†ç±»ä»»åŠ¡":
            ref_placeholder = """ç¤ºä¾‹ï¼ˆæ¯è¡Œä¸€ä¸ªæ ‡ç­¾ï¼Œä¸æµ‹è¯•æ•°æ®ä¸€ä¸€å¯¹åº”ï¼‰ï¼š
ç§¯æ
æ¶ˆæ
ä¸­ç«‹"""
            ref_help = "æ¯è¡Œä¸€ä¸ªæ ‡ç­¾ï¼Œé¡ºåºä¸å·¦ä¾§æµ‹è¯•æ•°æ®å¯¹åº”"
        elif task_type == "æ‘˜è¦ä»»åŠ¡":
            ref_placeholder = "è¾“å…¥äººå·¥æ’°å†™çš„æ ‡å‡†æ‘˜è¦..."
            ref_help = "ç”¨äºè®¡ç®— ROUGE åˆ†æ•°çš„å‚è€ƒæ‘˜è¦"
        elif task_type == "ç¿»è¯‘ä»»åŠ¡":
            ref_placeholder = "è¾“å…¥äººå·¥ç¿»è¯‘çš„æ ‡å‡†è¯‘æ–‡..."
            ref_help = "ç”¨äºè®¡ç®— BLEU åˆ†æ•°çš„å‚è€ƒè¯‘æ–‡"
        else:
            ref_placeholder = "è¾“å…¥æ ‡å‡†ç­”æ¡ˆæˆ–æœŸæœ›è¾“å‡º..."
            ref_help = "ç”¨äºè®¡ç®—è¯„ä¼°æŒ‡æ ‡çš„å‚è€ƒç­”æ¡ˆ"
        
        reference_output = st.text_area(
            "å‚è€ƒç­”æ¡ˆ",
            height=150,
            placeholder=ref_placeholder,
            key="reference_output",
            help=ref_help
        )
        
        st.caption("ğŸ’¡ **ä¸ºä»€ä¹ˆéœ€è¦å‚è€ƒç­”æ¡ˆï¼Ÿ**")
        if task_type == "åˆ†ç±»ä»»åŠ¡":
            st.caption("Accuracy éœ€è¦å¯¹æ¯”ã€Œæ¨¡å‹é¢„æµ‹ã€å’Œã€Œæ­£ç¡®æ ‡ç­¾ã€ã€‚æ”¯æŒæ‰¹é‡æµ‹è¯•ï¼Œæ›´å‡†ç¡®è¯„ä¼°åˆ†ç±»æ•ˆæœã€‚")
        else:
            st.caption("Accuracy/BLEU/ROUGE ç­‰æ•°å­¦æŒ‡æ ‡éœ€è¦å¯¹æ¯”ã€Œæ¨¡å‹è¾“å‡ºã€å’Œã€Œæ ‡å‡†ç­”æ¡ˆã€æ¥è®¡ç®—åˆ†æ•°ã€‚")
    
    # è¿è¡Œè¯„ä¼°æŒ‰é’®
    if st.button("ğŸš€ è¿è¡Œ Prompt å¹¶è®¡ç®—æŒ‡æ ‡", type="primary", use_container_width=True):
        if not test_input or not reference_output:
            st.error("âŒ è¯·åŒæ—¶æä¾›æµ‹è¯•è¾“å…¥å’Œå‚è€ƒç­”æ¡ˆï¼")
        elif not api_key_input or api_key_input.strip() == "":
            st.error("âŒ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® API Key")
        else:
            # æ·»åŠ è¯¦ç»†æ—¥å¿—
            print(f"\n{'='*60}")
            print(f"ğŸ§ª å¼€å§‹æ•ˆæœéªŒè¯")
            print(f"{'='*60}")
            print(f"ğŸ“‹ ä»»åŠ¡ç±»å‹: {task_type}")
            print(f"ğŸ“ æµ‹è¯•è¾“å…¥é•¿åº¦: {len(test_input)} å­—ç¬¦")
            print(f"âœ… å‚è€ƒç­”æ¡ˆé•¿åº¦: {len(reference_output)} å­—ç¬¦")
            print(f"ğŸ”Œ API æä¾›å•†: {api_provider}")
            print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model_choice}")
            print(f"{'='*60}\n")
            
            with st.spinner("ğŸ”® æ¨¡å‹æ­£åœ¨æ ¹æ®ä¼˜åŒ–åçš„ Prompt ç”Ÿæˆç»“æœ..."):
                try:
                    print("ğŸ”§ æ­¥éª¤ 1: åˆ›å»ºä¼˜åŒ–å™¨...")
                    # åˆ›å»ºä¼˜åŒ–å™¨ï¼ˆä½¿ç”¨ç›¸åŒçš„é…ç½®ï¼‰
                    optimizer = PromptOptimizer(
                        api_key=api_key_input,
                        model=model_choice,
                        base_url=base_url if base_url else None,
                        provider=api_provider.lower()
                    )
                    print("âœ… ä¼˜åŒ–å™¨åˆ›å»ºæˆåŠŸ")
                    
                    print("\nğŸ”§ æ­¥éª¤ 2: æ„å»ºæœ€ç»ˆ Prompt...")
                    
                    # æ™ºèƒ½æ›¿æ¢å‡½æ•°ï¼šå°è¯•å¤šç§å ä½ç¬¦æ ¼å¼
                    def smart_replace(template: str, text: str, task_type_name: str = "") -> str:
                        """æ™ºèƒ½æ›¿æ¢å„ç§å¯èƒ½çš„å ä½ç¬¦æ ¼å¼"""
                        # è®°å½•åŸå§‹æ¨¡æ¿
                        original = template
                        
                        # å°è¯•å„ç§å ä½ç¬¦æ ¼å¼ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
                        replacements = [
                            # æ ‡å‡†å ä½ç¬¦
                            ("{{text}}", text),
                            ("{text}", text),
                            ("{{input}}", text),
                            ("{input}", text),
                            
                            # ä¸­æ–‡æ–¹æ‹¬å·å ä½ç¬¦
                            ("[è¾“å…¥è¯„è®º]", text),
                            ("[å¾…åˆ†ç±»æ–‡æœ¬]", text),
                            ("[å¾…ç¿»è¯‘æ–‡æœ¬]", text),
                            ("[å¾…æ‘˜è¦æ–‡æœ¬]", text),
                            ("[è¾“å…¥æ–‡æœ¬]", text),
                            ("[æ–‡æœ¬å†…å®¹]", text),
                            ("[ç”¨æˆ·è¾“å…¥]", text),
                            
                            # ä¸­æ–‡èŠ±æ‹¬å·å ä½ç¬¦
                            ("ã€è¾“å…¥è¯„è®ºã€‘", text),
                            ("ã€å¾…åˆ†ç±»æ–‡æœ¬ã€‘", text),
                            ("ã€å¾…ç¿»è¯‘æ–‡æœ¬ã€‘", text),
                            ("ã€å¾…æ‘˜è¦æ–‡æœ¬ã€‘", text),
                            ("ã€è¾“å…¥æ–‡æœ¬ã€‘", text),
                            ("ã€æ–‡æœ¬å†…å®¹ã€‘", text),
                            ("ã€å¾…å¤„ç†æ–‡æœ¬ã€‘", text),
                            
                            # è‹±æ–‡æè¿°æ€§å ä½ç¬¦
                            ("[INPUT]", text),
                            ("[TEXT]", text),
                            ("[CONTENT]", text),
                            ("{INPUT}", text),
                            ("{TEXT}", text),
                            
                            # å…¶ä»–å¸¸è§æ ¼å¼
                            ("<text>", text),
                            ("<input>", text),
                            ("$text", text),
                            ("$input", text),
                        ]
                        
                        result = template
                        replaced_count = 0
                        replaced_placeholders = []
                        
                        for placeholder, replacement in replacements:
                            if placeholder in result:
                                old_result = result
                                result = result.replace(placeholder, replacement)
                                if result != old_result:
                                    replaced_count += 1
                                    replaced_placeholders.append(placeholder)
                                    print(f"   âœ… æ›¿æ¢ '{placeholder}' -> å®é™…æ–‡æœ¬")
                        
                        if replaced_count == 0:
                            print(f"   âš ï¸ è­¦å‘Šï¼šæœªæ‰¾åˆ°ä»»ä½•å ä½ç¬¦ï¼")
                            print(f"   ğŸ“‹ å®Œæ•´æ¨¡æ¿å†…å®¹ï¼š")
                            print(f"   {template}")
                            print(f"   ğŸ’¡ æç¤ºï¼šè¯·æ£€æŸ¥æ¨¡æ¿ä¸­ä½¿ç”¨çš„å ä½ç¬¦æ ¼å¼")
                            print(f"   ğŸ”§ å°è¯•è‡ªåŠ¨ä¿®å¤ï¼šåœ¨ Prompt æœ«å°¾æ·»åŠ æ–‡æœ¬æ’å…¥ä½ç½®...")
                            
                            # æ ¹æ®ä»»åŠ¡ç±»å‹æ·»åŠ åˆé€‚çš„æç¤ºè¯­
                            if "åˆ†ç±»" in task_type_name:
                                result = template + f"\n\nå¾…åˆ†ç±»æ–‡æœ¬ï¼š{text}\n\nè¯·åˆ†æä¸Šè¿°æ–‡æœ¬å¹¶è¾“å‡ºåˆ†ç±»ç»“æœã€‚"
                            elif "æ‘˜è¦" in task_type_name:
                                result = template + f"\n\nå¾…æ‘˜è¦æ–‡æœ¬ï¼š\n{text}\n\nè¯·æ ¹æ®ä¸Šè¿°è¦æ±‚ç”Ÿæˆæ‘˜è¦ã€‚"
                            elif "ç¿»è¯‘" in task_type_name:
                                result = template + f"\n\nå¾…ç¿»è¯‘æ–‡æœ¬ï¼š\n{text}\n\nè¯·ç¿»è¯‘ä¸Šè¿°æ–‡æœ¬ã€‚"
                            else:
                                result = template + f"\n\nè¾“å…¥å†…å®¹ï¼š{text}"
                            
                            print(f"   âœ… å·²è‡ªåŠ¨æ·»åŠ æ–‡æœ¬åˆ° Prompt æœ«å°¾ï¼ˆä»»åŠ¡ç±»å‹ï¼š{task_type_name}ï¼‰")
                        else:
                            print(f"   âœ… æˆåŠŸæ›¿æ¢ {replaced_count} ä¸ªå ä½ç¬¦: {', '.join(replaced_placeholders)}")
                        
                        return result
                    
                    # æ ¹æ®ä»»åŠ¡ç±»å‹æ„å»ºæœ€ç»ˆ Prompt
                    if task_type == "ç”Ÿæˆä»»åŠ¡":
                        # ç”Ÿæˆä»»åŠ¡ç›´æ¥ä½¿ç”¨ä¼˜åŒ–åçš„ prompt
                        print("ğŸ“„ ä½¿ç”¨ç”Ÿæˆä»»åŠ¡ Prompt æ¨¡æ¿")
                        template = current_result.improved_prompt
                        print(f"ğŸ“‹ æ¨¡æ¿é•¿åº¦: {len(template)} å­—ç¬¦")
                        if len(template) < 100:
                            print(f"   âš ï¸ è­¦å‘Šï¼šPrompt å¤ªçŸ­ï¼Œå¯èƒ½ä¸å®Œæ•´ï¼")
                        print(f"ğŸ“‹ æ¨¡æ¿å‰500å­—ç¬¦: {template[:500]}...")
                        final_prompt = smart_replace(template, test_input, task_type)
                        
                    elif task_type == "åˆ†ç±»ä»»åŠ¡":
                        print("ğŸ“„ ä½¿ç”¨åˆ†ç±»ä»»åŠ¡ Prompt æ¨¡æ¿")
                        template = current_result.final_prompt
                        print(f"ğŸ“‹ æ¨¡æ¿é•¿åº¦: {len(template)} å­—ç¬¦")
                        
                        # æ£€æŸ¥ Prompt è´¨é‡
                        if len(template) < 200:
                            print(f"   âš ï¸ è­¦å‘Šï¼šPrompt å¤ªçŸ­ï¼ˆ< 200å­—ç¬¦ï¼‰ï¼Œå¯èƒ½ä¸å®Œæ•´ï¼")
                            print(f"   ğŸ’¡ å»ºè®®ï¼šæ£€æŸ¥ LLM æ˜¯å¦æ­£ç¡®ç”Ÿæˆäº†å®Œæ•´çš„ final_prompt")
                            st.warning("âš ï¸ æ£€æµ‹åˆ°ç”Ÿæˆçš„ Prompt è¾ƒçŸ­ï¼Œå¯èƒ½å½±å“åˆ†ç±»æ•ˆæœã€‚å»ºè®®é‡æ–°ç”Ÿæˆ Promptã€‚")
                        
                        print(f"ğŸ“‹ æ¨¡æ¿å‰500å­—ç¬¦:\n{template[:500]}...")
                        if len(template) > 500:
                            print(f"ğŸ“‹ æ¨¡æ¿å200å­—ç¬¦:\n...{template[-200:]}")
                        
                        final_prompt = smart_replace(template, test_input, task_type)
                        
                    elif task_type == "æ‘˜è¦ä»»åŠ¡":
                        print("ğŸ“„ ä½¿ç”¨æ‘˜è¦ä»»åŠ¡ Prompt æ¨¡æ¿")
                        template = current_result.final_prompt
                        print(f"ğŸ“‹ æ¨¡æ¿é•¿åº¦: {len(template)} å­—ç¬¦")
                        if len(template) < 200:
                            print(f"   âš ï¸ è­¦å‘Šï¼šPrompt å¤ªçŸ­ï¼Œå¯èƒ½ä¸å®Œæ•´ï¼")
                        print(f"ğŸ“‹ æ¨¡æ¿å‰500å­—ç¬¦: {template[:500]}...")
                        final_prompt = smart_replace(template, test_input, task_type)
                        
                    elif task_type == "ç¿»è¯‘ä»»åŠ¡":
                        print("ğŸ“„ ä½¿ç”¨ç¿»è¯‘ä»»åŠ¡ Prompt æ¨¡æ¿")
                        template = current_result.final_prompt
                        print(f"ğŸ“‹ æ¨¡æ¿é•¿åº¦: {len(template)} å­—ç¬¦")
                        if len(template) < 200:
                            print(f"   âš ï¸ è­¦å‘Šï¼šPrompt å¤ªçŸ­ï¼Œå¯èƒ½ä¸å®Œæ•´ï¼")
                        print(f"ğŸ“‹ æ¨¡æ¿å‰500å­—ç¬¦: {template[:500]}...")
                        final_prompt = smart_replace(template, test_input, task_type)
                    
                    print(f"\nâœ… Prompt æ„å»ºå®Œæˆ")
                    print(f"ğŸ“ æœ€ç»ˆ Prompt é•¿åº¦: {len(final_prompt)} å­—ç¬¦")
                    print(f"ğŸ“‹ æœ€ç»ˆ Promptï¼ˆå‰300å­—ç¬¦ï¼‰:\n{final_prompt[:300]}...")
                    print(f"\nğŸ” æ£€æŸ¥å ä½ç¬¦æ˜¯å¦è¢«æ›¿æ¢:")
                    print(f"   - æ˜¯å¦è¿˜åŒ…å« '{{{{text}}}}': {'{{text}}' in final_prompt}")
                    print(f"   - æ˜¯å¦è¿˜åŒ…å« '{{text}}': {'{text}' in final_prompt}")
                    print(f"   - æ˜¯å¦åŒ…å«æµ‹è¯•è¾“å…¥: {test_input[:20] in final_prompt if len(test_input) > 20 else test_input in final_prompt}")
                    
                    print("\nğŸ”§ æ­¥éª¤ 3: è°ƒç”¨ LLM...")
                    # è°ƒç”¨ LLM
                    response = optimizer.llm.invoke(final_prompt)
                    prediction = response.content
                    print(f"âœ… LLM å“åº”æˆåŠŸ")
                    print(f"ğŸ“ é¢„æµ‹ç»“æœé•¿åº¦: {len(prediction)} å­—ç¬¦")
                    print(f"ğŸ“‹ é¢„æµ‹ç»“æœï¼ˆå‰200å­—ç¬¦ï¼‰: {prediction[:200]}...")
                    
                    # ä¿å­˜é¢„æµ‹ç»“æœ
                    st.session_state.prediction = prediction
                    st.session_state.test_reference = reference_output
                    
                    # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
                    st.markdown("---")
                    st.subheader("ğŸ¤– æ¨¡å‹é¢„æµ‹ç»“æœ")
                    st.info(prediction)
                    
                    print("\nğŸ”§ æ­¥éª¤ 4: è®¡ç®—è¯„ä¼°æŒ‡æ ‡...")
                    # è®¡ç®—æŒ‡æ ‡
                    st.markdown("---")
                    st.subheader("ğŸ“Š æ€§èƒ½è¯„åˆ†")
                    
                    calc = MetricsCalculator()
                    print(f"ğŸ“Š ä»»åŠ¡ç±»å‹: {task_type}")
                    
                    # æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©æŒ‡æ ‡
                    if task_type == "åˆ†ç±»ä»»åŠ¡":
                        print("ğŸ“ˆ è®¡ç®—åˆ†ç±»ä»»åŠ¡ Accuracy...")
                        
                        # åˆ†ç±»ä»»åŠ¡æ”¯æŒæ‰¹é‡æµ‹è¯•ï¼šæŒ‰è¡Œåˆ†å‰²
                        test_samples = [line.strip() for line in test_input.strip().split('\n') if line.strip()]
                        reference_labels = [line.strip() for line in reference_output.strip().split('\n') if line.strip()]
                        
                        print(f"   ğŸ”¹ æµ‹è¯•æ ·æœ¬æ•°: {len(test_samples)}")
                        print(f"   ğŸ”¹ å‚è€ƒæ ‡ç­¾æ•°: {len(reference_labels)}")
                        
                        # æ£€æŸ¥æ•°é‡æ˜¯å¦åŒ¹é…
                        if len(test_samples) != len(reference_labels):
                            st.error(f"âŒ æµ‹è¯•æ ·æœ¬æ•°é‡ ({len(test_samples)}) ä¸å‚è€ƒæ ‡ç­¾æ•°é‡ ({len(reference_labels)}) ä¸åŒ¹é…ï¼")
                            print(f"   âŒ æ•°é‡ä¸åŒ¹é…ï¼")
                        else:
                            # å¦‚æœåªæœ‰ä¸€ä¸ªæ ·æœ¬ï¼Œç›´æ¥ä½¿ç”¨ä¹‹å‰çš„é¢„æµ‹ç»“æœ
                            if len(test_samples) == 1:
                                pred_clean = prediction.strip().split('\n')[0].strip()
                                predictions = [pred_clean]
                                print(f"   ğŸ”¹ å•æ ·æœ¬æµ‹è¯•")
                                print(f"   ğŸ”¹ é¢„æµ‹: {pred_clean}")
                                print(f"   ğŸ”¹ å‚è€ƒ: {reference_labels[0]}")
                            else:
                                # æ‰¹é‡é¢„æµ‹ï¼šå¯¹æ¯ä¸ªæ ·æœ¬è°ƒç”¨ä¸€æ¬¡
                                predictions = []
                                print(f"   ğŸ”¹ æ‰¹é‡æµ‹è¯•æ¨¡å¼")
                                
                                progress_bar = st.progress(0)
                                status_text = st.empty()
                                
                                for idx, sample in enumerate(test_samples):
                                    status_text.text(f"æ­£åœ¨å¤„ç† {idx+1}/{len(test_samples)} ...")
                                    
                                    # æ„å»ºå•ä¸ªæ ·æœ¬çš„ Prompt
                                    sample_prompt = smart_replace(template, sample, task_type)
                                    
                                    # è°ƒç”¨ LLM
                                    response = optimizer.llm.invoke(sample_prompt)
                                    pred = response.content.strip().split('\n')[0].strip()
                                    predictions.append(pred)
                                    
                                    print(f"   æ ·æœ¬ {idx+1}: {sample[:30]}... -> é¢„æµ‹: {pred}")
                                    
                                    progress_bar.progress((idx + 1) / len(test_samples))
                                
                                status_text.empty()
                                progress_bar.empty()
                            
                            # è®¡ç®—å‡†ç¡®ç‡
                            score = calc.calculate_accuracy(predictions, reference_labels)
                            print(f"   âœ… Accuracy åˆ†æ•°: {score}%")
                            
                            metric_name = "Accuracy (å‡†ç¡®ç‡)"
                            metric_key = "accuracy"
                            
                            col_m1, col_m2 = st.columns([1, 2])
                            with col_m1:
                                st.metric(label=metric_name, value=f"{score}%")
                                st.caption(f"æµ‹è¯•æ ·æœ¬: {len(test_samples)} ä¸ª")
                                st.caption(f"é¢„æµ‹æ­£ç¡®: {int(score * len(test_samples) / 100)} ä¸ª")
                            with col_m2:
                                level, color, advice = calc.get_metric_interpretation(metric_key, score)
                                st.markdown(f"**è¯„çº§ï¼š** {level}")
                                if color == "success":
                                    st.success(advice)
                                elif color == "warning":
                                    st.warning(advice)
                                elif color == "error":
                                    st.error(advice)
                                else:
                                    st.info(advice)
                            
                            # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
                            with st.expander("ğŸ“‹ æŸ¥çœ‹æ¯ä¸ªæ ·æœ¬çš„é¢„æµ‹ç»“æœ", expanded=False):
                                result_df_data = []
                                for i, (sample, pred, ref) in enumerate(zip(test_samples, predictions, reference_labels), 1):
                                    is_correct = pred.lower() == ref.lower()
                                    result_df_data.append({
                                        "åºå·": i,
                                        "æµ‹è¯•æ–‡æœ¬": sample[:50] + "..." if len(sample) > 50 else sample,
                                        "é¢„æµ‹æ ‡ç­¾": pred,
                                        "æ­£ç¡®æ ‡ç­¾": ref,
                                        "ç»“æœ": "âœ… æ­£ç¡®" if is_correct else "âŒ é”™è¯¯"
                                    })
                                
                                import pandas as pd
                                result_df = pd.DataFrame(result_df_data)
                                st.dataframe(result_df, use_container_width=True)
                    
                    elif task_type == "æ‘˜è¦ä»»åŠ¡":
                        print("ğŸ“ˆ è®¡ç®—æ‘˜è¦ä»»åŠ¡ ROUGE...")
                        # æ‘˜è¦ä»»åŠ¡ï¼šè®¡ç®— ROUGE
                        lang_code = "zh" if test_lang == "ä¸­æ–‡" else "en"
                        print(f"   ğŸ”¹ è¯­è¨€è®¾ç½®: {lang_code}")
                        print(f"   ğŸ”¹ é¢„æµ‹é•¿åº¦: {len(prediction)} å­—ç¬¦")
                        print(f"   ğŸ”¹ å‚è€ƒé•¿åº¦: {len(reference_output)} å­—ç¬¦")
                        
                        rouge_scores = calc.calculate_rouge(prediction, reference_output, lang=lang_code)
                        print(f"   âœ… ROUGE åˆ†æ•°: {rouge_scores}")
                        
                        st.markdown("**ROUGE åˆ†æ•°ï¼š**")
                        col_r1, col_r2, col_r3 = st.columns(3)
                        with col_r1:
                            st.metric("ROUGE-1", f"{rouge_scores['rouge1']}%", help="å•è¯é‡åˆåº¦")
                        with col_r2:
                            st.metric("ROUGE-2", f"{rouge_scores['rouge2']}%", help="åŒè¯ç»„é‡åˆåº¦")
                        with col_r3:
                            st.metric("ROUGE-L", f"{rouge_scores['rougeL']}%", help="æœ€é•¿å…¬å…±å­åºåˆ—")
                        
                        # ä½¿ç”¨ ROUGE-L ä½œä¸ºä¸»è¦è¯„ä»·æŒ‡æ ‡
                        level, color, advice = calc.get_metric_interpretation("rouge", rouge_scores['rougeL'])
                        st.markdown(f"**ç»¼åˆè¯„çº§ï¼ˆåŸºäº ROUGE-Lï¼‰ï¼š** {level}")
                        if color == "success":
                            st.success(advice)
                        elif color == "warning":
                            st.warning(advice)
                        elif color == "error":
                            st.error(advice)
                        else:
                            st.info(advice)
                    
                    elif task_type == "ç¿»è¯‘ä»»åŠ¡":
                        print("ğŸ“ˆ è®¡ç®—ç¿»è¯‘ä»»åŠ¡ BLEU...")
                        # ç¿»è¯‘ä»»åŠ¡ï¼šè®¡ç®— BLEU
                        lang_code = "zh" if test_lang == "ä¸­æ–‡" else "en"
                        print(f"   ğŸ”¹ è¯­è¨€è®¾ç½®: {lang_code}")
                        print(f"   ğŸ”¹ é¢„æµ‹ç¿»è¯‘: {prediction[:100]}...")
                        print(f"   ğŸ”¹ å‚è€ƒç¿»è¯‘: {reference_output[:100]}...")
                        
                        bleu_score = calc.calculate_bleu(prediction, reference_output, lang=lang_code)
                        print(f"   âœ… BLEU åˆ†æ•°: {bleu_score}%")
                        
                        col_b1, col_b2 = st.columns([1, 2])
                        with col_b1:
                            st.metric("BLEU Score", f"{bleu_score}%")
                        with col_b2:
                            level, color, advice = calc.get_metric_interpretation("bleu", bleu_score)
                            st.markdown(f"**è¯„çº§ï¼š** {level}")
                            if color == "success":
                                st.success(advice)
                            elif color == "warning":
                                st.warning(advice)
                            elif color == "error":
                                st.error(advice)
                            else:
                                st.info(advice)
                    
                    elif task_type == "ç”Ÿæˆä»»åŠ¡":
                        print("â„¹ï¸ ç”Ÿæˆä»»åŠ¡ä½¿ç”¨å®šæ€§è¯„ä¼°")
                        # ç”Ÿæˆä»»åŠ¡æ²¡æœ‰æ ‡å‡†æŒ‡æ ‡ï¼Œä½¿ç”¨å®šæ€§è¯„ä¼°
                        st.info("ğŸ’¡ ç”Ÿæˆä»»åŠ¡é€šå¸¸ä½¿ç”¨äººå·¥è¯„ä¼°æˆ– LLM-as-a-Judge è¿›è¡Œè¯„ä»·ï¼Œæš‚ä¸æ”¯æŒè‡ªåŠ¨åŒ–æŒ‡æ ‡ã€‚")
                        st.markdown("**å»ºè®®è¯„ä¼°ç»´åº¦ï¼š**")
                        st.markdown("- âœ… æ˜¯å¦éµå¾ªäº† Prompt çš„è¦æ±‚ï¼Ÿ")
                        st.markdown("- âœ… è¾“å‡ºæ ¼å¼æ˜¯å¦æ­£ç¡®ï¼Ÿ")
                        st.markdown("- âœ… å†…å®¹æ˜¯å¦å‡†ç¡®ã€å®Œæ•´ï¼Ÿ")
                    
                    print("\nâœ… æ•ˆæœéªŒè¯å®Œæˆï¼")
                    print(f"{'='*60}\n")
                    # å¯¹æ¯”å±•ç¤º
                    with st.expander("ğŸ” è¯¦ç»†å¯¹æ¯”", expanded=False):
                        comp_col1, comp_col2 = st.columns(2)
                        with comp_col1:
                            st.markdown("**ğŸ¤– æ¨¡å‹è¾“å‡ºï¼š**")
                            st.code(prediction, language=None)
                        with comp_col2:
                            st.markdown("**âœ… å‚è€ƒç­”æ¡ˆï¼š**")
                            st.code(reference_output, language=None)
                    
                except Exception as e:
                    print(f"\nâŒ éªŒè¯è¿‡ç¨‹å‘ç”Ÿé”™è¯¯ï¼")
                    print(f"{'='*60}")
                    error_msg = str(e)
                    print(f"ğŸ› é”™è¯¯ç±»å‹: {type(e).__name__}")
                    print(f"ğŸ“ é”™è¯¯ä¿¡æ¯: {error_msg}")
                    
                    import traceback
                    print(f"\nğŸ“„ å®Œæ•´å †æ ˆä¿¡æ¯ï¼š")
                    traceback.print_exc()
                    print(f"{'='*60}\n")
                    
                    st.error(f"âŒ è¯„ä¼°å¤±è´¥ï¼š{str(e)}")
                    import traceback
                    with st.expander("æŸ¥çœ‹é”™è¯¯è¯¦æƒ…"):
                        st.code(traceback.format_exc())

# ========== éšæœºæœç´¢ä¼˜åŒ–åŠŸèƒ½ ==========
st.markdown("---")
st.header("ğŸ”¬ Prompt è‡ªåŠ¨å¯»ä¼˜å®éªŒå®¤")

with st.expander("ğŸ’¡ ä»€ä¹ˆæ˜¯è‡ªåŠ¨å¯»ä¼˜ï¼Ÿ", expanded=False):
    st.markdown("""
    **è‡ªåŠ¨å¯»ä¼˜**å°† Prompt å·¥ç¨‹ä»æ‰‹å·¥è‰ºæå‡åˆ°å·¥ä¸šåŒ–ç”Ÿäº§ï¼š
    
    ### ğŸ² éšæœºæœç´¢ (Random Search)
    
    **åŸç†**: éšæœºç»„åˆä¸åŒçš„è§’è‰²ã€é£æ ¼ã€æŠ€å·§ï¼Œåœ¨æµ‹è¯•é›†ä¸Šå®é™…è¿è¡Œå¹¶æ‰“åˆ†
    
    **ä¼˜åŠ¿**:
    - âœ… å¿«é€Ÿè¦†ç›–æœç´¢ç©ºé—´
    - âœ… çªç ´äººç±»æ€ç»´å®šåŠ¿
    - âœ… é€‚åˆå¿«é€Ÿæ¢ç´¢
    
    **æˆæœ¬**: `è¿­ä»£æ¬¡æ•° Ã— æµ‹è¯•é›†å¤§å°` æ¬¡ API è°ƒç”¨
    
    ---
    
    ### ğŸ§¬ é—ä¼ ç®—æ³• (Genetic Algorithm)
    
    **åŸç†**: æ¨¡æ‹Ÿç”Ÿç‰©è¿›åŒ–ï¼Œè®©é«˜åˆ† Prompt "ç¹è¡"å‡ºæ›´å¥½çš„åä»£
    
    **æ ¸å¿ƒæœºåˆ¶**:
    1. **é€‰æ‹©**: ä¿ç•™å¾—åˆ†æœ€é«˜çš„ç²¾è‹±ä¸ªä½“
    2. **äº¤å‰**: ä¸¤ä¸ªé«˜åˆ† Prompt äº¤æ¢ç»„ä»¶ï¼ˆå¦‚ A çš„è§’è‰² + B çš„é£æ ¼ï¼‰
    3. **å˜å¼‚**: éšæœºä¿®æ”¹æŸäº›åŸºå› ï¼Œå¼•å…¥æ–°å¯èƒ½æ€§
    
    **ä¼˜åŠ¿**:
    - âœ… **è¶Šå¾€åæ•ˆæœè¶Šå¥½**ï¼ˆè¿›åŒ–è¶‹åŠ¿ï¼‰
    - âœ… è‡ªåŠ¨æ”¶æ•›åˆ°å±€éƒ¨æœ€ä¼˜
    - âœ… é€‚åˆç²¾ç»†æ‰“ç£¨
    
    **æˆæœ¬**: `ä»£æ•° Ã— ç§ç¾¤å¤§å° Ã— æµ‹è¯•é›†å¤§å°` æ¬¡ API è°ƒç”¨ï¼ˆ**æ›´é«˜**ï¼‰
    
    ---
    
    ### ğŸ“Š å¦‚ä½•é€‰æ‹©ï¼Ÿ
    
    | åœºæ™¯ | æ¨èç®—æ³• | åŸå›  |
    |------|---------|------|
    | å¿«é€Ÿæ¢ç´¢ | éšæœºæœç´¢ | ä½æˆæœ¬ï¼Œå¹¿æ’’ç½‘ |
    | ç²¾ç»†ä¼˜åŒ– | é—ä¼ ç®—æ³• | æŒç»­è¿›åŒ–ï¼Œé€¼è¿‘æè‡´ |
    | é¢„ç®—æœ‰é™ | éšæœºæœç´¢ | API è°ƒç”¨æ¬¡æ•°æ›´å°‘ |
    | è¿½æ±‚æè‡´ | é—ä¼ ç®—æ³• | å¤šä»£è¿›åŒ–ï¼Œçªç ´ç“¶é¢ˆ |
    
    **å»ºè®®**: å…ˆç”¨éšæœºæœç´¢æ‰¾åˆ° 70-80 åˆ†çš„ Promptï¼Œå†ç”¨é—ä¼ ç®—æ³•å†²åˆºåˆ° 90+ åˆ†ï¼
    """)

# ç®—æ³•é€‰æ‹©å™¨
algo_col1, algo_col2 = st.columns([2, 3])

with algo_col1:
    st.subheader("ğŸ¯ é€‰æ‹©ä¼˜åŒ–ç®—æ³•")
    
    algo_type = st.radio(
        "ç®—æ³•ç­–ç•¥",
        ["ğŸ² éšæœºæœç´¢", "ğŸ§¬ é—ä¼ ç®—æ³•"],
        help="éšæœºæœç´¢é€‚åˆå¿«é€Ÿå°è¯•ï¼›é—ä¼ ç®—æ³•é€‚åˆæ·±åº¦ä¼˜åŒ–",
        key="algo_type"
    )
    
    if algo_type == "ğŸ² éšæœºæœç´¢":
        st.info("""
        **éšæœºæœç´¢ç‰¹ç‚¹**:
        - æ¯æ¬¡ç‹¬ç«‹éšæœº
        - æœç´¢é€Ÿåº¦å¿«
        - æˆæœ¬ç›¸å¯¹è¾ƒä½
        """)
    else:
        st.info("""
        **é—ä¼ ç®—æ³•ç‰¹ç‚¹**:
        - å¤šä»£æŒç»­è¿›åŒ–
        - å¾—åˆ†å•è°ƒé€’å¢
        - æˆæœ¬ç›¸å¯¹è¾ƒé«˜
        - **æ¨è**: å…ˆéšæœºæœç´¢å†é—ä¼ ç®—æ³•
        """)

with algo_col2:
    st.markdown("### ğŸ“Š ç®—æ³•å¯¹æ¯”")
    
    comparison_data = {
        "æŒ‡æ ‡": ["æœç´¢ç­–ç•¥", "æ”¶æ•›æ€§", "æˆæœ¬", "é€‚ç”¨åœºæ™¯"],
        "ğŸ² éšæœºæœç´¢": ["éšæœºæŠ½æ ·", "æ— ä¿è¯", "è¾ƒä½", "å¿«é€Ÿæ¢ç´¢"],
        "ğŸ§¬ é—ä¼ ç®—æ³•": ["è¿›åŒ–è¿­ä»£", "å•è°ƒé€’å¢", "è¾ƒé«˜", "ç²¾ç»†æ‰“ç£¨"]
    }
    import pandas as pd
    comparison_df = pd.DataFrame(comparison_data)
    st.dataframe(comparison_df, use_container_width=True, hide_index=True)

st.markdown("---")

search_col1, search_col2 = st.columns([3, 2])

with search_col1:
    st.subheader("ğŸ“‹ é…ç½®æœç´¢ä»»åŠ¡")
    
    # ä»»åŠ¡ç±»å‹é€‰æ‹©
    search_task_type = st.selectbox(
        "é€‰æ‹©ä»»åŠ¡ç±»å‹",
        ["classification", "summarization", "translation"],
        format_func=lambda x: {
            "classification": "åˆ†ç±»ä»»åŠ¡ (Classification)",
            "summarization": "æ‘˜è¦ä»»åŠ¡ (Summarization)",
            "translation": "ç¿»è¯‘ä»»åŠ¡ (Translation)"
        }[x],
        key="search_task_type"
    )
    
    # ä»»åŠ¡æè¿°
    search_task_desc = st.text_area(
        "ä»»åŠ¡æè¿°",
        placeholder="ä¾‹å¦‚ï¼šå¯¹ç”¨æˆ·è¯„è®ºè¿›è¡Œæƒ…æ„Ÿåˆ†ç±»ï¼ˆç§¯æ/æ¶ˆæ/ä¸­ç«‹ï¼‰",
        height=80,
        key="search_task_desc"
    )
    
    # æµ‹è¯•æ•°æ®é›†
    st.markdown("#### ğŸ“¥ æµ‹è¯•æ•°æ®é›† (Validation Set)")
    st.caption("è¯·æä¾›è‡³å°‘2-3ä¸ªæµ‹è¯•æ ·æœ¬å’Œå¯¹åº”çš„æ ‡å‡†ç­”æ¡ˆï¼Œç”¨äºè¯„ä¼°ä¸åŒ Prompt çš„å®é™…æ•ˆæœ")
    
    # æ ¹æ®ä»»åŠ¡ç±»å‹æä¾›ä¸åŒçš„é»˜è®¤æ•°æ®
    if search_task_type == "classification":
        default_test_data = [
            # ç®€å•æ¡ˆä¾‹ï¼ˆåŸºå‡†ï¼‰
            {"input": "è¿™ä¸ªäº§å“çœŸçš„å¾ˆå¥½ç”¨ï¼Œéå¸¸æ»¡æ„ï¼", "ground_truth": "ç§¯æ"},
            {"input": "ä»·æ ¼å¤ªè´µäº†ï¼Œæ€§ä»·æ¯”ä¸é«˜", "ground_truth": "æ¶ˆæ"},
            
            # å›°éš¾æ¡ˆä¾‹ï¼šæ··åˆæƒ…æ„Ÿ
            {"input": "äº§å“è´¨é‡ä¸é”™ï¼Œä½†æ˜¯ä»·æ ¼æœ‰ç‚¹è´µï¼Œæ€»ä½“æ¥è¯´è¿˜è¡Œ", "ground_truth": "ä¸­ç«‹"},
            {"input": "åŠŸèƒ½å¾ˆå¼ºå¤§ï¼Œå°±æ˜¯æ“ä½œæœ‰ç‚¹å¤æ‚ï¼Œéœ€è¦å­¦ä¹ æˆæœ¬", "ground_truth": "ä¸­ç«‹"},
            
            # å›°éš¾æ¡ˆä¾‹ï¼šåè®½è¯­æ°”
            {"input": "å“‡ï¼ŒçœŸæ˜¯å¤ª'æ£’'äº†ï¼Œæ”¶åˆ°å°±åäº†ï¼Œéå¸¸'æ»¡æ„'å‘¢", "ground_truth": "æ¶ˆæ"},
            
            # å›°éš¾æ¡ˆä¾‹ï¼šå§”å©‰è¡¨è¾¾
            {"input": "emmm...æ€ä¹ˆè¯´å‘¢ï¼Œå¯èƒ½ä¸å¤ªé€‚åˆæˆ‘å§", "ground_truth": "æ¶ˆæ"},
            
            # å›°éš¾æ¡ˆä¾‹ï¼šçº¯å®¢è§‚æè¿°
            {"input": "åŒ…è£…æ˜¯çº¢è‰²çš„ï¼Œå°ºå¯¸å’Œæè¿°ä¸€è‡´ï¼Œæ˜¨å¤©æ”¶åˆ°çš„", "ground_truth": "ä¸­ç«‹"},
            
            # å›°éš¾æ¡ˆä¾‹ï¼šæœŸå¾…è½ç©º
            {"input": "æœ¬æ¥æŠ±äº†å¾ˆå¤§æœŸæœ›ï¼Œç»“æœå°±è¿™ï¼Ÿ", "ground_truth": "æ¶ˆæ"}
        ]
    elif search_task_type == "summarization":
        default_test_data = [
            {
                "input": "ä»Šå¤©å¬å¼€äº†äº§å“è¯„å®¡ä¼šè®®ï¼Œè®¨è®ºäº†æ–°åŠŸèƒ½çš„è®¾è®¡æ–¹æ¡ˆã€‚ä¼šè®®å†³å®šé‡‡ç”¨æ–¹æ¡ˆAï¼Œç”±å¼ ä¸‰è´Ÿè´£å¼€å‘ï¼Œé¢„è®¡2å‘¨å®Œæˆã€‚æ­¤å¤–ï¼Œè¿˜è®¨è®ºäº†å¸‚åœºæ¨å¹¿ç­–ç•¥ï¼Œå†³å®šå…ˆåœ¨ä¸€çº¿åŸå¸‚è¯•ç‚¹ï¼Œæ”¶é›†ç”¨æˆ·åé¦ˆåå†å…¨é¢æ¨å¹¿ã€‚",
                "ground_truth": "ä¼šè®®å†³å®šé‡‡ç”¨æ–¹æ¡ˆAï¼Œå¼ ä¸‰è´Ÿè´£å¼€å‘ï¼ˆ2å‘¨ï¼‰ï¼Œå…ˆåœ¨ä¸€çº¿åŸå¸‚è¯•ç‚¹åå†å…¨é¢æ¨å¹¿ã€‚"
            },
            {
                "input": "å…¬å¸å¹´ä¼šå°†äºä¸‹æœˆ15æ—¥ä¸¾è¡Œï¼Œåœ°ç‚¹åœ¨å¸‚ä¸­å¿ƒå¤§é…’åº—ã€‚å„éƒ¨é—¨éœ€æå‰å‡†å¤‡èŠ‚ç›®ï¼ŒäººåŠ›èµ„æºéƒ¨è´Ÿè´£åè°ƒã€‚é¢„ç®—æ§åˆ¶åœ¨50ä¸‡ä»¥å†…ï¼Œéœ€è¦æå‰é¢„å®šåœºåœ°å’Œæ™šå®´ã€‚",
                "ground_truth": "å¹´ä¼šä¸‹æœˆ15æ—¥å¸‚ä¸­å¿ƒå¤§é…’åº—ä¸¾è¡Œï¼Œå„éƒ¨é—¨å‡†å¤‡èŠ‚ç›®ï¼ŒHRåè°ƒï¼Œé¢„ç®—50ä¸‡ã€‚"
            },
            {
                "input": "æ ¹æ®æœ€æ–°é”€å”®æ•°æ®ï¼ŒQ3å­£åº¦è¥æ”¶åŒæ¯”å¢é•¿35%ï¼Œä¸»è¦æ¥è‡ªäºæ–°äº§å“çº¿çš„è´¡çŒ®ã€‚å…¶ä¸­ï¼ŒAIäº§å“çº¿å¢é•¿æœ€å¿«ï¼Œè¾¾åˆ°äº†60%çš„åŒæ¯”å¢é•¿ç‡ã€‚ä½†æ˜¯ï¼Œä¼ ç»Ÿäº§å“çº¿å‡ºç°äº†10%çš„ä¸‹æ»‘ï¼Œéœ€è¦å¼•èµ·é‡è§†ã€‚",
                "ground_truth": "Q3è¥æ”¶å¢é•¿35%ï¼ŒAIäº§å“çº¿å¢é•¿60%ï¼Œä½†ä¼ ç»Ÿäº§å“ä¸‹æ»‘10%éœ€å…³æ³¨ã€‚"
            },
            {
                "input": "ç”¨æˆ·åé¦ˆä¸»è¦é›†ä¸­åœ¨ä¸‰ä¸ªæ–¹é¢ï¼šé¦–å…ˆæ˜¯ç•Œé¢è®¾è®¡éœ€è¦ä¼˜åŒ–ï¼Œæœ‰42%çš„ç”¨æˆ·æåˆ°æ“ä½œä¸å¤Ÿç›´è§‚ï¼›å…¶æ¬¡æ˜¯åŠ è½½é€Ÿåº¦æ…¢ï¼Œæœ‰35%çš„ç”¨æˆ·æŠ±æ€¨ï¼›æœ€åæ˜¯ç¼ºå°‘æŸäº›æ ¸å¿ƒåŠŸèƒ½ï¼Œå 23%ã€‚æ€»ä½“æ»¡æ„åº¦ä¸º3.2åˆ†ï¼ˆæ»¡åˆ†5åˆ†ï¼‰ã€‚",
                "ground_truth": "ç”¨æˆ·åé¦ˆï¼šç•Œé¢ä¸ç›´è§‚(42%)ã€åŠ è½½æ…¢(35%)ã€ç¼ºåŠŸèƒ½(23%)ï¼Œæ»¡æ„åº¦3.2/5åˆ†ã€‚"
            }
        ]
    else:  # translation
        default_test_data = [
            {"input": "äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œ", "ground_truth": "Artificial intelligence is changing the world"},
            {"input": "æœºå™¨å­¦ä¹ æ˜¯AIçš„æ ¸å¿ƒæŠ€æœ¯", "ground_truth": "Machine learning is the core technology of AI"},
            {"input": "æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å›¾åƒè¯†åˆ«é¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•", "ground_truth": "Deep learning models have made breakthrough progress in the field of image recognition"},
            {"input": "è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯ä½¿è®¡ç®—æœºèƒ½å¤Ÿç†è§£å’Œç”Ÿæˆäººç±»è¯­è¨€", "ground_truth": "Natural language processing technology enables computers to understand and generate human language"},
            {"input": "å¤§è¯­è¨€æ¨¡å‹çš„å‡ºç°æ ‡å¿—ç€äººå·¥æ™ºèƒ½å‘å±•çš„æ–°é˜¶æ®µ", "ground_truth": "The emergence of large language models marks a new stage in the development of artificial intelligence"}
        ]
    
    # ä½¿ç”¨ data_editor è®©ç”¨æˆ·ç¼–è¾‘æµ‹è¯•æ•°æ®
    test_dataset = st.data_editor(
        default_test_data,
        num_rows="dynamic",
        use_container_width=True,
        column_config={
            "input": st.column_config.TextColumn("æµ‹è¯•è¾“å…¥", width="medium"),
            "ground_truth": st.column_config.TextColumn("æ ‡å‡†ç­”æ¡ˆ", width="medium")
        },
        key="search_test_dataset"
    )

with search_col2:
    st.subheader("âš™ï¸ æœç´¢å‚æ•°")
    
    # æ ¹æ®ç®—æ³•ç±»å‹æ˜¾ç¤ºä¸åŒå‚æ•°
    if algo_type == "ğŸ² éšæœºæœç´¢":
        # éšæœºæœç´¢å‚æ•°
        search_iterations = st.slider(
            "æœç´¢è¿­ä»£æ¬¡æ•°",
            min_value=3,
            max_value=20,
            value=5,
            help="å°è¯•å¤šå°‘ç§ä¸åŒçš„ Prompt ç»„åˆ",
            key="search_iterations"
        )
        
        # æ˜¾ç¤ºé¢„ä¼°æ¶ˆè€—
        estimated_calls = search_iterations * len(test_dataset) if test_dataset else 0
        st.info(f"ğŸ’° é¢„è®¡ API è°ƒç”¨ï¼š**{estimated_calls}** æ¬¡")
        
    else:  # é—ä¼ ç®—æ³•
        # é—ä¼ ç®—æ³•å‚æ•°
        ga_generations = st.slider(
            "è¿›åŒ–ä»£æ•° (Generations)",
            min_value=3,
            max_value=10,
            value=5,
            help="ç§ç¾¤è¿›åŒ–çš„ä»£æ•°ï¼Œè¶Šå¤šæ•ˆæœè¶Šå¥½ä½†æˆæœ¬è¶Šé«˜",
            key="ga_generations"
        )
        
        ga_population = st.slider(
            "ç§ç¾¤è§„æ¨¡ (Population Size)",
            min_value=4,
            max_value=20,
            value=8,
            help="æ¯ä¸€ä»£æœ‰å¤šå°‘ä¸ªä¸ªä½“ï¼Œè§„æ¨¡è¶Šå¤§è¦†ç›–è¶Šå…¨é¢",
            key="ga_population"
        )
        
        # é«˜çº§å‚æ•°
        with st.expander("ğŸ”§ é«˜çº§å‚æ•°", expanded=False):
            ga_elite_ratio = st.slider(
                "ç²¾è‹±ä¿ç•™æ¯”ä¾‹",
                min_value=0.1,
                max_value=0.5,
                value=0.2,
                step=0.1,
                help="ä¿ç•™å¤šå°‘æ¯”ä¾‹çš„ä¼˜ç§€ä¸ªä½“åˆ°ä¸‹ä¸€ä»£",
                key="ga_elite_ratio"
            )
            
            ga_mutation_rate = st.slider(
                "å˜å¼‚æ¦‚ç‡",
                min_value=0.1,
                max_value=0.5,
                value=0.2,
                step=0.1,
                help="æ¯ä¸ªåŸºå› å‘ç”Ÿå˜å¼‚çš„æ¦‚ç‡",
                key="ga_mutation_rate"
            )
        
        # æ˜¾ç¤ºé¢„ä¼°æ¶ˆè€—
        estimated_calls = ga_generations * ga_population * len(test_dataset) if test_dataset else 0
        st.warning(f"ğŸ’° é¢„è®¡ API è°ƒç”¨ï¼š**{estimated_calls}** æ¬¡")
        st.caption("âš ï¸ é—ä¼ ç®—æ³•æˆæœ¬è¾ƒé«˜ï¼Œå»ºè®®å…ˆç”¨å°è§„æ¨¡å‚æ•°æµ‹è¯•")
    
    st.markdown("---")
    
    # å¼€å§‹æœç´¢æŒ‰é’®
    start_search_btn = st.button(
        f"ğŸš€ å¼€å§‹{'éšæœºæœç´¢' if algo_type == 'ğŸ² éšæœºæœç´¢' else 'é—ä¼ è¿›åŒ–'}å¯»ä¼˜",
        type="primary",
        use_container_width=True,
        disabled=not (search_task_desc and test_dataset and len(test_dataset) >= 1),
        key="start_search_btn"
    )

# æ‰§è¡Œæœç´¢ï¼ˆéšæœºæœç´¢æˆ–é—ä¼ ç®—æ³•ï¼‰
if start_search_btn:
    if not api_key_input or api_key_input.strip() == "":
        st.error("âŒ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® API Key")
    elif not search_task_desc or search_task_desc.strip() == "":
        st.error("âŒ è¯·è¾“å…¥ä»»åŠ¡æè¿°")
    elif not test_dataset or len(test_dataset) < 1:
        st.error("âŒ è¯·è‡³å°‘æä¾› 1 æ¡æµ‹è¯•æ•°æ®")
    else:
        try:
            # åˆ›å»ºä¼˜åŒ–å™¨
            optimizer = PromptOptimizer(
                api_key=api_key_input,
                model=model_choice,
                base_url=base_url if base_url else None,
                provider=api_provider.lower()
            )
            
            # è½¬æ¢æµ‹è¯•æ•°æ®æ ¼å¼
            import pandas as pd
            if isinstance(test_dataset, pd.DataFrame):
                test_data_list = test_dataset.to_dict('records')
            elif isinstance(test_dataset, list):
                test_data_list = test_dataset
            else:
                test_data_list = list(test_dataset)
            
            # é˜¶æ®µ1: ç”Ÿæˆæœç´¢ç©ºé—´
            with st.status("ğŸ§  æ­£åœ¨åˆ†æä»»åŠ¡ï¼Œç”Ÿæˆæœç´¢ç©ºé—´...", expanded=True) as status:
                st.write("è®© LLM åˆ†æä»»åŠ¡ç‰¹ç‚¹ï¼Œç”Ÿæˆå¯èƒ½çš„è§’è‰²ã€é£æ ¼å’ŒæŠ€å·§ç»„åˆ...")
                
                search_space = optimizer.generate_search_space(
                    task_description=search_task_desc,
                    task_type=search_task_type
                )
                
                st.success("âœ… æœç´¢ç©ºé—´ç”Ÿæˆå®Œæˆï¼")
                
                # å±•ç¤ºç”Ÿæˆçš„å˜é‡æ± 
                space_col1, space_col2, space_col3 = st.columns(3)
                with space_col1:
                    st.markdown("**ğŸ­ è§’è‰²æ± **")
                    for role in search_space.roles:
                        st.write(f"â€¢ {role}")
                with space_col2:
                    st.markdown("**ğŸ¨ é£æ ¼æ± **")
                    for style in search_space.styles:
                        st.write(f"â€¢ {style}")
                with space_col3:
                    st.markdown("**ğŸ”§ æŠ€å·§æ± **")
                    for tech in search_space.techniques:
                        st.write(f"â€¢ {tech}")
                
                # æ ¹æ®ç®—æ³•ç±»å‹æ‰§è¡Œä¸åŒé€»è¾‘
                if algo_type == "ğŸ² éšæœºæœç´¢":
                    # === éšæœºæœç´¢ ===
                    status.update(label="ğŸ² æ­£åœ¨æ‰§è¡Œéšæœºæœç´¢...", state="running")
                    
                    progress_bar = st.progress(0.0)
                    progress_text = st.empty()
                    
                    def update_progress_random(current, total, message):
                        progress = current / total
                        progress_bar.progress(progress)
                        progress_text.text(f"{message} ({current}/{total})")
                    
                    # è¿è¡Œéšæœºæœç´¢
                    all_results, best_result = optimizer.run_random_search(
                        task_description=search_task_desc,
                        task_type=search_task_type,
                        test_dataset=test_data_list,
                        search_space=search_space,
                        iterations=search_iterations,
                        progress_callback=update_progress_random
                    )
                    
                    evolution_history = None  # éšæœºæœç´¢æ— è¿›åŒ–å†å²
                    
                else:
                    # === é—ä¼ ç®—æ³• ===
                    status.update(label="ğŸ§¬ æ­£åœ¨æ‰§è¡Œé—ä¼ ç®—æ³•è¿›åŒ–...", state="running")
                    
                    progress_bar = st.progress(0.0)
                    progress_text = st.empty()
                    
                    # å®æ—¶æ›´æ–°è¿›åŒ–æ›²çº¿
                    chart_placeholder = st.empty()
                    history_data = []
                    
                    def update_progress_ga(gen, total_gen, best_score, avg_score):
                        """é—ä¼ ç®—æ³•è¿›åº¦å›è°ƒ"""
                        progress = gen / total_gen
                        progress_bar.progress(progress)
                        progress_text.text(f"ç¬¬ {gen}/{total_gen} ä»£ï¼šæœ€ä½³ {best_score:.2f}, å¹³å‡ {avg_score:.2f}")
                        
                        # æ›´æ–°è¿›åŒ–æ›²çº¿
                        history_data.append({
                            "ä»£æ•°": gen,
                            "æœ€é«˜åˆ†": best_score,
                            "å¹³å‡åˆ†": avg_score
                        })
                        chart_df = pd.DataFrame(history_data)
                        chart_placeholder.line_chart(chart_df.set_index("ä»£æ•°"))
                    
                    # è¿è¡Œé—ä¼ ç®—æ³•
                    all_results, best_result, evolution_history = optimizer.run_genetic_algorithm(
                        task_description=search_task_desc,
                        task_type=search_task_type,
                        test_dataset=test_data_list,
                        search_space=search_space,
                        generations=ga_generations,
                        population_size=ga_population,
                        elite_ratio=ga_elite_ratio,
                        mutation_rate=ga_mutation_rate,
                        progress_callback=update_progress_ga
                    )
                
                status.update(label="âœ… ä¼˜åŒ–å®Œæˆï¼", state="complete")
            
            # é˜¶æ®µ3: å±•ç¤ºç»“æœ
            st.markdown("---")
            st.header("ğŸ† ä¼˜åŒ–ç»“æœ")
            
            # æœ€ä½³ç»“æœé«˜äº®å±•ç¤º
            if algo_type == "ğŸ§¬ é—ä¼ ç®—æ³•" and evolution_history:
                improvement = evolution_history[-1]['best_score'] - evolution_history[0]['best_score']
                st.success(f"ğŸ¥‡ **æœ€ç»ˆå¾—åˆ†ï¼š{best_result.avg_score:.2f}** | ğŸ§¬ è¿›åŒ–å¢ç›Šï¼š+{improvement:.2f} åˆ†")
            else:
                st.success(f"ğŸ¥‡ **æœ€ä½³å¾—åˆ†ï¼š{best_result.avg_score:.2f}**")
            
            result_col1, result_col2 = st.columns([3, 2])
            
            with result_col1:
                st.markdown("### ğŸ¯ å† å†› Prompt")
                st.code(best_result.full_prompt, language="text")
            
            with result_col2:
                st.markdown("### ğŸ“Š ç­–ç•¥ç»„æˆ")
                st.markdown(f"**ğŸ­ è§’è‰²ï¼š** {best_result.role}")
                st.markdown(f"**ğŸ¨ é£æ ¼ï¼š** {best_result.style}")
                st.markdown(f"**ğŸ”§ æŠ€å·§ï¼š** {best_result.technique}")
                st.markdown(f"**ğŸ’¯ å¾—åˆ†ï¼š** {best_result.avg_score:.2f}")
                
                if algo_type == "ğŸ§¬ é—ä¼ ç®—æ³•" and evolution_history:
                    st.markdown("---")
                    st.markdown("**ğŸ§¬ è¿›åŒ–ç»Ÿè®¡**")
                    st.markdown(f"â€¢ åˆå§‹æœ€é«˜åˆ†: {evolution_history[0]['best_score']:.2f}")
                    st.markdown(f"â€¢ æœ€ç»ˆæœ€é«˜åˆ†: {evolution_history[-1]['best_score']:.2f}")
                    st.markdown(f"â€¢ è¿›åŒ–æå‡: +{improvement:.2f} åˆ†")
            
            # æ‰€æœ‰ç»“æœæ’è¡Œæ¦œ
            st.markdown("---")
            st.subheader("ğŸ“‹ å®Œæ•´ä¼˜åŒ–è®°å½•")
            
            # æ„å»ºç»“æœè¡¨æ ¼
            results_df = pd.DataFrame([
                {
                    "æ’å": i + 1,
                    "ID": r.iteration_id,
                    "è§’è‰²": r.role,
                    "é£æ ¼": r.style,
                    "æŠ€å·§": r.technique,
                    "å¾—åˆ†": f"{r.avg_score:.2f}"
                }
                for i, r in enumerate(sorted(all_results, key=lambda x: x.avg_score, reverse=True))
            ])
            
            st.dataframe(
                results_df,
                use_container_width=True,
                hide_index=True
            )
            
            # å¯è§†åŒ–
            st.markdown("---")
            
            if algo_type == "ğŸ§¬ é—ä¼ ç®—æ³•" and evolution_history:
                # é—ä¼ ç®—æ³•ï¼šæ˜¾ç¤ºè¿›åŒ–æ›²çº¿
                st.subheader("ğŸ“ˆ è¿›åŒ–æ›²çº¿")
                
                import matplotlib.pyplot as plt
                import matplotlib
                matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
                matplotlib.rcParams['axes.unicode_minus'] = False
                
                fig, ax = plt.subplots(figsize=(10, 5))
                
                generations = [h['generation'] for h in evolution_history]
                best_scores = [h['best_score'] for h in evolution_history]
                avg_scores = [h['avg_score'] for h in evolution_history]
                worst_scores = [h['worst_score'] for h in evolution_history]
                
                ax.plot(generations, best_scores, marker='o', linewidth=2, markersize=8, label='æœ€é«˜åˆ†', color='#2ecc71')
                ax.plot(generations, avg_scores, marker='s', linewidth=2, markersize=6, label='å¹³å‡åˆ†', color='#3498db')
                ax.plot(generations, worst_scores, marker='^', linewidth=1, markersize=5, label='æœ€ä½åˆ†', color='#e74c3c', alpha=0.5)
                
                ax.fill_between(generations, worst_scores, best_scores, alpha=0.2, color='#3498db')
                
                ax.set_xlabel('ä»£æ•° (Generation)')
                ax.set_ylabel('å¾—åˆ† (Score)')
                ax.set_title('é—ä¼ ç®—æ³•è¿›åŒ–æ›²çº¿ - å¯ä»¥çœ‹åˆ°å¾—åˆ†æŒç»­ä¸Šå‡ï¼')
                ax.legend()
                ax.grid(True, alpha=0.3)
                
                st.pyplot(fig)
                
                # è¿›åŒ–æ•°æ®è¡¨
                with st.expander("ğŸ“Š æŸ¥çœ‹è¯¦ç»†è¿›åŒ–æ•°æ®", expanded=False):
                    evo_df = pd.DataFrame(evolution_history)
                    evo_df.columns = ['ä»£æ•°', 'æœ€é«˜åˆ†', 'å¹³å‡åˆ†', 'æœ€ä½åˆ†']
                    st.dataframe(evo_df, use_container_width=True, hide_index=True)
                
            else:
                # éšæœºæœç´¢ï¼šæ˜¾ç¤ºå¾—åˆ†åˆ†å¸ƒ
                st.subheader("ğŸ“ˆ å¾—åˆ†åˆ†å¸ƒå›¾")
                
                import matplotlib.pyplot as plt
                import matplotlib
                matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
                matplotlib.rcParams['axes.unicode_minus'] = False
                
                fig, ax = plt.subplots(figsize=(10, 4))
                scores = [r.avg_score for r in all_results]
                iterations = [r.iteration_id for r in all_results]
                
                ax.plot(iterations, scores, marker='o', linewidth=2, markersize=8, color='#3498db')
                ax.axhline(y=best_result.avg_score, color='r', linestyle='--', linewidth=2, label=f'æœ€ä½³å¾—åˆ†: {best_result.avg_score:.2f}')
                ax.set_xlabel('è¿­ä»£æ¬¡æ•°')
                ax.set_ylabel('å¾—åˆ†')
                ax.set_title('éšæœºæœç´¢å¾—åˆ†å˜åŒ– - éšæœºæ³¢åŠ¨ï¼Œæ— è§„å¾‹')
                ax.legend()
                ax.grid(True, alpha=0.3)
                
                st.pyplot(fig)
            
            # ä¿å­˜æœ€ä½³ç»“æœåˆ° session_state
            st.session_state.best_search_result = best_result
            
            st.success(f"âœ… {'éšæœºæœç´¢' if algo_type == 'ğŸ² éšæœºæœç´¢' else 'é—ä¼ ç®—æ³•'}ä¼˜åŒ–å®Œæˆï¼æ‚¨å¯ä»¥å°†å† å†› Prompt å¤åˆ¶ä½¿ç”¨ã€‚")
            
            if algo_type == "ğŸ² éšæœºæœç´¢":
                st.info("ğŸ’¡ **æç¤º**: å¦‚æœæƒ³è¿›ä¸€æ­¥æå‡ï¼Œå¯ä»¥åˆ‡æ¢åˆ°ã€ŒğŸ§¬ é—ä¼ ç®—æ³•ã€è¿›è¡Œæ·±åº¦ä¼˜åŒ–ï¼")
            
        except Exception as e:
            st.error(f"âŒ ä¼˜åŒ–è¿‡ç¨‹å‡ºé”™ï¼š{str(e)}")
            import traceback
            with st.expander("æŸ¥çœ‹é”™è¯¯è¯¦æƒ…"):
                st.code(traceback.format_exc())

col_foot1, col_foot2, col_foot3 = st.columns(3)

with col_foot1:
    st.metric("æ ¸å¿ƒæŠ€æœ¯", "LLM-as-Optimizer", "ğŸ¤–")
with col_foot2:
    st.metric("ä¼˜åŒ–ç­–ç•¥", "3å¤§æ ¸å¿ƒæ–¹æ³•", "ğŸ¯")
with col_foot3:
    st.metric("æ¡†æ¶æ”¯æŒ", "4ç§æ¨¡æ¿", "ğŸ“")

# é¡µè„š
st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: #888;'>"
    "ğŸš€ AI Prompt è‡ªåŠ¨ä¼˜åŒ–ç³»ç»Ÿ"
    "</div>",
    unsafe_allow_html=True
)
