"""
æœç´¢ç©ºé—´ç”Ÿæˆå™¨
ç”¨äºè‡ªåŠ¨ç”Ÿæˆä¼˜åŒ–æœç´¢çš„å‚æ•°ç©ºé—´
"""
import time
import json
from langchain_core.prompts import ChatPromptTemplate
from config.models import SearchSpace
from config.template_loader import get_search_space_meta_prompt


class SearchSpaceGenerator:
    """æœç´¢ç©ºé—´ç”Ÿæˆå™¨"""
    
    def __init__(self, llm, provider: str):
        """
        åˆå§‹åŒ–ç”Ÿæˆå™¨
        
        Args:
            llm: LangChain LLM å®ä¾‹
            provider: API æä¾›å•†
        """
        self.llm = llm
        self.provider = provider
    
    def generate(self, task_description: str, task_type: str = "classification", **kwargs) -> SearchSpace:
        """
        è®© LLM è‡ªåŠ¨åˆ†æä»»åŠ¡ï¼Œç”Ÿæˆå¯ä¾›æœç´¢çš„å˜é‡æ± 
        
        Args:
            task_description: ä»»åŠ¡æè¿°
            task_type: ä»»åŠ¡ç±»å‹ (classification/summarization/translation)
            **kwargs: é¢å¤–çš„ä»»åŠ¡é…ç½®ä¿¡æ¯
                - labels: åˆ†ç±»ä»»åŠ¡çš„æ ‡ç­¾åˆ—è¡¨
                - source_type: æ‘˜è¦ä»»åŠ¡çš„æºæ–‡æœ¬ç±»å‹
                - target_audience: æ‘˜è¦ä»»åŠ¡çš„ç›®æ ‡å—ä¼—
                - focus_points: æ‘˜è¦ä»»åŠ¡çš„æ ¸å¿ƒå…³æ³¨ç‚¹
                - source_lang: ç¿»è¯‘ä»»åŠ¡çš„æºè¯­è¨€
                - target_lang: ç¿»è¯‘ä»»åŠ¡çš„ç›®æ ‡è¯­è¨€
                - domain: ç¿»è¯‘ä»»åŠ¡çš„åº”ç”¨é¢†åŸŸ
                - tone: ç¿»è¯‘ä»»åŠ¡çš„æœŸæœ›é£æ ¼
            
        Returns:
            SearchSpace å¯¹è±¡ï¼ŒåŒ…å« roles, styles, techniques
        """
        print(f"\n{'='*60}")
        print(f"ğŸ§  ç”Ÿæˆæœç´¢ç©ºé—´")
        print(f"{'='*60}")
        print(f"ä»»åŠ¡ç±»å‹: {task_type}")
        print(f"ä»»åŠ¡æè¿°: {task_description}")
        print(f"{'='*60}\n")
        
        # ä½¿ç”¨å¤–éƒ¨æ¨¡æ¿åŠ è½½ Meta-Prompt
        system_prompt = get_search_space_meta_prompt()
        
        # æ„å»ºè¯¦ç»†çš„ä»»åŠ¡ä¸Šä¸‹æ–‡
        context_info = f"""
ä»»åŠ¡ç±»å‹ï¼š{task_type}
ä»»åŠ¡æè¿°ï¼š{task_description}
"""
        
        # æ ¹æ®ä»»åŠ¡ç±»å‹æ·»åŠ ç‰¹å®šçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        if task_type == "classification" and kwargs.get('labels'):
            context_info += f"""
åˆ†ç±»æ ‡ç­¾ï¼š{', '.join(kwargs['labels'])}
"""
        elif task_type == "summarization":
            if kwargs.get('source_type'):
                context_info += f"""
æºæ–‡æœ¬ç±»å‹ï¼š{kwargs['source_type']}
"""
            if kwargs.get('target_audience'):
                context_info += f"""
ç›®æ ‡å—ä¼—ï¼š{kwargs['target_audience']}
"""
            if kwargs.get('focus_points'):
                context_info += f"""
æ ¸å¿ƒå…³æ³¨ç‚¹ï¼š{kwargs['focus_points']}
"""
        elif task_type == "translation":
            if kwargs.get('source_lang') and kwargs.get('target_lang'):
                context_info += f"""
ç¿»è¯‘æ–¹å‘ï¼š{kwargs['source_lang']} â†’ {kwargs['target_lang']}
"""
            if kwargs.get('domain'):
                context_info += f"""
åº”ç”¨é¢†åŸŸï¼š{kwargs['domain']}
"""
            if kwargs.get('tone'):
                context_info += f"""
æœŸæœ›é£æ ¼ï¼š{kwargs['tone']}
"""
        
        user_prompt = f"""
{context_info}

è¯·ä¸ºè¿™ä¸ªä»»åŠ¡è®¾è®¡ï¼š
1. 5ä¸ªä¸åŒçš„è§’è‰²å®šä½ï¼ˆä»ä¿å®ˆåˆ°åˆ›æ–°ï¼Œè¦†ç›–ä¸åŒä¸“ä¸šèƒŒæ™¯ï¼‰
2. 5ç§ä¸åŒçš„å›ç­”é£æ ¼/è¯­æ°”
3. 3ç§ä¸åŒçš„æç¤ºå·¥ç¨‹æŠ€å·§æˆ–æŒ‡ä»¤æ¨¡å¼

ç¡®ä¿è¾“å‡ºçº¯ JSON æ ¼å¼ã€‚
"""
        
        prompt_template = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("human", user_prompt)
        ])
        
        try:
            # è°ƒç”¨ LLM
            print("ğŸ“¡ è°ƒç”¨ LLM ç”Ÿæˆæœç´¢ç©ºé—´...")
            messages = prompt_template.format_messages(task_type=task_type, task_description=task_description)
            response = self.llm.invoke(messages)
            
            time.sleep(0.5)  # API è°ƒç”¨å»¶è¿Ÿï¼Œé¿å…é¢‘ç‡è¿‡å¿«
            
            print(f"âœ… LLM å“åº”æˆåŠŸ")
            print(f"åŸå§‹å“åº”é•¿åº¦: {len(response.content)} å­—ç¬¦")
            
            # è§£æ JSON
            content = response.content.strip()
            print(f"\nğŸ” è§£æ JSON å“åº”...")
            print(f"åŸå§‹å†…å®¹å‰100å­—ç¬¦: {content[:100]}...")
            
            # ç§»é™¤å¯èƒ½çš„ markdown ä»£ç å—æ ‡è®°
            if content.startswith("```json"):
                content = content[7:]
                print("  ç§»é™¤äº† ```json æ ‡è®°")
            if content.startswith("```"):
                content = content[3:]
                print("  ç§»é™¤äº† ``` æ ‡è®°")
            if content.endswith("```"):
                content = content[:-3]
                print("  ç§»é™¤äº†å°¾éƒ¨ ``` æ ‡è®°")
            content = content.strip()
            
            # æå– JSON éƒ¨åˆ†ï¼ˆä»ç¬¬ä¸€ä¸ª { åˆ°æœ€åä¸€ä¸ª }ï¼‰
            try:
                start_idx = content.index('{')
                end_idx = content.rindex('}') + 1
                content = content[start_idx:end_idx]
                print(f"  æå–äº†çº¯ JSON å†…å®¹ï¼ˆä»ç¬¬ {start_idx} åˆ°ç¬¬ {end_idx} å­—ç¬¦ï¼‰")
            except ValueError:
                print("  âš ï¸ æœªæ‰¾åˆ°å®Œæ•´çš„ JSON å¯¹è±¡ï¼Œå°è¯•ç›´æ¥è§£æ")
            
            print(f"æ¸…ç†åå†…å®¹å‰100å­—ç¬¦: {content[:100]}...")
            
            data = json.loads(content)
            print(f"âœ… JSON è§£ææˆåŠŸ")
            print(f"  - roles: {len(data.get('roles', []))} ä¸ª")
            print(f"  - styles: {len(data.get('styles', []))} ä¸ª")
            print(f"  - techniques: {len(data.get('techniques', []))} ä¸ª")
            
            # å¤„ç† LLM å¯èƒ½è¿”å›å¯¹è±¡æ•°ç»„çš„æƒ…å†µ
            def extract_names(items):
                """æå–å­—ç¬¦ä¸²æˆ–å¯¹è±¡æ•°ç»„ä¸­çš„åç§°"""
                if not items:
                    return []
                result = []
                for item in items:
                    if isinstance(item, str):
                        result.append(item)
                    elif isinstance(item, dict) and 'name' in item:
                        result.append(item['name'])
                        print(f"    æå–: {item['name']}")
                return result
            
            # è½¬æ¢æ•°æ®æ ¼å¼
            print(f"ğŸ”„ å¤„ç†æ•°æ®æ ¼å¼...")
            data['roles'] = extract_names(data.get('roles', []))
            data['styles'] = extract_names(data.get('styles', []))
            data['techniques'] = extract_names(data.get('techniques', []))
            
            print(f"  âœ… roles: {data['roles']}")
            print(f"  âœ… styles: {data['styles']}")
            print(f"  âœ… techniques: {data['techniques']}")
            
            result = SearchSpace(**data)
            print(f"\nâœ… æœç´¢ç©ºé—´ç”Ÿæˆå®Œæˆï¼\n")
            return result
            
        except Exception as e:
            print(f"\nâŒ ç”Ÿæˆæœç´¢ç©ºé—´å¤±è´¥ï¼")
            print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
            print(f"é”™è¯¯ä¿¡æ¯: {e}")
            
            import traceback
            print(f"\nå®Œæ•´é”™è¯¯å †æ ˆï¼š")
            traceback.print_exc()
            
            # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©ä¸Šå±‚å¤„ç†
            raise RuntimeError(f"æœç´¢ç©ºé—´ç”Ÿæˆå¤±è´¥: {e}")
