"""
é—ä¼ ç®—æ³•ä¼˜åŒ–æ¨¡å—
ä½¿ç”¨è¿›åŒ–æ€æƒ³ä¼˜åŒ– Prompt ç»„åˆ
"""
import time
import random
from typing import Optional, Callable
from config.models import SearchSpace, SearchResult
from metrics import MetricsCalculator


class GeneticAlgorithm:
    """é—ä¼ ç®—æ³•ä¼˜åŒ–å™¨"""
    
    def __init__(self, llm):
        """
        åˆå§‹åŒ–é—ä¼ ç®—æ³•
        
        Args:
            llm: LLM å®ä¾‹
        """
        self.llm = llm
    
    def run(
        self,
        task_description: str,
        task_type: str,
        test_dataset: list,
        search_space: SearchSpace,
        generations: int = 5,
        population_size: int = 8,
        elite_ratio: float = 0.2,
        mutation_rate: float = 0.2,
        progress_callback: Optional[Callable] = None
    ) -> tuple[list, SearchResult, list]:
        """
        é—ä¼ ç®—æ³•ä¼˜åŒ– Prompt
        
        æ ¸å¿ƒæ€æƒ³ï¼šé€šè¿‡å¤šä»£è¿›åŒ–ï¼Œè®©ä¼˜ç§€çš„ Prompt ç»„åˆ"ç¹è¡"å‡ºæ›´å¥½çš„åä»£
        
        Args:
            task_description: ä»»åŠ¡æè¿°
            task_type: ä»»åŠ¡ç±»å‹ (classification/summarization/translation)
            test_dataset: æµ‹è¯•æ•°æ®é›† [{"input": "...", "ground_truth": "..."}, ...]
            search_space: æœç´¢ç©ºé—´
            generations: è¿›åŒ–ä»£æ•°ï¼ˆè¶Šå¤šè¶Šå¥½ï¼Œä½†æ¶ˆè€—æ›´å¤§ï¼‰
            population_size: ç§ç¾¤è§„æ¨¡ï¼ˆæ¯ä»£æœ‰å¤šå°‘ä¸ªä¸ªä½“ï¼‰
            elite_ratio: ç²¾è‹±ä¿ç•™æ¯”ä¾‹ï¼ˆä¿ç•™å¤šå°‘ä¼˜ç§€ä¸ªä½“åˆ°ä¸‹ä¸€ä»£ï¼‰
            mutation_rate: å˜å¼‚æ¦‚ç‡ï¼ˆå¼•å…¥éšæœºæ€§é¿å…å±€éƒ¨æœ€ä¼˜ï¼‰
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•° callback(gen, total_gen, best_score, avg_score)
        
        Returns:
            (all_results, best_result, evolution_history)
            - all_results: æ‰€æœ‰è¿­ä»£çš„ç»“æœ
            - best_result: æœ€ä½³ç»“æœ
            - evolution_history: è¿›åŒ–å†å² [{"generation": 1, "best_score": 85.0, "avg_score": 78.5}, ...]
        """
        print(f"\n{'='*60}")
        print(f"ğŸ§¬ é—ä¼ ç®—æ³•ä¼˜åŒ–å¼€å§‹")
        print(f"{'='*60}")
        print(f"ğŸ“‹ ä»»åŠ¡ç±»å‹: {task_type}")
        print(f"ğŸ“Š ä»£æ•°: {generations}, ç§ç¾¤è§„æ¨¡: {population_size}")
        print(f"ğŸ”¬ ç²¾è‹±æ¯”ä¾‹: {elite_ratio * 100}%, å˜å¼‚ç‡: {mutation_rate * 100}%")
        print(f"ğŸ“ æµ‹è¯•é›†æ ·æœ¬æ•°: {len(test_dataset)}")
        print(f"ğŸ’° é¢„è®¡ API è°ƒç”¨: {generations * population_size * len(test_dataset)} æ¬¡")
        print(f"{'='*60}\n")
        
        # é¢„ç”Ÿæˆæ‰€æœ‰ç»„åˆï¼Œç¡®ä¿ä¸é‡å¤
        all_combinations = [
            (role, style, tech)
            for role in search_space.roles
            for style in search_space.styles
            for tech in search_space.techniques
        ]
        total_combinations = len(all_combinations)
        if total_combinations == 0:
            raise ValueError("æœç´¢ç©ºé—´ä¸ºç©ºï¼Œæ— æ³•è¿è¡Œé—ä¼ ç®—æ³•ã€‚")
        if population_size > total_combinations:
            raise ValueError(f"ç§ç¾¤è§„æ¨¡ {population_size} è¶…è¿‡æœç´¢ç©ºé—´ç»„åˆæ•° {total_combinations}ï¼Œæ— æ³•ä¿è¯ä¸é‡å¤ã€‚")

        max_generations = total_combinations // population_size
        if max_generations == 0:
            raise ValueError("æœç´¢ç©ºé—´ç»„åˆæ•°ä¸è¶³ä»¥ç”Ÿæˆå®Œæ•´ä¸€ä»£ç§ç¾¤ã€‚")
        if generations > max_generations:
            print(f"âš ï¸ ä»£æ•° {generations} è¶…è¿‡å¯ç”¨ä¸é‡å¤ä»£æ•° {max_generations}ï¼Œå·²è‡ªåŠ¨è°ƒæ•´ã€‚")
            generations = max_generations

        remaining_combinations = set(all_combinations)

        def _reserve_unique_combo(preferred_combo=None):
            if preferred_combo and preferred_combo in remaining_combinations:
                remaining_combinations.remove(preferred_combo)
                return preferred_combo
            if not remaining_combinations:
                raise RuntimeError("æœç´¢ç©ºé—´ç»„åˆå·²è€—å°½ï¼Œæ— æ³•ç”Ÿæˆä¸é‡å¤çš„ä¸ªä½“ã€‚")
            combo = random.choice(list(remaining_combinations))
            remaining_combinations.remove(combo)
            return combo

        def _finalize_unique_combo(individual):
            preferred_combo = (individual["role"], individual["style"], individual["technique"])
            role, style, technique = _reserve_unique_combo(preferred_combo)
            if (role, style, technique) != preferred_combo:
                print("    ğŸ” å»é‡: ç»„åˆå·²ä½¿ç”¨ï¼Œæ›¿æ¢ä¸ºæ–°ç»„åˆ")
            individual["role"], individual["style"], individual["technique"] = role, style, technique
            return individual

        def create_individual():
            """åˆ›å»ºä¸€ä¸ªéšæœºä¸ªä½“ï¼ˆPrompt ç»„åˆï¼‰"""
            role, style, technique = _reserve_unique_combo()
            return {
                "role": role,
                "style": style,
                "technique": technique,
                "score": 0.0,
                "full_prompt": ""
            }
        
        def evaluate_individual(individual, generation: int, index: int):
            """è¯„ä¼°ä¸ªä½“çš„é€‚åº”åº¦ï¼ˆåœ¨æµ‹è¯•é›†ä¸Šçš„å¾—åˆ†ï¼‰"""
            role = individual["role"]
            style = individual["style"]
            technique = individual["technique"]

            label_candidates = []
            if task_type == "classification":
                label_candidates = list({
                    str(sample.get("ground_truth", "")).strip()
                    for sample in test_dataset
                    if str(sample.get("ground_truth", "")).strip()
                })
            
            # æ„å»º Promptï¼ˆæ ¹æ®ä»»åŠ¡ç±»å‹ä¼˜åŒ–è¾“å‡ºæ ¼å¼ï¼‰
            if task_type == "classification":
                # åˆ†ç±»ä»»åŠ¡ï¼šå¼ºåˆ¶è¦æ±‚åªè¾“å‡ºæ ‡ç­¾
                prompt_template = f"""ä½ æ˜¯ä¸€ä½{role}ã€‚

è¯·ä»¥{style}çš„é£æ ¼å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š
{task_description}

ç­–ç•¥æç¤ºï¼š{technique}

**é‡è¦ï¼šä½ å¿…é¡»åªè¾“å‡ºåˆ†ç±»æ ‡ç­¾ï¼ˆå¦‚ï¼šç§¯æã€æ¶ˆæã€ä¸­ç«‹ï¼‰ï¼Œä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šã€åˆ†ææˆ–å…¶ä»–å†…å®¹ã€‚**

è¾“å…¥ï¼š{{{{text}}}}
è¾“å‡ºï¼ˆåªè¾“å‡ºæ ‡ç­¾ï¼‰ï¼š"""
            else:
                # å…¶ä»–ä»»åŠ¡ï¼šå¸¸è§„æ ¼å¼
                prompt_template = f"""ä½ æ˜¯ä¸€ä½{role}ã€‚

è¯·ä»¥{style}çš„é£æ ¼å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š
{task_description}

ç­–ç•¥æç¤ºï¼š{technique}

è¾“å…¥ï¼š{{{{text}}}}
"""
            
            individual["full_prompt"] = prompt_template
            
            # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
            predictions = []
            ground_truths = []
            
            print(f"  ç¬¬ {generation} ä»£ä¸ªä½“ {index}: {role} + {style} + {technique}")
            
            for idx, sample in enumerate(test_dataset, 1):
                test_input = sample.get("input", "")
                ground_truth = sample.get("ground_truth", "")
                
                # æ›¿æ¢å ä½ç¬¦
                final_prompt = prompt_template.replace("{{text}}", test_input)
                
                # è°ƒç”¨ LLMï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
                prediction = ""
                max_retries = 5
                retry_delay = 2.0
                
                for retry in range(max_retries):
                    try:
                        response = self.llm.invoke(final_prompt)
                        if not getattr(self.llm, "is_mock", False):
                            time.sleep(1.0)  # API è°ƒç”¨å»¶è¿Ÿï¼Œé—ä¼ ç®—æ³•å¯†é›†è°ƒç”¨éœ€è¦æ›´é•¿å»¶è¿Ÿ
                        prediction = response.content.strip()
                        break  # æˆåŠŸåˆ™è·³å‡ºé‡è¯•å¾ªç¯
                        
                    except Exception as e:
                        error_msg = str(e)
                        is_rate_limit = "429" in error_msg or "Too Many Requests" in error_msg
                        is_network_issue = any(
                            key in error_msg
                            for key in [
                                "HTTPSConnectionPool",
                                "ConnectionError",
                                "Read timed out",
                                "ConnectTimeout",
                                "Max retries exceeded"
                            ]
                        )

                        if is_rate_limit or is_network_issue:
                            if retry < max_retries - 1:
                                wait_time = retry_delay * (2 ** retry)  # æŒ‡æ•°é€€é¿: 2s, 4s, 8s
                                if is_rate_limit:
                                    print(f"    âš ï¸ æ ·æœ¬ {idx} è¯·æ±‚è¿‡å¿«ï¼Œç­‰å¾… {wait_time:.0f}s åé‡è¯•ï¼ˆç¬¬{retry+1}æ¬¡ï¼‰...")
                                else:
                                    print(f"    âš ï¸ æ ·æœ¬ {idx} ç½‘ç»œå¼‚å¸¸ï¼Œç­‰å¾… {wait_time:.0f}s åé‡è¯•ï¼ˆç¬¬{retry+1}æ¬¡ï¼‰...")
                                if not getattr(self.llm, "is_mock", False):
                                    time.sleep(wait_time)
                                continue
                            else:
                                print(f"    âŒ æ ·æœ¬ {idx} è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè·³è¿‡")
                                prediction = ""
                                break
                        else:
                            print(f"    âŒ æ ·æœ¬ {idx} è¯„ä¼°å¤±è´¥: {error_msg[:50]}")
                            prediction = ""
                            break
                
                # æ¸…ç†é¢„æµ‹ç»“æœ
                if prediction and task_type == "classification":
                    # å–ç¬¬ä¸€è¡Œ
                    prediction = prediction.split('\n')[0].strip()
                    # ç§»é™¤å¸¸è§çš„å‰ç¼€è¯
                    for prefix in ["è¾“å‡ºï¼š", "è¾“å‡º:", "ç»“æœï¼š", "ç»“æœ:", "åˆ†ç±»ï¼š", "åˆ†ç±»:", "æ ‡ç­¾ï¼š", "æ ‡ç­¾:"]:
                        if prediction.startswith(prefix):
                            prediction = prediction[len(prefix):].strip()
                    # å¦‚æœåŒ…å«å¤šä¸ªè¯ï¼Œå°è¯•æå–å…³é”®æ ‡ç­¾
                    if label_candidates and prediction not in label_candidates:
                        for label in label_candidates:
                            if label and label in prediction:
                                prediction = label
                                break
                    if len(prediction) > 10 and (not label_candidates or prediction not in label_candidates):
                        # å…œåº•ï¼šå°è¯•åœ¨å¥å­ä¸­æŸ¥æ‰¾å¸¸è§æƒ…æ„Ÿæ ‡ç­¾å…³é”®è¯
                        for label in ["ç§¯æ", "æ¶ˆæ", "ä¸­ç«‹", "æ­£é¢", "è´Ÿé¢", "ä¸­æ€§"]:
                            if label in prediction:
                                prediction = label
                                break
                
                predictions.append(prediction)
                ground_truths.append(ground_truth)
                
                # è°ƒè¯•è¾“å‡ºï¼šæ˜¾ç¤ºé¢„æµ‹å’ŒçœŸå®å€¼
                if generation == 1 and index == 1 and idx <= 2:  # åªæ˜¾ç¤ºç¬¬ä¸€ä»£ç¬¬ä¸€ä¸ªä½“çš„å‰2ä¸ªæ ·æœ¬
                    print(f"      [è°ƒè¯•] æ ·æœ¬{idx} é¢„æµ‹='{prediction}' vs çœŸå®='{ground_truth}'")
            
            # è®¡ç®—åˆ†æ•°
            calc = MetricsCalculator()
            
            # è¿‡æ»¤æ‰ç©ºé¢„æµ‹ï¼ˆè¯„ä¼°å¤±è´¥çš„æ ·æœ¬ï¼‰
            valid_pairs = [(p, g) for p, g in zip(predictions, ground_truths) if p]
            
            if not valid_pairs:
                # æ‰€æœ‰æ ·æœ¬éƒ½å¤±è´¥äº†
                score = 0.0
                print(f"    â†’ å¾—åˆ†: 0.00 (æ‰€æœ‰æ ·æœ¬è¯„ä¼°å¤±è´¥)")
            else:
                valid_predictions = [p for p, g in valid_pairs]
                valid_ground_truths = [g for p, g in valid_pairs]
                
                if task_type == "classification":
                    score = calc.calculate_accuracy(valid_predictions, valid_ground_truths)
                elif task_type == "summarization":
                    scores = [calc.calculate_rouge(p, g)['rougeL'] for p, g in valid_pairs]
                    score = sum(scores) / len(scores) if scores else 0
                elif task_type == "translation":
                    scores = [calc.calculate_bleu(p, g) for p, g in valid_pairs]
                    score = sum(scores) / len(scores) if scores else 0
                else:
                    score = 0.0
                
                # å¦‚æœéƒ¨åˆ†æ ·æœ¬å¤±è´¥ï¼Œæ˜¾ç¤ºæˆåŠŸç‡
                failed_count = len(predictions) - len(valid_pairs)
                if failed_count > 0:
                    print(f"    â†’ å¾—åˆ†: {score:.2f} ({len(valid_pairs)}/{len(predictions)} æ ·æœ¬æˆåŠŸ)")
                else:
                    print(f"    â†’ å¾—åˆ†: {score:.2f}")
            
            individual["score"] = score
            
            # å¦‚æœå¾—åˆ†ä¸º0ä¸”æœ‰æˆåŠŸçš„æ ·æœ¬ï¼Œæ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
            if score == 0.0 and valid_pairs:
                print(f"      [0åˆ†è°ƒè¯•] é¢„æµ‹='{valid_predictions[0][:50]}' vs çœŸå®='{valid_ground_truths[0]}'")
            
            return individual
        
        def crossover(parent1, parent2):
            """äº¤å‰ï¼šå­©å­ç»§æ‰¿çˆ¶æ¯çš„ä¼˜è‰¯åŸºå› """
            return {
                "role": random.choice([parent1["role"], parent2["role"]]),
                "style": random.choice([parent1["style"], parent2["style"]]),
                "technique": random.choice([parent1["technique"], parent2["technique"]]),
                "score": 0.0,
                "full_prompt": ""
            }
        
        def mutate(individual):
            """å˜å¼‚ï¼šéšæœºæ”¹å˜æŸäº›åŸºå› ï¼Œå¼•å…¥æ–°å¯èƒ½æ€§"""
            if random.random() < mutation_rate:
                individual["role"] = random.choice(search_space.roles)
                print(f"    ğŸ”€ å˜å¼‚: æ›´æ¢è§’è‰² â†’ {individual['role']}")
            if random.random() < mutation_rate:
                individual["style"] = random.choice(search_space.styles)
                print(f"    ğŸ”€ å˜å¼‚: æ›´æ¢é£æ ¼ â†’ {individual['style']}")
            if random.random() < mutation_rate:
                individual["technique"] = random.choice(search_space.techniques)
                print(f"    ğŸ”€ å˜å¼‚: æ›´æ¢æŠ€å·§ â†’ {individual['technique']}")
            return individual
        
        # === é—ä¼ ç®—æ³•ä¸»å¾ªç¯ ===
        
        # åˆå§‹åŒ–ç¬¬ä¸€ä»£ç§ç¾¤
        print(f"ğŸ§¬ ç¬¬ 1 ä»£ï¼šåˆå§‹åŒ–ç§ç¾¤ï¼ˆ{population_size} ä¸ªä¸ªä½“ï¼‰")
        population = [create_individual() for _ in range(population_size)]
        
        evolution_history = []
        all_results = []
        
        for gen in range(generations):
            print(f"\n{'='*60}")
            print(f"ğŸ§¬ ç¬¬ {gen + 1}/{generations} ä»£è¿›åŒ–")
            print(f"{'='*60}")
            
            # è¯„ä¼°å½“å‰ç§ç¾¤
            for i, individual in enumerate(population, 1):
                evaluate_individual(individual, gen + 1, i)
            
            # æŒ‰é€‚åº”åº¦æ’åº
            population.sort(key=lambda x: x["score"], reverse=True)
            
            # è®°å½•å†å²
            best_score = population[0]["score"]
            avg_score = sum(ind["score"] for ind in population) / len(population)
            
            evolution_history.append({
                "generation": gen + 1,
                "best_score": best_score,
                "avg_score": avg_score,
                "worst_score": population[-1]["score"]
            })
            
            print(f"\nğŸ“Š ç¬¬ {gen + 1} ä»£ç»Ÿè®¡:")
            print(f"  ğŸ¥‡ æœ€é«˜åˆ†: {best_score:.2f}")
            print(f"  ğŸ“Š å¹³å‡åˆ†: {avg_score:.2f}")
            print(f"  ğŸ“‰ æœ€ä½åˆ†: {population[-1]['score']:.2f}")
            print(f"  ğŸ† å† å†›: {population[0]['role']} + {population[0]['style']} + {population[0]['technique']}")
            
            # ä¿å­˜æ‰€æœ‰ç»“æœ
            for i, ind in enumerate(population):
                result = SearchResult(
                    iteration_id=gen * population_size + i + 1,
                    role=ind["role"],
                    style=ind["style"],
                    technique=ind["technique"],
                    full_prompt=ind["full_prompt"],
                    avg_score=ind["score"],
                    task_type=task_type
                )
                all_results.append(result)
            
            # è°ƒç”¨è¿›åº¦å›è°ƒ
            if progress_callback:
                progress_callback(gen + 1, generations, best_score, avg_score)
            
            # å¦‚æœæ˜¯æœ€åä¸€ä»£ï¼Œè·³è¿‡ç¹è¡
            if gen == generations - 1:
                break
            
            # é€‰æ‹©ï¼ˆç²¾è‹±ç­–ç•¥ï¼‰ï¼šå»é‡æ¨¡å¼ä¸‹ç²¾è‹±ç”¨äºçˆ¶ä»£é€‰æ‹©ï¼Œä¸ç›´æ¥ä¿ç•™
            elite_count = max(1, int(population_size * elite_ratio))
            print(f"\nğŸ§¬ é€‰æ‹©: ç²¾è‹±ç”¨äºçˆ¶ä»£é€‰æ‹©ï¼ˆå»é‡æ¨¡å¼ä¸ä¿ç•™åˆ°ä¸‹ä¸€ä»£ï¼‰")
            new_population = []
            
            # ç¹è¡ï¼ˆäº¤å‰ + å˜å¼‚ï¼‰
            print(f"ğŸ§¬ ç¹è¡: ç”Ÿæˆ {population_size} ä¸ªæ–°ä¸ªä½“")
            while len(new_population) < population_size:
                # è½®ç›˜èµŒé€‰æ‹©çˆ¶æ¯ï¼ˆæ›´å€¾å‘äºé€‰æ‹©é«˜åˆ†ä¸ªä½“ï¼‰
                # ç®€åŒ–ç‰ˆï¼šä»å‰50%ä¸­éšæœºé€‰
                parent_pool_size = max(2, population_size // 2)
                parent1 = random.choice(population[:parent_pool_size])
                parent2 = random.choice(population[:parent_pool_size])
                
                # äº¤å‰
                child = crossover(parent1, parent2)
                
                # å˜å¼‚
                child = mutate(child)

                # å»é‡å¹¶å ç”¨ç»„åˆ
                child = _finalize_unique_combo(child)
                
                new_population.append(child)
            
            population = new_population
        
        # æœ€ç»ˆç»“æœ
        best_result = max(all_results, key=lambda x: x.avg_score)
        
        print(f"\n{'='*60}")
        print(f"ğŸ† é—ä¼ ç®—æ³•å®Œæˆï¼")
        print(f"{'='*60}")
        print(f"ğŸ¥‡ æœ€ç»ˆå† å†›å¾—åˆ†: {best_result.avg_score:.2f}")
        print(f"ğŸ§¬ æœ€ä½³ç»„åˆ: {best_result.role} + {best_result.style} + {best_result.technique}")
        print(f"ğŸ“ˆ è¿›åŒ–å¢ç›Š: {evolution_history[-1]['best_score'] - evolution_history[0]['best_score']:.2f} åˆ†")
        print(f"{'='*60}\n")
        
        return all_results, best_result, evolution_history
