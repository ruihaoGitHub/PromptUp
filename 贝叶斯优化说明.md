# 贝叶斯优化功能说明

## 📦 安装依赖

贝叶斯优化功能需要额外安装 `optuna` 库：

```bash
pip install optuna
```

## 🎯 算法对比

| 算法 | 搜索策略 | 收敛性 | 效率 | API 成本 | 适用场景 |
|------|---------|--------|------|---------|----------|
| 🎲 **随机搜索** | 随机抽样 | 无保证 | 低 | 高（需要30-50次） | 快速探索参数空间 |
| 🧬 **遗传算法** | 进化迭代 | 单调递增 | 中 | 中（需要5代×8个体） | 精细优化，追求极致 |
| 🧐 **贝叶斯优化** | 智能推理 | 快速收敛 | **高** | **低（仅需15-20次）** | API 预算有限，追求效率 |

## 🧐 贝叶斯优化原理

### 核心思想
贝叶斯优化使用 **TPE (Tree-structured Parzen Estimator)** 算法，它会：

1. **学习历史**：记录每次尝试的参数和得分
2. **建立模型**：用概率模型预测哪些参数组合可能得高分
3. **智能决策**：在"开发"（exploit）和"探索"（explore）之间平衡
   - **开发**：选择模型预测得分高的参数
   - **探索**：尝试不确定性大的区域，避免局部最优

### 为什么适合 Prompt 优化？
- LLM API 调用**昂贵且慢**
- 参数是**离散的**（角色、风格、技巧都是分类变量）
- TPE 天然支持分类变量，无需编码
- 通常 15-20 次试验就能找到接近最优的解

## 🚀 使用方法

### 方式1：通过 UI（推荐）

1. 启动 Streamlit 应用：
```bash
streamlit run app.py
```

2. 在"🔍 智能寻优"页面：
   - 选择算法：**🧐 贝叶斯优化**
   - 设置尝试次数：15-30 次（推荐 20 次）
   - 点击"🚀 开始寻优"

3. 观察结果：
   - 实时曲线显示"得分"和"最佳得分"
   - 通常在前 10-15 次试验就能找到高分区域
   - 后续试验会在高分区域精细搜索

### 方式2：通过脚本测试

运行测试脚本：
```bash
python test_bayesian_optimization.py
```

### 方式3：代码调用

```python
from optimizer import PromptOptimizer

optimizer = PromptOptimizer(api_key="your_key", provider="nvidia")

# 生成搜索空间
search_space = optimizer.generate_search_space(
    task_description="情感分类任务",
    task_type="classification"
)

# 运行贝叶斯优化
all_results, best_result, trial_history = optimizer.run_bayesian_optimization(
    task_description="对用户评论进行情感分类",
    task_type="classification",
    test_dataset=test_data,
    search_space=search_space,
    n_trials=20  # 尝试次数
)

print(f"最佳得分: {best_result.avg_score}")
print(f"最佳 Prompt: {best_result.prompt_template}")
```

## 📊 参数说明

### n_trials（尝试次数）
- **范围**：10-50
- **推荐值**：20
- **说明**：
  - 10-15 次：快速验证，可能找到不错的结果
  - 20-30 次：平衡效率和效果，推荐
  - 30-50 次：追求极致，但边际收益递减

### 如何判断收敛？
观察曲线中的"最佳得分"线：
- ✅ **收敛**：最佳得分在前 10-15 次试验后不再明显提升
- ⚠️ **未收敛**：最佳得分持续上升，可以增加 n_trials
- 🎯 **过早停止**：如果第 5 次就找到 100 分，可以提前停止

## 🔬 实验对比示例

假设有 6 个测试样本：

| 算法 | 尝试次数 | API 调用 | 耗时（估算） | 最佳得分 |
|------|---------|---------|------------|---------|
| 随机搜索 | 30 次 | 180 次 | ~3 分钟 | 85.0 |
| 遗传算法 | 5代×8个体 | 240 次 | ~4 分钟 | 91.7 |
| **贝叶斯优化** | **15 次** | **90 次** | **~1.5 分钟** | **90.0** |

**结论**：贝叶斯优化用一半的成本找到了接近遗传算法的结果！

## 💡 最佳实践

### 1. 首次尝试流程
```
随机搜索（5次）→ 快速了解参数空间
    ↓
贝叶斯优化（20次）→ 高效找到优质 Prompt
    ↓
遗传算法（3代×6个体）→ 可选，追求极致优化
```

### 2. API 预算有限
直接使用贝叶斯优化，15-20 次试验即可。

### 3. 大规模生产环境
1. 用小样本（10条）+ 贝叶斯优化（20次）找候选 Prompt
2. 用大样本（100条）验证 Top 3 候选
3. 选择最佳 Prompt 部署

### 4. 参数调优建议
- **测试集**：6-10 个样本足够（太多会很慢）
- **n_trials**：
  - 简单任务：15 次
  - 中等难度：20 次
  - 复杂任务：30 次

## ❓ 常见问题

### Q1: 为什么我的贝叶斯优化没有比随机搜索快？
**A**: 可能原因：
- 搜索空间太小（角色/风格/技巧选项太少）
- 测试集太简单（所有组合都能得高分）
- 尝试次数太少（建议至少 15 次）

### Q2: 什么时候不适合用贝叶斯优化？
**A**: 以下情况用遗传算法更好：
- 需要"变异"来创造新 Prompt（不只是组合现有选项）
- 追求绝对最优（不在乎成本）
- 搜索空间非常大（100+ 种组合）

### Q3: 可以中断后继续吗？
**A**: 当前版本不支持断点续传。如果需要，可以：
1. 保存 `trial_history` 到文件
2. 下次运行时加载历史数据
3. 修改代码将历史数据注入 Optuna Study

## 📚 技术细节

### Optuna 配置
```python
study = optuna.create_study(
    direction="maximize",  # 最大化分数
    sampler=optuna.samplers.TPESampler(seed=42)  # TPE 算法，种子固定可复现
)
```

### TPE 算法特点
- **适合离散参数**：无需编码，直接处理分类变量
- **快速收敛**：通常 10-20 次试验就能找到好区域
- **全局搜索**：不会陷入局部最优（相比网格搜索）

### 与其他算法对比
| 特性 | Random Search | Grid Search | Genetic Algorithm | **Bayesian (TPE)** |
|------|--------------|-------------|-------------------|-------------------|
| 离散参数 | ✅ | ✅ | ✅ | ✅ |
| 智能决策 | ❌ | ❌ | ✅ | ✅ |
| 快速收敛 | ❌ | ❌ | ⚠️（需多代） | ✅ |
| 全局最优 | ⚠️（运气） | ❌（易局部） | ✅ | ✅ |
| API 效率 | 低 | 极低 | 中 | **高** |

## 🎓 进阶阅读

- [Optuna 官方文档](https://optuna.readthedocs.io/)
- [TPE 算法论文](https://papers.nips.cc/paper/2011/hash/86e8f7ab32cfd12577bc2619bc635690-Abstract.html)
- [贝叶斯优化综述](https://arxiv.org/abs/1807.02811)
