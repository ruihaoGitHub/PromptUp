# PromptUp é¡¹ç›®æ¶æ„æ–‡æ¡£

## ğŸ“ æ¶æ„æ¦‚è§ˆ

PromptUp é‡‡ç”¨**æ¨¡å—åŒ–æ¶æ„**è®¾è®¡ï¼Œå°† Prompt ä¼˜åŒ–ã€è¯„ä¼°æŒ‡æ ‡ã€ç”¨æˆ·ç•Œé¢ä¸‰å¤§æ ¸å¿ƒåŠŸèƒ½è§£è€¦ï¼Œä¾¿äºç»´æŠ¤å’Œæ‰©å±•ã€‚

### æ¶æ„å›¾ï¼ˆUMLï¼‰

#### ç³»ç»Ÿåˆ†å±‚æ¶æ„

```mermaid
graph TB
    subgraph UI["ğŸ–¥ï¸ ç”¨æˆ·ç•Œé¢å±‚"]
        APP["app.py<br/>Streamlit UI"]
    end
    
    subgraph BL["ğŸ§  ä¸šåŠ¡é€»è¾‘å±‚"]
        OPT["optimizer.py<br/>Prompt ä¼˜åŒ–å¼•æ“"]
        MET["metrics.py<br/>è¯„ä¼°æŒ‡æ ‡è®¡ç®—"]
        TPL["templates.py<br/>Prompt æ¨¡æ¿åº“"]
    end
    
    subgraph API["ğŸŒ API æ¥å£å±‚"]
        NVIDIA["langchain-nvidia-ai-endpoints<br/>NVIDIA API"]
        OPENAI["langchain-openai<br/>OpenAI API"]
    end
    
    subgraph DATA["ğŸ“¦ æ•°æ®éªŒè¯å±‚"]
        PYDANTIC["Pydantic Models<br/>OptimizedPrompt<br/>ClassificationPrompt<br/>SummarizationPrompt<br/>TranslationPrompt"]
    end
    
    subgraph EXT["ğŸ”Œ å¤–éƒ¨æœåŠ¡"]
        NVAPI["NVIDIA AI Endpoints<br/>60+ æ¨¡å‹"]
        OAIAPI["OpenAI API<br/>GPT-4o, GPT-4"]
    end
    
    APP --> OPT
    APP --> MET
    APP --> TPL
    OPT --> NVIDIA
    OPT --> OPENAI
    OPT --> PYDANTIC
    NVIDIA --> NVAPI
    OPENAI --> OAIAPI
    MET -.è¯„ä¼°ç»“æœ.-> APP
    OPT -.ä¼˜åŒ–ç»“æœ.-> APP
    
    style UI fill:#e1f5ff
    style BL fill:#fff3e0
    style API fill:#f3e5f5
    style DATA fill:#e8f5e9
    style EXT fill:#fce4ec
```

---

## ğŸ“ æ–‡ä»¶ç»“æ„è¯´æ˜

### æ ¸å¿ƒæ–‡ä»¶

#### 1. `app.py` - Streamlit ä¸»ç•Œé¢
**æ–‡ä»¶å¤§å°**ï¼šçº¦ 1437 è¡Œ  
**ä½œç”¨**ï¼šç”¨æˆ·äº¤äº’ç•Œé¢ï¼Œæ•´åˆæ‰€æœ‰åŠŸèƒ½æ¨¡å—

**ä¸»è¦åŠŸèƒ½åŒºå—**ï¼š

| ä»£ç åŒºé—´ | åŠŸèƒ½æ¨¡å— | è¯´æ˜ |
|---------|---------|------|
| 1-100 | å¯¼å…¥å’Œåˆå§‹åŒ– | å¯¼å…¥ä¾èµ–åº“ï¼ŒåŠ è½½ç¯å¢ƒå˜é‡ï¼Œåˆå§‹åŒ–æ¨¡å‹åˆ—è¡¨ |
| 100-250 | ä¾§è¾¹æ é…ç½® | API æä¾›å•†é€‰æ‹©ã€API Key è¾“å…¥ã€æ¨¡å‹é€‰æ‹©ã€ä¼˜åŒ–æ¨¡å¼é€‰æ‹© |
| 250-400 | ä»»åŠ¡ç±»å‹é€‰æ‹©å™¨ | 4 ä¸ªä»»åŠ¡ç±»å‹çš„ Tabï¼ˆç”Ÿæˆã€åˆ†ç±»ã€æ‘˜è¦ã€ç¿»è¯‘ï¼‰ |
| 400-650 | ç”Ÿæˆä»»åŠ¡ç•Œé¢ | é€šç”¨ Prompt ä¼˜åŒ–è¾“å…¥å’Œè¾“å‡º |
| 650-800 | åˆ†ç±»ä»»åŠ¡ç•Œé¢ | ä»»åŠ¡æè¿°ã€æ ‡ç­¾è¾“å…¥ã€åˆ†ç±» Prompt ç”Ÿæˆ |
| 800-900 | æ‘˜è¦ä»»åŠ¡ç•Œé¢ | ä»»åŠ¡æè¿°ã€å…³æ³¨ç‚¹è¾“å…¥ã€æ‘˜è¦ Prompt ç”Ÿæˆ |
| 900-1000 | ç¿»è¯‘ä»»åŠ¡ç•Œé¢ | æºè¯­è¨€ã€ç›®æ ‡è¯­è¨€ã€æœ¯è¯­è¡¨è¾“å…¥ã€ç¿»è¯‘ Prompt ç”Ÿæˆ |
| 1000-1200 | éªŒè¯å®éªŒå®¤ | æµ‹è¯•æ•°æ®è¾“å…¥ã€å‚è€ƒç­”æ¡ˆè¾“å…¥ã€è¿è¡Œæµ‹è¯•æŒ‰é’® |
| 1200-1437 | æµ‹è¯•é€»è¾‘ | å•æ ·æœ¬æµ‹è¯•ã€æ‰¹é‡æµ‹è¯•ã€æŒ‡æ ‡è®¡ç®—ã€ç»“æœå±•ç¤º |

**å…³é”®å‡½æ•°**ï¼š

```python
def smart_replace(template: str, text: str, task_type: str) -> str:
    """
    æ™ºèƒ½å ä½ç¬¦æ›¿æ¢å‡½æ•°
    - æ”¯æŒ 30+ ç§å ä½ç¬¦æ ¼å¼
    - è‡ªåŠ¨æ£€æµ‹å ä½ç¬¦
    - å¦‚æœç¼ºå°‘å ä½ç¬¦ï¼Œè‡ªåŠ¨æ·»åŠ 
    è¡Œå·ï¼š1082-1150
    """
    pass

def display_classification_result(predictions, references, labels):
    """
    æ˜¾ç¤ºåˆ†ç±»ä»»åŠ¡æµ‹è¯•ç»“æœ
    - è®¡ç®— Accuracy
    - å±•ç¤ºæ··æ·†çŸ©é˜µå¼å¯¹æ¯”è¡¨æ ¼
    - æ˜¾ç¤ºè¯„åˆ†è§£è¯»
    è¡Œå·ï¼š1260+
    """
    pass
```

**æŠ€æœ¯æ ˆ**ï¼š
- `streamlit`ï¼šUI æ¡†æ¶
- `st.session_state`ï¼šçŠ¶æ€ç®¡ç†ï¼ˆå­˜å‚¨ä¼˜åŒ–ç»“æœï¼‰
- `st.tabs`ï¼šå¤šä»»åŠ¡ç±»å‹åˆ‡æ¢
- `st.progress`ï¼šæ‰¹é‡æµ‹è¯•è¿›åº¦æ¡

---

#### 2. `optimizer.py` - Prompt ä¼˜åŒ–æ ¸å¿ƒå¼•æ“
**æ–‡ä»¶å¤§å°**ï¼šçº¦ 918 è¡Œ  
**ä½œç”¨**ï¼šå®ç° Meta-Prompt æŠ€æœ¯ï¼Œé’ˆå¯¹ä¸åŒä»»åŠ¡ç±»å‹ä¼˜åŒ– Prompt

**æ¨¡å—ç»“æ„**ï¼š

| ä»£ç åŒºé—´ | æ¨¡å—åç§° | è¯´æ˜ |
|---------|---------|------|
| 1-60 | æ•°æ®æ¨¡å‹å®šä¹‰ | 4 ä¸ª Pydantic æ¨¡å‹ï¼ˆOptimizedPromptã€ClassificationPromptã€SummarizationPromptã€TranslationPromptï¼‰ |
| 60-200 | PromptOptimizer ç±»åˆå§‹åŒ– | API é…ç½®ã€LLM åˆå§‹åŒ–ã€é”™è¯¯å¤„ç† |
| 200-350 | åˆ†ç±»ä»»åŠ¡ä¼˜åŒ– | `optimize_classification()` - æ ‡ç­¾æ¶ˆæ­§ã€Few-Shot åˆæˆã€æ€ç»´é“¾è®¾è®¡ |
| 350-500 | æ‘˜è¦ä»»åŠ¡ä¼˜åŒ– | `optimize_summarization()` - è§’è‰²è®¾å®šã€æå–è§„åˆ™ã€æ ¼å¼æ¨¡æ¿ |
| 500-650 | ç¿»è¯‘ä»»åŠ¡ä¼˜åŒ– | `optimize_translation()` - è¯‘è€…è§’è‰²ã€é£æ ¼æŒ‡å—ã€æœ¯è¯­è¡¨æ•´åˆ |
| 650-800 | é€šç”¨ä»»åŠ¡ä¼˜åŒ– | `optimize()` - é€šç”¨ Prompt ä¼˜åŒ–ï¼Œæ”¯æŒå¤šç§æ¡†æ¶ |
| 800-918 | è¾…åŠ©å‡½æ•° | A/B å¯¹æ¯”æµ‹è¯•ã€ç»“æœè§£æã€é”™è¯¯å¤„ç† |

**å…³é”®ç±»ä¸æ–¹æ³•**ï¼š

##### `PromptOptimizer` ç±»

```python
class PromptOptimizer:
    """
    Prompt ä¼˜åŒ–å™¨æ ¸å¿ƒç±»
    
    å±æ€§ï¼š
    - llm: LangChain LLM å®ä¾‹ï¼ˆNVIDIA/OpenAIï¼‰
    - parser: JSON è¾“å‡ºè§£æå™¨
    - api_provider: API æä¾›å•†ç±»å‹
    
    æ–¹æ³•ï¼š
    - optimize(): é€šç”¨ Prompt ä¼˜åŒ–
    - optimize_classification(): åˆ†ç±»ä»»åŠ¡ä¸“ç”¨ä¼˜åŒ–
    - optimize_summarization(): æ‘˜è¦ä»»åŠ¡ä¸“ç”¨ä¼˜åŒ–
    - optimize_translation(): ç¿»è¯‘ä»»åŠ¡ä¸“ç”¨ä¼˜åŒ–
    - compare_results(): A/B å¯¹æ¯”æµ‹è¯•
    """
```

##### æ•°æ®æ¨¡å‹ï¼ˆPydanticï¼‰

```python
class OptimizedPrompt(BaseModel):
    """é€šç”¨ä¼˜åŒ–ç»“æœ"""
    thinking_process: str       # ä¼˜åŒ–æ€è€ƒè¿‡ç¨‹
    improved_prompt: str        # ä¼˜åŒ–åçš„ Prompt
    enhancement_techniques: list[str]  # ä½¿ç”¨çš„æŠ€æœ¯
    keywords_added: list[str]   # æ–°å¢çš„å…³é”®è¯
    structure_applied: str      # åº”ç”¨çš„æ¡†æ¶

class ClassificationPrompt(BaseModel):
    """åˆ†ç±»ä»»åŠ¡ä¼˜åŒ–ç»“æœ"""
    thinking_process: str       # ä¼˜åŒ–æ€è€ƒè¿‡ç¨‹
    role_definition: str        # è§’è‰²è®¾å®š
    label_definitions: dict     # æ ‡ç­¾å®šä¹‰å­—å…¸
    few_shot_examples: list     # Few-Shot ç¤ºä¾‹
    reasoning_guidance: str     # æ€ç»´é“¾å¼•å¯¼
    output_format: str          # è¾“å‡ºæ ¼å¼è¯´æ˜
    final_prompt: str           # æœ€ç»ˆ Promptï¼ˆå«å ä½ç¬¦ï¼‰
    
class SummarizationPrompt(BaseModel):
    """æ‘˜è¦ä»»åŠ¡ä¼˜åŒ–ç»“æœ"""
    thinking_process: str       # ä¼˜åŒ–æ€è€ƒè¿‡ç¨‹
    role_setting: str           # è§’è‰²è®¾å®š
    extraction_rules: list[str] # æå–è§„åˆ™åˆ—è¡¨
    negative_constraints: list[str]  # è´Ÿé¢çº¦æŸ
    format_template: str        # æ ¼å¼æ¨¡æ¿
    step_by_step_guide: list[str]    # åˆ†æ­¥æŒ‡å¯¼
    focus_areas: list[str]      # å…³æ³¨é¢†åŸŸ
    final_prompt: str           # æœ€ç»ˆ Prompt

class TranslationPrompt(BaseModel):
    """ç¿»è¯‘ä»»åŠ¡ä¼˜åŒ–ç»“æœ"""
    thinking_process: str       # ä¼˜åŒ–æ€è€ƒè¿‡ç¨‹
    role_definition: str        # è§’è‰²è®¾å®š
    style_guidelines: list[str] # é£æ ¼æŒ‡å—åˆ—è¡¨
    glossary_section: str       # æœ¯è¯­è¡¨éƒ¨åˆ†
    workflow_steps: list[str]   # ç¿»è¯‘æµç¨‹æ­¥éª¤
    final_prompt: str           # æœ€ç»ˆ Prompt
```

##### æ ¸å¿ƒæ–¹æ³•è¯¦è§£

**1. åˆ†ç±»ä»»åŠ¡ä¼˜åŒ– (`optimize_classification`)**

```python
def optimize_classification(
    self, 
    task_description: str,  # ä»»åŠ¡æè¿°
    labels: list[str]       # æ ‡ç­¾åˆ—è¡¨
) -> ClassificationPrompt:
    """
    åˆ†ç±»ä»»åŠ¡ä¸“ç”¨ä¼˜åŒ–æ–¹æ³•
    
    ä¼˜åŒ–ç­–ç•¥ï¼š
    1. æ ‡ç­¾æ¶ˆæ­§ï¼ˆLabel Disambiguationï¼‰
       - ä¸ºæ¯ä¸ªæ ‡ç­¾ç”Ÿæˆæ˜ç¡®å®šä¹‰
       - è¯´æ˜è¾¹ç•Œæƒ…å†µå’Œåˆ¤æ–­æ ‡å‡†
       
    2. Few-Shot åˆæˆ
       - æ ¹æ®æ ‡ç­¾è‡ªåŠ¨ç”Ÿæˆ 3-5 ä¸ªå…¸å‹ç¤ºä¾‹
       - è¦†ç›–ä¸åŒæ ‡ç­¾ï¼Œå…·æœ‰ä»£è¡¨æ€§
       
    3. æ€ç»´é“¾è®¾è®¡ï¼ˆChain of Thoughtï¼‰
       - å¼•å¯¼æ¨¡å‹å…ˆåˆ†æç‰¹å¾ï¼Œå†ç»™å‡ºç»“æœ
       - ä½¿ç”¨ "Let's think step by step"
       
    4. æ ¼å¼é”å®šï¼ˆOutput Formatï¼‰
       - æ˜ç¡®è¦æ±‚è¾“å‡ºæ ¼å¼ï¼ˆJSON/çº¯æ–‡æœ¬ï¼‰
       - ç¦æ­¢å¤šä½™è§£é‡Š
       
    5. å ä½ç¬¦ç¡®ä¿
       - åœ¨ final_prompt ä¸­å¼ºåˆ¶åŒ…å«å ä½ç¬¦
       - æ”¯æŒ [å¾…åˆ†ç±»æ–‡æœ¬]ã€{{text}} ç­‰æ ¼å¼
    
    è¿”å›ï¼šClassificationPrompt å¯¹è±¡
    """
    # æ„å»º Meta-Promptï¼ˆç³»ç»Ÿæç¤ºè¯ï¼‰
    system_prompt = """
    ä½ æ˜¯ä¸“é—¨æ„å»º AI æ–‡æœ¬åˆ†ç±»å™¨çš„ä¸“å®¶...
    
    **å¿…é¡»åœ¨ final_prompt ä¸­åŒ…å«å ä½ç¬¦**ï¼š
    - [å¾…åˆ†ç±»æ–‡æœ¬] æˆ– {{text}}
    - æ˜ç¡®æ ‡æ³¨å¾…åˆ†ç±»æ–‡æœ¬çš„æ’å…¥ä½ç½®
    """
    
    # è°ƒç”¨ LLM ç”Ÿæˆä¼˜åŒ–ç»“æœ
    # è§£æ JSON è¾“å‡º
    # è¿”å›ç»“æ„åŒ–ç»“æœ
```

**2. æ‘˜è¦ä»»åŠ¡ä¼˜åŒ– (`optimize_summarization`)**

```python
def optimize_summarization(
    self,
    task_description: str,   # ä»»åŠ¡æè¿°
    source_type: str,        # æºæ–‡æœ¬ç±»å‹
    target_audience: str,    # ç›®æ ‡å—ä¼—
    focus_areas: list[str]   # æ ¸å¿ƒå…³æ³¨ç‚¹
) -> SummarizationPrompt:
    """
    æ‘˜è¦ä»»åŠ¡ä¸“ç”¨ä¼˜åŒ–æ–¹æ³•
    
    ä¼˜åŒ–ç­–ç•¥ï¼š
    1. è§’è‰²è®¾å®š
       - è®¾è®¡ä¸“ä¸šçš„æ‘˜è¦æ’°å†™è€…è§’è‰²
       - æ˜ç¡®ä»»åŠ¡èƒŒæ™¯å’Œç›®æ ‡
       
    2. æå–è§„åˆ™
       - å…³é”®ä¿¡æ¯è¯†åˆ«è§„åˆ™
       - äº‹å®ã€æ•°æ®ã€ç»“è®ºæå–æ ‡å‡†
       
    3. è´Ÿé¢çº¦æŸ
       - é¿å…ä¸»è§‚è¯„ä»·
       - ä¸æ·»åŠ åŸæ–‡æ²¡æœ‰çš„ä¿¡æ¯
       - ç¦æ­¢çŒœæµ‹å’Œæ¨æ–­
       
    4. æ ¼å¼æ¨¡æ¿
       - æä¾›ç»“æ„åŒ–è¾“å‡ºæ¨¡æ¿
       - æ”¯æŒåˆ†æ®µã€è¦ç‚¹ã€è¡¨æ ¼ç­‰æ ¼å¼
       
    5. åˆ†æ­¥æŒ‡å¯¼
       - é˜…è¯»ç†è§£ â†’ å…³é”®ç‚¹è¯†åˆ« â†’ å†…å®¹ç»„ç»‡ â†’ æ‘˜è¦è¾“å‡º
    
    è¿”å›ï¼šSummarizationPrompt å¯¹è±¡
    """
```

**3. ç¿»è¯‘ä»»åŠ¡ä¼˜åŒ– (`optimize_translation`)**

```python
def optimize_translation(
    self,
    task_description: str,    # ä»»åŠ¡æè¿°
    source_lang: str,         # æºè¯­è¨€
    target_lang: str,         # ç›®æ ‡è¯­è¨€
    style_guidelines: list[str],  # é£æ ¼æŒ‡å—
    glossary: str = ""        # æœ¯è¯­è¡¨ï¼ˆå¯é€‰ï¼‰
) -> TranslationPrompt:
    """
    ç¿»è¯‘ä»»åŠ¡ä¸“ç”¨ä¼˜åŒ–æ–¹æ³•
    
    ä¼˜åŒ–ç­–ç•¥ï¼š
    1. ä¸“ä¸šè§’è‰²è®¾å®š
       - è®¾å®šä¸ºèµ„æ·±è¯‘è€…
       - å¼ºè°ƒå‡†ç¡®æ€§å’Œä¸“ä¸šæ€§
       
    2. é£æ ¼æŒ‡å—
       - è½¬æ¢ä¸ºæ¸…å•å½¢å¼
       - æ˜ç¡®ç¿»è¯‘æ ‡å‡†
       
    3. æœ¯è¯­è¡¨æ•´åˆ
       - è§£ææœ¯è¯­å¯¹ï¼ˆæºè¯=ç›®æ ‡è¯ï¼‰
       - æ ¼å¼åŒ–ä¸ºè¡¨æ ¼æˆ–åˆ—è¡¨
       - è¦æ±‚ä¸¥æ ¼éµå®ˆæœ¯è¯­ç¿»è¯‘
       
    4. ä¸‰æ­¥ç¿»è¯‘æ³•
       - ç¬¬ä¸€æ­¥ï¼šç›´è¯‘ï¼ˆä¿è¯å‡†ç¡®ï¼‰
       - ç¬¬äºŒæ­¥ï¼šæ„è¯‘ï¼ˆç¬¦åˆç›®æ ‡è¯­è¨€ä¹ æƒ¯ï¼‰
       - ç¬¬ä¸‰æ­¥ï¼šæ¶¦è‰²ï¼ˆæå‡æµç•…åº¦ï¼‰
    
    è¿”å›ï¼šTranslationPrompt å¯¹è±¡
    """
```

**æŠ€æœ¯è¦ç‚¹**ï¼š

1. **Meta-Prompt æŠ€æœ¯**
   - ä½¿ç”¨ LLM ä¼˜åŒ– Prompt çš„æŠ€æœ¯ï¼ˆLLM-as-an-Optimizerï¼‰
   - ç³»ç»Ÿæç¤ºè¯ï¼ˆsystem_promptï¼‰åŒ…å«è¯¦ç»†çš„ä¼˜åŒ–æŒ‡å—
   - è¦æ±‚ LLM è¾“å‡º JSON æ ¼å¼çš„ç»“æ„åŒ–ç»“æœ

2. **å ä½ç¬¦æœºåˆ¶**
   - åœ¨åˆ†ç±»/æ‘˜è¦/ç¿»è¯‘ Prompt ä¸­å¼ºåˆ¶è¦æ±‚åŒ…å«å ä½ç¬¦
   - æ”¯æŒå¤šç§æ ¼å¼ï¼š`[å¾…åˆ†ç±»æ–‡æœ¬]`ã€`{{text}}`ã€`[è¾“å…¥è¯„è®º]`
   - ç¡®ä¿ç”Ÿæˆçš„ Prompt å¯ä»¥ç›´æ¥ç”¨äºæµ‹è¯•

3. **é”™è¯¯å¤„ç†**
   - API è°ƒç”¨å¤±è´¥è‡ªåŠ¨é‡è¯•
   - JSON è§£æå¤±è´¥å›é€€åˆ°æ–‡æœ¬æ¨¡å¼
   - è¯¦ç»†çš„é”™è¯¯æ—¥å¿—è¾“å‡º

4. **API é€‚é…**
   - æ”¯æŒ NVIDIA å’Œ OpenAI ä¸¤ç§ API
   - è‡ªåŠ¨æ£€æµ‹å¹¶é€‚é… API æ ¼å¼å·®å¼‚
   - ç»Ÿä¸€çš„é”™è¯¯å¤„ç†æœºåˆ¶

---

#### 3. `metrics.py` - è¯„ä¼°æŒ‡æ ‡è®¡ç®—æ¨¡å—
**æ–‡ä»¶å¤§å°**ï¼šçº¦ 200+ è¡Œ  
**ä½œç”¨**ï¼šå®ç° Accuracyã€ROUGEã€BLEU ä¸‰å¤§è¯„ä¼°æŒ‡æ ‡

**æ¨¡å—ç»“æ„**ï¼š

| ä»£ç åŒºé—´ | åŠŸèƒ½ | è¯´æ˜ |
|---------|------|------|
| 1-50 | å¯¼å…¥å’Œåˆå§‹åŒ– | å¯¼å…¥è¯„ä¼°åº“ï¼Œåˆå§‹åŒ–åˆ†è¯å™¨ |
| 50-100 | Accuracy è®¡ç®— | åˆ†ç±»ä»»åŠ¡å‡†ç¡®ç‡ |
| 100-150 | ROUGE è®¡ç®— | æ‘˜è¦ä»»åŠ¡ ROUGE-1/2/L |
| 150-200 | BLEU è®¡ç®— | ç¿»è¯‘ä»»åŠ¡ BLEU Score |
| 200+ | æŒ‡æ ‡è§£è¯» | æ ¹æ®åˆ†æ•°è¿”å›è¯„çº§å’Œå»ºè®® |

**å…³é”®ç±»ä¸æ–¹æ³•**ï¼š

```python
class MetricsCalculator:
    """
    è¯„ä¼°æŒ‡æ ‡è®¡ç®—å™¨
    
    æ–¹æ³•ï¼š
    - calculate_accuracy(): è®¡ç®—åˆ†ç±»å‡†ç¡®ç‡
    - calculate_rouge(): è®¡ç®— ROUGE-1/2/L
    - calculate_bleu(): è®¡ç®— BLEU Score
    - get_metric_interpretation(): è·å–æŒ‡æ ‡è§£è¯»
    """
    
    def calculate_accuracy(
        self, 
        predictions: list[str],  # é¢„æµ‹ç»“æœåˆ—è¡¨
        references: list[str]    # å‚è€ƒç­”æ¡ˆåˆ—è¡¨
    ) -> float:
        """
        è®¡ç®—åˆ†ç±»ä»»åŠ¡å‡†ç¡®ç‡
        
        å®ç°ï¼š
        - ä½¿ç”¨ sklearn.metrics.accuracy_score
        - è¿”å› 0-100 çš„ç™¾åˆ†æ¯”
        - è‡ªåŠ¨å¤„ç†å¤§å°å†™å’Œç©ºæ ¼
        
        è¿”å›ï¼šAccuracy (0-100)
        """
        # é¢„å¤„ç†ï¼šå»é™¤ç©ºæ ¼ï¼Œç»Ÿä¸€å¤§å°å†™
        # è°ƒç”¨ sklearn è®¡ç®—
        # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
        pass
    
    def calculate_rouge(
        self,
        prediction: str,    # LLM ç”Ÿæˆçš„æ‘˜è¦
        reference: str      # äººå·¥æ’°å†™çš„å‚è€ƒæ‘˜è¦
    ) -> dict:
        """
        è®¡ç®— ROUGE åˆ†æ•°
        
        å®ç°ï¼š
        - ä½¿ç”¨ rouge_score åº“
        - è®¡ç®— rouge1ã€rouge2ã€rougeL
        - è¿”å› F1 Scoreï¼ˆ0-100ï¼‰
        
        è¿”å›ï¼š{"rouge1": 65.3, "rouge2": 42.1, "rougeL": 58.7}
        """
        # åˆå§‹åŒ– ROUGE è®¡ç®—å™¨
        # è®¡ç®—ä¸‰ç§ ROUGE åˆ†æ•°
        # æå– F1 Score å¹¶è½¬æ¢ä¸ºç™¾åˆ†æ¯”
        pass
    
    def calculate_bleu(
        self,
        prediction: str,    # LLM ç”Ÿæˆçš„è¯‘æ–‡
        reference: str      # äººå·¥ç¿»è¯‘çš„å‚è€ƒè¯‘æ–‡
    ) -> float:
        """
        è®¡ç®— BLEU åˆ†æ•°
        
        å®ç°ï¼š
        - ä½¿ç”¨ nltk.translate.bleu_score
        - æ”¯æŒä¸­è‹±æ–‡ï¼ˆä¸­æ–‡ä½¿ç”¨ jieba åˆ†è¯ï¼‰
        - è¿”å› 0-100 çš„åˆ†æ•°
        
        è¿”å›ï¼šBLEU Score (0-100)
        """
        # æ£€æµ‹è¯­è¨€ï¼ˆä¸­æ–‡/è‹±æ–‡ï¼‰
        # ä¸­æ–‡ä½¿ç”¨ jieba åˆ†è¯ï¼Œè‹±æ–‡ä½¿ç”¨ç©ºæ ¼åˆ†è¯
        # è°ƒç”¨ sentence_bleu è®¡ç®—
        # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
        pass
    
    def get_metric_interpretation(
        self,
        metric_name: str,   # æŒ‡æ ‡åç§°ï¼ˆaccuracy/rouge/bleuï¼‰
        score: float        # åˆ†æ•°ï¼ˆ0-100ï¼‰
    ) -> tuple[str, str, str]:
        """
        è·å–æŒ‡æ ‡è§£è¯»
        
        è¿”å›ï¼š
        - level: è¯„çº§ï¼ˆä¼˜ç§€/è‰¯å¥½/éœ€æ”¹è¿›ï¼‰
        - color: é¢œè‰²ä»£ç ï¼ˆgreen/yellow/redï¼‰
        - advice: ä¼˜åŒ–å»ºè®®
        
        ç¤ºä¾‹ï¼š
        ("ä¼˜ç§€", "green", "Prompt æ•ˆæœå¾ˆå¥½ï¼Œç»§ç»­ä¿æŒï¼")
        """
        pass
```

**æŠ€æœ¯è¦ç‚¹**ï¼š

1. **ä¸­æ–‡æ”¯æŒ**
   - BLEU è®¡ç®—ä½¿ç”¨ `jieba` åˆ†è¯
   - è‡ªåŠ¨æ£€æµ‹ä¸­æ–‡å­—ç¬¦ï¼Œé€‰æ‹©åˆé€‚çš„åˆ†è¯æ–¹æ³•

2. **å½’ä¸€åŒ–å¤„ç†**
   - æ‰€æœ‰æŒ‡æ ‡ç»Ÿä¸€è¿”å› 0-100 çš„ç™¾åˆ†æ¯”
   - ä¾¿äºç»Ÿä¸€å±•ç¤ºå’Œæ¯”è¾ƒ

3. **è¯„åˆ†æ ‡å‡†**
   - Accuracy: â‰¥80% ä¼˜ç§€ï¼Œ60-80% è‰¯å¥½ï¼Œ<60% éœ€æ”¹è¿›
   - ROUGE: â‰¥50% ä¼˜ç§€ï¼Œ30-50% è‰¯å¥½ï¼Œ<30% éœ€æ”¹è¿›
   - BLEU: â‰¥40% ä¼˜ç§€ï¼Œ20-40% è‰¯å¥½ï¼Œ<20% éœ€æ”¹è¿›

---

#### 4. `templates.py` - Prompt æ¨¡æ¿åº“
**æ–‡ä»¶å¤§å°**ï¼šçº¦ 150 è¡Œ  
**ä½œç”¨**ï¼šæä¾›ç»å…¸ Prompt å·¥ç¨‹æ¡†æ¶æ¨¡æ¿

**åŒ…å«çš„æ¨¡æ¿**ï¼š

| æ¨¡æ¿åç§° | é€‚ç”¨åœºæ™¯ | æ ¸å¿ƒè¦ç´  |
|---------|---------|---------|
| CO-STAR | é€šç”¨ä»»åŠ¡ | Context, Objective, Style, Tone, Audience, Response |
| BROKE | ä¸šåŠ¡åˆ†æ | Background, Role, Objective, Key Result, Evolve |
| CRISPE | åˆ›æ„å†™ä½œ | Capacity, Role, Insight, Statement, Personality, Experiment |
| RASCEF | ä»£ç ç”Ÿæˆ | Role, Action, Steps, Context, Examples, Format |

**ä½¿ç”¨æ–¹å¼**ï¼š
```python
from templates import PROMPT_TEMPLATES

# è·å– CO-STAR æ¨¡æ¿
template = PROMPT_TEMPLATES["CO-STAR"]
print(template["description"])  # æ¨¡æ¿è¯´æ˜
print(template["structure"])     # æ¨¡æ¿ç»“æ„
```

---

#### 5. `nvidia_models.py` - NVIDIA æ¨¡å‹åˆ—è¡¨
**æ–‡ä»¶å¤§å°**ï¼šçº¦ 100 è¡Œ  
**ä½œç”¨**ï¼šç»´æŠ¤ NVIDIA AI Endpoints æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨

**æ•°æ®ç»“æ„**ï¼š
```python
NVIDIA_MODELS = [
    "meta/llama-3.1-405b-instruct",    # æ¨èï¼šæœ€å¼ºæ¨¡å‹
    "meta/llama-3.1-70b-instruct",     # å¹³è¡¡æ€§èƒ½å’Œé€Ÿåº¦
    "deepseek/deepseek-r1",            # æ¨ç†èƒ½åŠ›å¼º
    "mistralai/mistral-large-2",       # æ¬§æ´²æ¨¡å‹
    "qwen/qwen2.5-72b-instruct",       # ä¸­æ–‡æ”¯æŒå¥½
    # ... å…± 60+ ä¸ªæ¨¡å‹
]
```

---

### è¾…åŠ©æ–‡ä»¶

#### 6. `test_nvidia.py` - API è¿æ¥æµ‹è¯•è„šæœ¬
**ä½œç”¨**ï¼šæµ‹è¯• NVIDIA API é…ç½®æ˜¯å¦æ­£ç¡®

**åŠŸèƒ½**ï¼š
- è¯»å– `.env` ä¸­çš„ API Key
- è°ƒç”¨ NVIDIA API å‘é€æµ‹è¯•è¯·æ±‚
- æ˜¾ç¤ºè¿æ¥çŠ¶æ€å’Œå“åº”å†…å®¹

**ä½¿ç”¨**ï¼š
```bash
python test_nvidia.py
```

---

#### 7. `test_optimize.py` - ä¼˜åŒ–åŠŸèƒ½æµ‹è¯•è„šæœ¬
**ä½œç”¨**ï¼šæµ‹è¯• Prompt ä¼˜åŒ–åŠŸèƒ½

**æµ‹è¯•ç”¨ä¾‹**ï¼š
- é€šç”¨ Prompt ä¼˜åŒ–
- åˆ†ç±»ä»»åŠ¡ä¼˜åŒ–
- æ‘˜è¦ä»»åŠ¡ä¼˜åŒ–
- ç¿»è¯‘ä»»åŠ¡ä¼˜åŒ–

**ä½¿ç”¨**ï¼š
```bash
python test_optimize.py
```

---

#### 8. `examples.py` - ä½¿ç”¨ç¤ºä¾‹è„šæœ¬
**ä½œç”¨**ï¼šå±•ç¤ºå¦‚ä½•åœ¨ä»£ç ä¸­ä½¿ç”¨ PromptOptimizer

**ç¤ºä¾‹ä»£ç **ï¼š
```python
from optimizer import PromptOptimizer

# åˆå§‹åŒ–ä¼˜åŒ–å™¨
optimizer = PromptOptimizer(
    api_provider="nvidia",
    model_name="meta/llama-3.1-405b-instruct"
)

# ä¼˜åŒ–åˆ†ç±» Prompt
result = optimizer.optimize_classification(
    task_description="å¯¹ç”¨æˆ·è¯„è®ºè¿›è¡Œæƒ…æ„Ÿåˆ†ç±»",
    labels=["ç§¯æ", "æ¶ˆæ", "ä¸­ç«‹"]
)

print(result.final_prompt)
```

---

#### 9. `requirements.txt` - ä¾èµ–åŒ…æ¸…å•
**å†…å®¹**ï¼š
```txt
streamlit>=1.31.0
langchain-core>=0.1.0
langchain-openai>=0.0.5
langchain-nvidia-ai-endpoints>=0.0.11
pydantic>=2.5.0
python-dotenv>=1.0.0
scikit-learn>=1.3.0
rouge-score>=0.1.2
nltk>=3.8
jieba>=0.42.1
```

---

#### 10. `.env.example` - ç¯å¢ƒå˜é‡ç¤ºä¾‹
**å†…å®¹**ï¼š
```env
# API æä¾›å•†é€‰æ‹©ï¼ˆnvidia æˆ– openaiï¼‰
API_PROVIDER=nvidia

# NVIDIA API é…ç½®
NVIDIA_API_KEY=nvapi-your-key-here
NVIDIA_BASE_URL=https://integrate.api.nvidia.com/v1

# OpenAI API é…ç½®ï¼ˆå¯é€‰ï¼‰
OPENAI_API_KEY=sk-your-key-here
```

---

#### 11. `start.bat` - Windows å¯åŠ¨è„šæœ¬
**å†…å®¹**ï¼š
```batch
@echo off
echo æ­£åœ¨å¯åŠ¨ PromptUp...
streamlit run app.py
pause
```

**ä½¿ç”¨**ï¼šåŒå‡» `start.bat` å³å¯å¯åŠ¨åº”ç”¨ã€‚

---

## ğŸ”„ æ•°æ®æµå›¾

### 1. Prompt ä¼˜åŒ–æµç¨‹

```mermaid
sequenceDiagram
    participant User as ğŸ‘¤ ç”¨æˆ·
    participant App as ğŸ–¥ï¸ app.py
    participant Opt as ğŸ§  optimizer.py
    participant LLM as ğŸ¤– LLM API
    participant State as ğŸ’¾ session_state
    
    User->>App: è¾“å…¥ Prompt å’Œä»»åŠ¡ç±»å‹
    App->>App: é€‰æ‹©ä¼˜åŒ–æ¨¡å¼
    App->>Opt: è°ƒç”¨ä¼˜åŒ–æ–¹æ³•<br/>(optimize_classification/summarization/translation)
    Opt->>Opt: æ„å»º Meta-Prompt<br/>(ç³»ç»Ÿæç¤ºè¯)
    Opt->>LLM: å‘é€ä¼˜åŒ–è¯·æ±‚<br/>(NVIDIA/OpenAI API)
    LLM-->>Opt: è¿”å› JSON ç»“æ„åŒ–ç»“æœ
    Opt->>Opt: è§£æ JSON è¾“å‡º<br/>(æå– final_prompt ç­‰å­—æ®µ)
    Opt-->>App: è¿”å›ä¼˜åŒ–ç»“æœ<br/>(ClassificationPrompt ç­‰)
    App->>State: å­˜å‚¨ä¼˜åŒ–ç»“æœ
    App->>User: å±•ç¤ºä¼˜åŒ–åçš„ Prompt
    
    Note over User,State: ç”¨æˆ·å¯è¿›å…¥éªŒè¯å®éªŒå®¤æµ‹è¯•
```

### 2. éªŒè¯æµ‹è¯•æµç¨‹

```mermaid
flowchart TD
    Start([ğŸ‘¤ ç”¨æˆ·è¾“å…¥æµ‹è¯•æ•°æ®]) --> ReadPrompt[ğŸ“– è¯»å–ä¼˜åŒ–åçš„ Prompt]
    ReadPrompt --> CheckPH{ğŸ” æ£€æµ‹å ä½ç¬¦}
    CheckPH -->|æ‰¾åˆ°å ä½ç¬¦| Replace[âœ… smart_replace<br/>æ›¿æ¢å ä½ç¬¦]
    CheckPH -->|æ— å ä½ç¬¦| AutoFix[âš ï¸ è‡ªåŠ¨ä¿®å¤<br/>æ·»åŠ ä»»åŠ¡ç›¸å…³æ–‡æœ¬]
    Replace --> CallLLM[ğŸ¤– è°ƒç”¨ LLM æ‰§è¡Œä»»åŠ¡]
    AutoFix --> CallLLM
    CallLLM --> GetResult[ğŸ“¥ è·å– LLM è¾“å‡º]
    GetResult --> CalcMetrics[ğŸ“Š metrics.py<br/>è®¡ç®—è¯„ä¼°æŒ‡æ ‡]
    CalcMetrics --> CheckTask{ğŸ¯ ä»»åŠ¡ç±»å‹}
    CheckTask -->|åˆ†ç±»| ShowAcc[ğŸ“ˆ æ˜¾ç¤º Accuracy]
    CheckTask -->|æ‘˜è¦| ShowRouge[ğŸ“ˆ æ˜¾ç¤º ROUGE-1/2/L]
    CheckTask -->|ç¿»è¯‘| ShowBleu[ğŸ“ˆ æ˜¾ç¤º BLEU Score]
    ShowAcc --> Display[ğŸ’» å±•ç¤ºç»“æœå’ŒæŒ‡æ ‡]
    ShowRouge --> Display
    ShowBleu --> Display
    Display --> End([âœ… æµ‹è¯•å®Œæˆ])
    
    style Start fill:#e3f2fd
    style End fill:#c8e6c9
    style CheckPH fill:#fff9c4
    style AutoFix fill:#ffccbc
    style CalcMetrics fill:#f3e5f5
```

### 3. æ‰¹é‡æµ‹è¯•æµç¨‹ï¼ˆåˆ†ç±»ä»»åŠ¡ï¼‰

```mermaid
flowchart TD
    Start([ğŸ‘¤ ç”¨æˆ·è¾“å…¥å¤šè¡Œæµ‹è¯•æ•°æ®]) --> Split[ğŸ“‹ åˆ†å‰²ä¸ºæ ·æœ¬åˆ—è¡¨]
    Split --> InitProgress[ğŸ”„ åˆå§‹åŒ–è¿›åº¦æ¡]
    InitProgress --> Loop{ğŸ“ éå†æ¯ä¸ªæ ·æœ¬}
    
    Loop -->|å¤„ç†ä¸­| Replace[ğŸ”„ smart_replace<br/>æ›¿æ¢å ä½ç¬¦]
    Replace --> CallLLM[ğŸ¤– è°ƒç”¨ LLM åˆ†ç±»]
    CallLLM --> Extract[ğŸ“¤ æå–é¢„æµ‹æ ‡ç­¾]
    Extract --> UpdateProgress[ğŸ“Š æ›´æ–°è¿›åº¦æ¡]
    UpdateProgress --> Loop
    
    Loop -->|å…¨éƒ¨å®Œæˆ| Collect[ğŸ“¦ æ”¶é›†æ‰€æœ‰é¢„æµ‹ç»“æœ]
    Collect --> CalcAcc[ğŸ“ˆ metrics.calculate_accuracy<br/>è®¡ç®—æ€»ä½“å‡†ç¡®ç‡]
    CalcAcc --> GenTable[ğŸ“‹ ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼]
    
    subgraph Results["ç»“æœå±•ç¤º"]
        ShowMetric[ğŸ“Š æ˜¾ç¤º Accuracy æŒ‡æ ‡]
        ShowTable[ğŸ“‹ æ˜¾ç¤ºæ ·æœ¬å¯¹æ¯”è¡¨æ ¼]
        ShowLevel[ğŸ¯ æ˜¾ç¤ºè¯„åˆ†ç­‰çº§<br/>ä¼˜ç§€/è‰¯å¥½/éœ€æ”¹è¿›]
    end
    
    GenTable --> Results
    Results --> End([âœ… æ‰¹é‡æµ‹è¯•å®Œæˆ])
    
    style Start fill:#e3f2fd
    style End fill:#c8e6c9
    style Loop fill:#fff9c4
    style CalcAcc fill:#f3e5f5
    style Results fill:#e8f5e9
```

---

## ğŸ§© æ¨¡å—ä¾èµ–å…³ç³»

```mermaid
graph TD
    subgraph Main["ğŸ¯ ä¸»åº”ç”¨"]
        APP["app.py<br/>Streamlit UI"]
    end
    
    subgraph Core["ğŸ§  æ ¸å¿ƒæ¨¡å—"]
        OPT["optimizer.py<br/>Prompt ä¼˜åŒ–å™¨"]
        MET["metrics.py<br/>æŒ‡æ ‡è®¡ç®—å™¨"]
        TPL["templates.py<br/>æ¨¡æ¿åº“"]
        NVM["nvidia_models.py<br/>æ¨¡å‹åˆ—è¡¨"]
    end
    
    subgraph LC["ğŸ¦œ LangChain"]
        LCCORE["langchain-core<br/>ChatPromptTemplate<br/>JsonOutputParser"]
        LCNV["langchain-nvidia-ai-endpoints<br/>ChatNVIDIA"]
        LCOA["langchain-openai<br/>ChatOpenAI"]
    end
    
    subgraph DV["ğŸ“¦ æ•°æ®éªŒè¯"]
        PYD["pydantic<br/>BaseModel<br/>æ•°æ®éªŒè¯"]
    end
    
    subgraph ML["ğŸ“Š æœºå™¨å­¦ä¹ åº“"]
        SKL["scikit-learn<br/>accuracy_score"]
        ROUGE["rouge-score<br/>RougeScorer"]
        NLTK["nltk<br/>sentence_bleu"]
        JIEBA["jieba<br/>ä¸­æ–‡åˆ†è¯"]
    end
    
    subgraph Util["ğŸ”§ å·¥å…·åº“"]
        ST["streamlit<br/>UI æ¡†æ¶"]
        ENV["python-dotenv<br/>ç¯å¢ƒå˜é‡"]
    end
    
    APP --> OPT
    APP --> MET
    APP --> TPL
    APP --> NVM
    APP --> ST
    APP --> ENV
    
    OPT --> LCCORE
    OPT --> LCNV
    OPT --> LCOA
    OPT --> PYD
    OPT --> ENV
    
    MET --> SKL
    MET --> ROUGE
    MET --> NLTK
    MET --> JIEBA
    
    style Main fill:#e3f2fd
    style Core fill:#fff3e0
    style LC fill:#f3e5f5
    style DV fill:#e8f5e9
    style ML fill:#fce4ec
    style Util fill:#e0f2f1
```

---

## ğŸ¨ UI ç»„ä»¶ç»“æ„

### Streamlit ç•Œé¢å¸ƒå±€

```
ä¾§è¾¹æ  (Sidebar)
â”œâ”€â”€ API æä¾›å•†é€‰æ‹©å™¨ (selectbox)
â”œâ”€â”€ API Key è¾“å…¥æ¡† (text_input)
â”œâ”€â”€ æ¨¡å‹é€‰æ‹©å™¨ (selectbox)
â””â”€â”€ ä¼˜åŒ–æ¨¡å¼é€‰æ‹©å™¨ (radio)

ä¸»ç•Œé¢ (Main)
â”œâ”€â”€ Tab 1: ç”Ÿæˆä»»åŠ¡
â”‚   â”œâ”€â”€ å·¦æ ï¼šè¾“å…¥åŒº
â”‚   â”‚   â”œâ”€â”€ Prompt è¾“å…¥æ¡†
â”‚   â”‚   â”œâ”€â”€ åœºæ™¯æè¿°è¾“å…¥æ¡†
â”‚   â”‚   â””â”€â”€ ä¼˜åŒ–æŒ‰é’®
â”‚   â””â”€â”€ å³æ ï¼šç»“æœåŒº
â”‚       â”œâ”€â”€ æ€è€ƒè¿‡ç¨‹
â”‚       â”œâ”€â”€ ä¼˜åŒ–å Prompt
â”‚       â””â”€â”€ ä¼˜åŒ–æŠ€æœ¯åˆ—è¡¨
â”‚
â”œâ”€â”€ Tab 2: åˆ†ç±»ä»»åŠ¡
â”‚   â”œâ”€â”€ å·¦æ ï¼šè¾“å…¥åŒº
â”‚   â”‚   â”œâ”€â”€ ä»»åŠ¡æè¿°
â”‚   â”‚   â”œâ”€â”€ æ ‡ç­¾åˆ—è¡¨
â”‚   â”‚   â””â”€â”€ ç”ŸæˆæŒ‰é’®
â”‚   â””â”€â”€ å³æ ï¼šç»“æœåŒº
â”‚       â”œâ”€â”€ è§’è‰²å®šä¹‰
â”‚       â”œâ”€â”€ æ ‡ç­¾å®šä¹‰
â”‚       â”œâ”€â”€ Few-Shot ç¤ºä¾‹
â”‚       â””â”€â”€ æœ€ç»ˆ Prompt
â”‚
â”œâ”€â”€ Tab 3: æ‘˜è¦ä»»åŠ¡
â”‚   â””â”€â”€ ï¼ˆç±»ä¼¼ç»“æ„ï¼‰
â”‚
â”œâ”€â”€ Tab 4: ç¿»è¯‘ä»»åŠ¡
â”‚   â””â”€â”€ ï¼ˆç±»ä¼¼ç»“æ„ï¼‰
â”‚
â””â”€â”€ éªŒè¯å®éªŒå®¤ (Expander)
    â”œâ”€â”€ æµ‹è¯•è¾“å…¥åŒº (text_area)
    â”œâ”€â”€ å‚è€ƒç­”æ¡ˆåŒº (text_area)
    â”œâ”€â”€ è¿è¡Œæµ‹è¯•æŒ‰é’®
    â””â”€â”€ ç»“æœå±•ç¤ºåŒº
        â”œâ”€â”€ è¯„ä¼°æŒ‡æ ‡å¡ç‰‡
        â”œâ”€â”€ è¯¦ç»†æ—¥å¿— (expander)
        â””â”€â”€ å¯¹æ¯”è¡¨æ ¼
```

---

## ğŸ” ç¯å¢ƒå˜é‡ç®¡ç†

### é…ç½®æ–‡ä»¶ï¼š`.env`

```env
# API æä¾›å•†
API_PROVIDER=nvidia  # æˆ– openai

# NVIDIA é…ç½®
NVIDIA_API_KEY=nvapi-xxxxx
NVIDIA_BASE_URL=https://integrate.api.nvidia.com/v1

# OpenAI é…ç½®
OPENAI_API_KEY=sk-xxxxx
```

### è¯»å–æ–¹å¼

```python
from dotenv import load_dotenv
import os

load_dotenv()

api_provider = os.getenv("API_PROVIDER", "nvidia")
nvidia_key = os.getenv("NVIDIA_API_KEY")
openai_key = os.getenv("OPENAI_API_KEY")
```

### ä¼˜å…ˆçº§

1. **Streamlit ç•Œé¢è¾“å…¥**ï¼šä¸´æ—¶è¦†ç›– `.env` é…ç½®
2. **`.env` æ–‡ä»¶**ï¼šæŒä¹…åŒ–é…ç½®
3. **é»˜è®¤å€¼**ï¼š`nvidia` ä½œä¸ºé»˜è®¤æä¾›å•†

---

## ğŸš¨ é”™è¯¯å¤„ç†æœºåˆ¶

### API è°ƒç”¨é”™è¯¯

```python
try:
    result = llm.invoke(prompt)
except Exception as e:
    if "authentication" in str(e).lower():
        return "âŒ API Key æ— æ•ˆï¼Œè¯·æ£€æŸ¥é…ç½®"
    elif "rate_limit" in str(e).lower():
        return "â³ API è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åé‡è¯•"
    else:
        return f"âŒ API è°ƒç”¨å¤±è´¥ï¼š{e}"
```

### JSON è§£æé”™è¯¯

```python
try:
    result = json.loads(llm_output)
except json.JSONDecodeError:
    # å›é€€åˆ°æ–‡æœ¬æ¨¡å¼
    return {"final_prompt": llm_output}
```

### å ä½ç¬¦ç¼ºå¤±é”™è¯¯

```python
if not has_placeholder(prompt):
    # è‡ªåŠ¨ä¿®å¤ï¼šæ·»åŠ å ä½ç¬¦
    prompt += "\n\nå¾…åˆ†ç±»æ–‡æœ¬ï¼š{text}\n\nè¯·è¾“å‡ºåˆ†ç±»ç»“æœã€‚"
    logging.warning("âš ï¸ è‡ªåŠ¨ä¿®å¤ï¼šæ·»åŠ äº†å ä½ç¬¦")
```

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### 1. æ‰¹é‡å¤„ç†ä¼˜åŒ–
- åˆ†ç±»ä»»åŠ¡æ”¯æŒæ‰¹é‡æµ‹è¯•ï¼ˆä¸€æ¬¡è¾“å…¥å¤šä¸ªæ ·æœ¬ï¼‰
- ä½¿ç”¨è¿›åº¦æ¡æ˜¾ç¤ºå®æ—¶è¿›åº¦
- é¿å…é‡å¤åŠ è½½æ¨¡å‹

### 2. ç¼“å­˜æœºåˆ¶
```python
@st.cache_resource
def load_optimizer(api_provider, model_name):
    """ç¼“å­˜ä¼˜åŒ–å™¨å®ä¾‹ï¼Œé¿å…é‡å¤åˆå§‹åŒ–"""
    return PromptOptimizer(api_provider, model_name)
```

### 3. å¼‚æ­¥å¤„ç†ï¼ˆæœªå®ç°ï¼Œå¯æ‰©å±•ï¼‰
```python
# æœªæ¥å¯ä»¥ä½¿ç”¨ asyncio å®ç°å¹¶è¡Œå¤„ç†
async def batch_classify(samples):
    tasks = [classify_async(sample) for sample in samples]
    return await asyncio.gather(*tasks)
```

---

## ğŸ§ª æµ‹è¯•ç­–ç•¥

### å•å…ƒæµ‹è¯•ï¼ˆå»ºè®®æ·»åŠ ï¼‰

```python
# tests/test_optimizer.py
def test_classification_optimization():
    optimizer = PromptOptimizer("nvidia")
    result = optimizer.optimize_classification(
        task_description="æƒ…æ„Ÿåˆ†ç±»",
        labels=["ç§¯æ", "æ¶ˆæ"]
    )
    assert "final_prompt" in result
    assert "[å¾…åˆ†ç±»æ–‡æœ¬]" in result.final_prompt or "{{text}}" in result.final_prompt
```

### é›†æˆæµ‹è¯•

```bash
# test_optimize.py
python test_optimize.py
```

### æ‰‹åŠ¨æµ‹è¯•

```bash
# å¯åŠ¨åº”ç”¨è¿›è¡Œæ‰‹åŠ¨æµ‹è¯•
streamlit run app.py
```

---

## ğŸ”® æ‰©å±•æ–¹å‘

### 1. æ–°å¢ä»»åŠ¡ç±»å‹
- é—®ç­”ï¼ˆQ&Aï¼‰
- å¯¹è¯ï¼ˆConversationï¼‰
- å®ä½“æå–ï¼ˆNamed Entity Recognitionï¼‰

### 2. æ›´å¤šè¯„ä¼°æŒ‡æ ‡
- F1 Scoreï¼ˆåˆ†ç±»ä»»åŠ¡ï¼‰
- METEORï¼ˆç¿»è¯‘ä»»åŠ¡ï¼‰
- BERTScoreï¼ˆè¯­ä¹‰ç›¸ä¼¼åº¦ï¼‰

### 3. Prompt ç‰ˆæœ¬ç®¡ç†
- ä¿å­˜å†å²ä¼˜åŒ–ç»“æœ
- æ¯”è¾ƒä¸åŒç‰ˆæœ¬çš„ Prompt
- å¯¼å‡º/å¯¼å…¥ Prompt æ¨¡æ¿

### 4. æ‰¹é‡ä»»åŠ¡æ”¯æŒ
- æ”¯æŒä¸Šä¼  CSV/Excel æ–‡ä»¶
- æ‰¹é‡å¤„ç†å¤šä¸ªæ ·æœ¬
- å¯¼å‡ºç»“æœæŠ¥å‘Š

### 5. API æä¾›å•†æ‰©å±•
- Anthropic Claude
- Google Gemini
- æœ¬åœ°éƒ¨ç½²æ¨¡å‹ï¼ˆOllamaï¼‰

---

## ğŸ“š å‚è€ƒèµ„æ–™

### Prompt Engineering æŠ€æœ¯
- [CO-STAR Framework](https://www.promptingguide.ai/)
- [BROKE Framework](https://github.com/brexhq/prompt-engineering)
- [LangChain Documentation](https://python.langchain.com/)

### è¯„ä¼°æŒ‡æ ‡
- [ROUGE Metric](https://github.com/google-research/google-research/tree/master/rouge)
- [BLEU Score](https://www.nltk.org/)
- [Accuracy in Classification](https://scikit-learn.org/)

### API æ–‡æ¡£
- [NVIDIA AI Endpoints](https://build.nvidia.com/)
- [OpenAI API Reference](https://platform.openai.com/docs/)

---

## ğŸ“ è®¾è®¡æ¨¡å¼

### 1. ç­–ç•¥æ¨¡å¼ï¼ˆStrategy Patternï¼‰
- ä¸åŒä»»åŠ¡ç±»å‹ä½¿ç”¨ä¸åŒçš„ä¼˜åŒ–ç­–ç•¥
- `optimize()`, `optimize_classification()`, `optimize_summarization()`, `optimize_translation()`

### 2. å·¥å‚æ¨¡å¼ï¼ˆFactory Patternï¼‰
- `PromptOptimizer` æ ¹æ® `api_provider` åˆ›å»ºä¸åŒçš„ LLM å®ä¾‹

### 3. æ¨¡æ¿æ–¹æ³•æ¨¡å¼ï¼ˆTemplate Method Patternï¼‰
- `templates.py` æä¾›é¢„å®šä¹‰çš„ Prompt æ¨¡æ¿
- å„ä»»åŠ¡ä¼˜åŒ–æ–¹æ³•éµå¾ªç»Ÿä¸€çš„æµç¨‹

### 4. å•ä¾‹æ¨¡å¼ï¼ˆSingleton Patternï¼‰
- Streamlit ä½¿ç”¨ `@st.cache_resource` ç¡®ä¿ä¼˜åŒ–å™¨å®ä¾‹å”¯ä¸€

---

## ğŸ“ˆ ç³»ç»Ÿç›‘æ§ä¸æ—¥å¿—

### æ—¥å¿—è¾“å‡º

```python
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ç¤ºä¾‹æ—¥å¿—
logger.info("âœ… æ‰¾åˆ°å ä½ç¬¦ï¼š[å¾…åˆ†ç±»æ–‡æœ¬]")
logger.warning("âš ï¸ æœªæ‰¾åˆ°å ä½ç¬¦ï¼Œè‡ªåŠ¨ä¿®å¤")
logger.error("âŒ API è°ƒç”¨å¤±è´¥")
```

### Streamlit æ—¥å¿—å±•ç¤º

```python
with st.expander("ğŸ“ è¯¦ç»†æ—¥å¿—", expanded=False):
    st.text(log_content)
```

---

## ğŸ—ï¸ UML ç±»å›¾

### æ ¸å¿ƒç±»å…³ç³»å›¾

```mermaid
classDiagram
    class PromptOptimizer {
        -llm: ChatLLM
        -parser: JsonOutputParser
        -api_provider: str
        -model_name: str
        +optimize(user_prompt, scene_desc, mode) OptimizedPrompt
        +optimize_classification(task_desc, labels) ClassificationPrompt
        +optimize_summarization(task_desc, source_type, audience, focus_areas) SummarizationPrompt
        +optimize_translation(task_desc, source_lang, target_lang, styles, glossary) TranslationPrompt
        +compare_results(original, optimized) tuple
    }
    
    class OptimizedPrompt {
        +thinking_process: str
        +improved_prompt: str
        +enhancement_techniques: list~str~
        +keywords_added: list~str~
        +structure_applied: str
    }
    
    class ClassificationPrompt {
        +thinking_process: str
        +role_definition: str
        +label_definitions: dict
        +few_shot_examples: list
        +reasoning_guidance: str
        +output_format: str
        +final_prompt: str
    }
    
    class SummarizationPrompt {
        +thinking_process: str
        +role_setting: str
        +extraction_rules: list~str~
        +negative_constraints: list~str~
        +format_template: str
        +step_by_step_guide: list~str~
        +focus_areas: list~str~
        +final_prompt: str
    }
    
    class TranslationPrompt {
        +thinking_process: str
        +role_definition: str
        +style_guidelines: list~str~
        +glossary_section: str
        +workflow_steps: list~str~
        +final_prompt: str
    }
    
    class MetricsCalculator {
        +calculate_accuracy(predictions, references) float
        +calculate_rouge(prediction, reference) dict
        +calculate_bleu(prediction, reference) float
        +get_metric_interpretation(metric_name, score) tuple
    }
    
    class StreamlitApp {
        +smart_replace(template, text, task_type) str
        +display_classification_result(predictions, references, labels)
        +display_summarization_result(prediction, reference)
        +display_translation_result(prediction, reference)
    }
    
    PromptOptimizer --> OptimizedPrompt : ç”Ÿæˆ
    PromptOptimizer --> ClassificationPrompt : ç”Ÿæˆ
    PromptOptimizer --> SummarizationPrompt : ç”Ÿæˆ
    PromptOptimizer --> TranslationPrompt : ç”Ÿæˆ
    StreamlitApp --> PromptOptimizer : è°ƒç”¨
    StreamlitApp --> MetricsCalculator : ä½¿ç”¨
    MetricsCalculator ..> ClassificationPrompt : è¯„ä¼°
    MetricsCalculator ..> SummarizationPrompt : è¯„ä¼°
    MetricsCalculator ..> TranslationPrompt : è¯„ä¼°
    
    note for PromptOptimizer "æ ¸å¿ƒä¼˜åŒ–å¼•æ“\næ”¯æŒ 4 ç§ä»»åŠ¡ç±»å‹"
    note for MetricsCalculator "è¯„ä¼°æŒ‡æ ‡è®¡ç®—å™¨\næ”¯æŒ 3 ç§æŒ‡æ ‡"
```

### æ•°æ®æ¨¡å‹ç»§æ‰¿å…³ç³»

```mermaid
classDiagram
    class BaseModel {
        <<Pydantic>>
    }
    
    class OptimizedPrompt {
        +thinking_process: str
        +improved_prompt: str
        +enhancement_techniques: list
        +keywords_added: list
        +structure_applied: str
    }
    
    class ClassificationPrompt {
        +thinking_process: str
        +role_definition: str
        +label_definitions: dict
        +few_shot_examples: list
        +reasoning_guidance: str
        +output_format: str
        +final_prompt: str
    }
    
    class SummarizationPrompt {
        +thinking_process: str
        +role_setting: str
        +extraction_rules: list
        +negative_constraints: list
        +format_template: str
        +step_by_step_guide: list
        +focus_areas: list
        +final_prompt: str
    }
    
    class TranslationPrompt {
        +thinking_process: str
        +role_definition: str
        +style_guidelines: list
        +glossary_section: str
        +workflow_steps: list
        +final_prompt: str
    }
    
    BaseModel <|-- OptimizedPrompt
    BaseModel <|-- ClassificationPrompt
    BaseModel <|-- SummarizationPrompt
    BaseModel <|-- TranslationPrompt
    
    note for BaseModel "Pydantic åŸºç±»\næä¾›æ•°æ®éªŒè¯"
```

---

## ğŸ¯ æ€»ç»“

PromptUp é‡‡ç”¨**æ¨¡å—åŒ–ã€åˆ†å±‚**çš„æ¶æ„è®¾è®¡ï¼Œå…·æœ‰ä»¥ä¸‹ä¼˜åŠ¿ï¼š

1. **é«˜å†…èšä½è€¦åˆ**ï¼šå„æ¨¡å—èŒè´£æ˜ç¡®ï¼Œæ˜“äºç»´æŠ¤
2. **å¯æ‰©å±•æ€§å¼º**ï¼šæ–°å¢ä»»åŠ¡ç±»å‹åªéœ€æ·»åŠ ä¼˜åŒ–æ–¹æ³•
3. **é”™è¯¯å¤„ç†å®Œå–„**ï¼šå¤šå±‚æ¬¡çš„å¼‚å¸¸æ•è·å’Œæ—¥å¿—è®°å½•
4. **ç”¨æˆ·å‹å¥½**ï¼šStreamlit æä¾›ç›´è§‚çš„å›¾å½¢ç•Œé¢
5. **è¯„ä¼°ä½“ç³»å®Œæ•´**ï¼šæ”¯æŒä¸‰å¤§ä¸»æµè¯„ä¼°æŒ‡æ ‡

---

**å¦‚éœ€æ›´è¯¦ç»†çš„æ¶æ„è¯´æ˜æˆ– UML å›¾ï¼Œè¯·å‚è€ƒä»¥ä¸‹èµ„æº**ï¼š
- æºä»£ç æ³¨é‡Š
- å¼€å‘æ–‡æ¡£
- æŠ€æœ¯åšå®¢

**å¦‚æœ‰ç–‘é—®ï¼Œè¯·æäº¤ Issue æˆ–è”ç³»å¼€å‘å›¢é˜Ÿã€‚**
