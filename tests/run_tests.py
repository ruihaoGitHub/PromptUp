"""
PromptUp é¡¹ç›®è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬
æ‰§è¡Œ Level 1-3 çš„æµ‹è¯•ï¼ˆå¯¼å…¥ã€å•å…ƒã€é›†æˆï¼‰
"""
import sys
import traceback
from typing import List, Tuple


class TestResult:
    """æµ‹è¯•ç»“æœç±»"""
    def __init__(self):
        self.passed = 0
        self.failed = 0
        self.skipped = 0
        self.errors = []
    
    def add_pass(self, test_name: str):
        self.passed += 1
        print(f"  âœ… {test_name}")
    
    def add_fail(self, test_name: str, error: str):
        self.failed += 1
        self.errors.append((test_name, error))
        print(f"  âŒ {test_name}")
        print(f"     é”™è¯¯: {error[:100]}...")
    
    def add_skip(self, test_name: str, reason: str):
        self.skipped += 1
        print(f"  â­ï¸  {test_name} (è·³è¿‡: {reason})")
    
    def summary(self):
        total = self.passed + self.failed + self.skipped
        print(f"\n{'='*60}")
        print(f"ğŸ“Š æµ‹è¯•æ€»ç»“")
        print(f"{'='*60}")
        print(f"æ€»æµ‹è¯•æ•°: {total}")
        print(f"âœ… é€šè¿‡: {self.passed}")
        print(f"âŒ å¤±è´¥: {self.failed}")
        print(f"â­ï¸  è·³è¿‡: {self.skipped}")
        
        if self.failed > 0:
            print(f"\nâŒ å¤±è´¥çš„æµ‹è¯•:")
            for test_name, error in self.errors:
                print(f"  â€¢ {test_name}")
                print(f"    {error[:200]}")
        
        success_rate = (self.passed / total * 100) if total > 0 else 0
        print(f"\næˆåŠŸç‡: {success_rate:.1f}%")
        print(f"{'='*60}\n")
        
        return self.failed == 0


def run_test(test_name: str, test_func, result: TestResult):
    """è¿è¡Œå•ä¸ªæµ‹è¯•"""
    try:
        test_func()
        result.add_pass(test_name)
    except Exception as e:
        error_msg = str(e) if str(e) else traceback.format_exc()
        result.add_fail(test_name, error_msg)


# ============================================================
# Level 1: å¯¼å…¥æµ‹è¯•
# ============================================================

def test_import_optimizer():
    """æµ‹è¯• optimizer.py å¯¼å…¥"""
    from optimizer import PromptOptimizer


def test_import_metrics():
    """æµ‹è¯• metrics.py å¯¼å…¥"""
    from metrics import MetricsCalculator


def test_import_app():
    """æµ‹è¯• app.py å¯¼å…¥"""
    import app


def test_import_utils():
    """æµ‹è¯• utils æ¨¡å—å¯¼å…¥"""
    from utils import safe_json_loads, clean_improved_prompt, parse_markdown_response


def test_import_config():
    """æµ‹è¯• config æ¨¡å—å¯¼å…¥"""
    from config.models import OptimizedPrompt, SearchSpace, SearchResult
    from config.template_loader import get_generation_meta_prompt


def test_import_optimizers():
    """æµ‹è¯• optimizers æ¨¡å—å¯¼å…¥"""
    from optimizers import ClassificationOptimizer, SummarizationOptimizer, TranslationOptimizer


def test_import_algorithms():
    """æµ‹è¯• algorithms æ¨¡å—å¯¼å…¥"""
    from algorithms import (
        SearchSpaceGenerator,
        RandomSearchAlgorithm,
        GeneticAlgorithm,
        BayesianOptimization
    )


def test_import_pages():
    """æµ‹è¯• pages æ¨¡å—å¯¼å…¥"""
    from pages import GenerationPage, ClassificationPage, SummarizationPage, TranslationPage


def test_import_ui():
    """æµ‹è¯• ui æ¨¡å—å¯¼å…¥"""
    from ui import apply_custom_styles, render_sidebar


def test_import_services():
    """æµ‹è¯• services æ¨¡å—å¯¼å…¥"""
    from services import LLMService, ResponseParser


# ============================================================
# Level 2: å•å…ƒæµ‹è¯•
# ============================================================

def test_llm_service_supports_json_mode():
    """æµ‹è¯• LLMService.supports_json_mode()"""
    from services import LLMService
    
    assert LLMService.supports_json_mode("openai") == True
    assert LLMService.supports_json_mode("nvidia") == False
    assert LLMService.supports_json_mode("OPENAI") == True  # å¤§å°å†™ä¸æ•æ„Ÿ


def test_response_parser_extract_json():
    """æµ‹è¯• ResponseParser æå– JSON"""
    from services import ResponseParser
    
    # æµ‹è¯• Markdown JSON å—
    content1 = '```json\n{"key": "value"}\n```'
    result1 = ResponseParser.extract_json_from_response(content1)
    assert "```" not in result1
    assert "key" in result1
    
    # æµ‹è¯•æ™®é€šä»£ç å—
    content2 = '```\n{"key": "value"}\n```'
    result2 = ResponseParser.extract_json_from_response(content2)
    assert "```" not in result2
    
    # æµ‹è¯•çº¯æ–‡æœ¬
    content3 = '{"key": "value"}'
    result3 = ResponseParser.extract_json_from_response(content3)
    assert result3 == content3


def test_response_parser_parse_json():
    """æµ‹è¯• ResponseParser è§£æ JSON"""
    from services import ResponseParser
    
    json_str = '{"thinking_process": "test", "improved_prompt": "result"}'
    result = ResponseParser.parse_json(json_str)
    
    assert isinstance(result, dict)
    assert result["thinking_process"] == "test"
    assert result["improved_prompt"] == "result"


def test_optimized_prompt_model():
    """æµ‹è¯• OptimizedPrompt æ•°æ®æ¨¡å‹"""
    from config.models import OptimizedPrompt
    
    data = {
        "thinking_process": "æµ‹è¯•æ€è€ƒè¿‡ç¨‹",
        "improved_prompt": "æ”¹è¿›åçš„æç¤ºè¯",
        "enhancement_techniques": ["æŠ€æœ¯1", "æŠ€æœ¯2"],
        "keywords_added": ["å…³é”®è¯1"],
        "structure_applied": "CO-STAR"
    }
    
    prompt = OptimizedPrompt(**data)
    assert prompt.thinking_process == "æµ‹è¯•æ€è€ƒè¿‡ç¨‹"
    assert prompt.improved_prompt == "æ”¹è¿›åçš„æç¤ºè¯"
    assert len(prompt.enhancement_techniques) == 2


def test_search_space_model():
    """æµ‹è¯• SearchSpace æ•°æ®æ¨¡å‹"""
    from config.models import SearchSpace
    
    data = {
        "roles": ["ä¸“å®¶", "åŠ©æ‰‹"],
        "styles": ["ç®€æ´", "è¯¦ç»†"],
        "techniques": ["æŠ€å·§1", "æŠ€å·§2"]
    }
    
    space = SearchSpace(**data)
    assert len(space.roles) == 2
    assert len(space.styles) == 2
    assert len(space.techniques) == 2


def test_safe_json_loads():
    """æµ‹è¯• safe_json_loads å·¥å…·å‡½æ•°"""
    from utils import safe_json_loads
    
    # æ­£å¸¸ JSON
    result1 = safe_json_loads('{"key": "value"}')
    assert result1["key"] == "value"
    
    # å¸¦è½¬ä¹‰çš„ JSON
    result2 = safe_json_loads(r'{"key": "value"}')
    assert "key" in result2


def test_clean_improved_prompt():
    """æµ‹è¯• clean_improved_prompt å·¥å…·å‡½æ•°"""
    from utils import clean_improved_prompt
    
    # æ­£å¸¸æ–‡æœ¬
    text1 = "è¿™æ˜¯æ­£å¸¸çš„æç¤ºè¯"
    result1 = clean_improved_prompt(text1)
    assert result1 == text1
    
    # åŒ…å« JSON åŒ…è£¹çš„æ–‡æœ¬
    text2 = '{"improved_prompt": "å®é™…å†…å®¹"}'
    result2 = clean_improved_prompt(text2)
    # åº”è¯¥æå–å‡ºå®é™…å†…å®¹


# ============================================================
# Level 3: é›†æˆæµ‹è¯•
# ============================================================

def test_optimizer_initialization():
    """æµ‹è¯• PromptOptimizer åˆå§‹åŒ–"""
    from optimizer import PromptOptimizer
    
    # ä½¿ç”¨æµ‹è¯•é…ç½®åˆå§‹åŒ–
    optimizer = PromptOptimizer(
        api_key="test-key-for-init",
        model="test-model",
        provider="nvidia"
    )
    
    # éªŒè¯ LLM å·²åˆå§‹åŒ–
    assert optimizer.llm is not None
    assert optimizer.provider == "nvidia"
    assert optimizer.model == "test-model"
    
    # éªŒè¯ä»»åŠ¡ä¼˜åŒ–å™¨å·²åˆå§‹åŒ–
    assert optimizer.classification_optimizer is not None
    assert optimizer.summarization_optimizer is not None
    assert optimizer.translation_optimizer is not None
    
    # éªŒè¯ç®—æ³•å·²åˆå§‹åŒ–
    assert optimizer.search_space_generator is not None
    assert optimizer.random_search is not None
    assert optimizer.genetic_algorithm is not None
    assert optimizer.bayesian_optimization is not None
    
    print("    â„¹ï¸  æ‰€æœ‰ç»„ä»¶å·²æ­£ç¡®åˆå§‹åŒ–")


def test_llm_service_create_nvidia():
    """æµ‹è¯• LLMService åˆ›å»º NVIDIA LLM"""
    from services import LLMService
    
    llm = LLMService.create_llm(
        provider="nvidia",
        api_key="test-key",
        model="test-model"
    )
    
    assert llm is not None
    print("    â„¹ï¸  NVIDIA LLM åˆ›å»ºæˆåŠŸ")


def test_llm_service_create_openai():
    """æµ‹è¯• LLMService åˆ›å»º OpenAI LLM"""
    from services import LLMService
    
    llm = LLMService.create_llm(
        provider="openai",
        api_key="test-key",
        model="gpt-4o"
    )
    
    assert llm is not None
    print("    â„¹ï¸  OpenAI LLM åˆ›å»ºæˆåŠŸ")


def test_metrics_calculator():
    """æµ‹è¯• MetricsCalculator"""
    from metrics import MetricsCalculator
    
    calc = MetricsCalculator()
    
    # æµ‹è¯•å‡†ç¡®ç‡
    predictions = ["A", "B", "C"]
    ground_truths = ["A", "B", "C"]
    accuracy = calc.calculate_accuracy(predictions, ground_truths)
    assert accuracy == 100.0
    
    print("    â„¹ï¸  MetricsCalculator å·¥ä½œæ­£å¸¸")


# ============================================================
# ä¸»æµ‹è¯•å‡½æ•°
# ============================================================

def run_level1_tests(result: TestResult):
    """è¿è¡Œ Level 1: å¯¼å…¥æµ‹è¯•"""
    print(f"\n{'='*60}")
    print("ğŸ“¦ Level 1: å¯¼å…¥æµ‹è¯•")
    print(f"{'='*60}\n")
    
    tests = [
        ("optimizer.py å¯¼å…¥", test_import_optimizer),
        ("metrics.py å¯¼å…¥", test_import_metrics),
        ("app.py å¯¼å…¥", test_import_app),
        ("utils æ¨¡å—å¯¼å…¥", test_import_utils),
        ("config æ¨¡å—å¯¼å…¥", test_import_config),
        ("optimizers æ¨¡å—å¯¼å…¥", test_import_optimizers),
        ("algorithms æ¨¡å—å¯¼å…¥", test_import_algorithms),
        ("pages æ¨¡å—å¯¼å…¥", test_import_pages),
        ("ui æ¨¡å—å¯¼å…¥", test_import_ui),
        ("services æ¨¡å—å¯¼å…¥", test_import_services),
    ]
    
    for test_name, test_func in tests:
        run_test(test_name, test_func, result)


def run_level2_tests(result: TestResult):
    """è¿è¡Œ Level 2: å•å…ƒæµ‹è¯•"""
    print(f"\n{'='*60}")
    print("ğŸ§ª Level 2: å•å…ƒæµ‹è¯•")
    print(f"{'='*60}\n")
    
    tests = [
        ("LLMService.supports_json_mode()", test_llm_service_supports_json_mode),
        ("ResponseParser æå– JSON", test_response_parser_extract_json),
        ("ResponseParser è§£æ JSON", test_response_parser_parse_json),
        ("OptimizedPrompt æ¨¡å‹", test_optimized_prompt_model),
        ("SearchSpace æ¨¡å‹", test_search_space_model),
        ("safe_json_loads å‡½æ•°", test_safe_json_loads),
        ("clean_improved_prompt å‡½æ•°", test_clean_improved_prompt),
    ]
    
    for test_name, test_func in tests:
        run_test(test_name, test_func, result)


def run_level3_tests(result: TestResult):
    """è¿è¡Œ Level 3: é›†æˆæµ‹è¯•"""
    print(f"\n{'='*60}")
    print("ğŸ”— Level 3: é›†æˆæµ‹è¯•")
    print(f"{'='*60}\n")
    
    tests = [
        ("PromptOptimizer åˆå§‹åŒ–", test_optimizer_initialization),
        ("LLMService åˆ›å»º NVIDIA LLM", test_llm_service_create_nvidia),
        ("LLMService åˆ›å»º OpenAI LLM", test_llm_service_create_openai),
        ("MetricsCalculator åŠŸèƒ½", test_metrics_calculator),
    ]
    
    for test_name, test_func in tests:
        run_test(test_name, test_func, result)


def main():
    """ä¸»æµ‹è¯•å…¥å£"""
    print("\n" + "="*60)
    print("ğŸš€ PromptUp é¡¹ç›®è‡ªåŠ¨åŒ–æµ‹è¯•")
    print("="*60)
    print("æµ‹è¯•èŒƒå›´: Level 1-3 (å¯¼å…¥ã€å•å…ƒã€é›†æˆ)")
    print("="*60 + "\n")
    
    result = TestResult()
    
    # è¿è¡Œæµ‹è¯•
    run_level1_tests(result)
    run_level2_tests(result)
    run_level3_tests(result)
    
    # æ˜¾ç¤ºæ€»ç»“
    success = result.summary()
    
    # è¿”å›é€€å‡ºç 
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
