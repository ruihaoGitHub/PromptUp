"""
è´å¶æ–¯ä¼˜åŒ–æµ‹è¯•è„šæœ¬
æ¼”ç¤ºå¦‚ä½•ç”¨æœ€å°‘çš„å°è¯•æ¬¡æ•°æ‰¾åˆ°æœ€ä¼˜ Prompt
"""

import os
from dotenv import load_dotenv
from optimizer import PromptOptimizer

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def test_bayesian_optimization():
    """æµ‹è¯•è´å¶æ–¯ä¼˜åŒ–åŠŸèƒ½"""
    
    print("\n" + "="*60)
    print("ğŸ§ è´å¶æ–¯ä¼˜åŒ–æµ‹è¯•")
    print("="*60 + "\n")
    
    # é…ç½®
    api_provider = os.getenv("API_PROVIDER", "nvidia")
    api_key = os.getenv("NVIDIA_API_KEY") if api_provider == "nvidia" else os.getenv("OPENAI_API_KEY")
    model = "meta/llama-3.1-8b-instruct" if api_provider == "nvidia" else "gpt-4o"
    
    if not api_key:
        print("âŒ æœªæ‰¾åˆ° API Keyï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®")
        return
    
    print(f"âœ… API æä¾›å•†: {api_provider}")
    print(f"âœ… ä½¿ç”¨æ¨¡å‹: {model}\n")
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = PromptOptimizer(
        api_key=api_key,
        model=model,
        provider=api_provider
    )
    
    # æµ‹è¯•ä»»åŠ¡é…ç½®
    task_description = "å¯¹ç”¨æˆ·è¯„è®ºè¿›è¡Œæƒ…æ„Ÿåˆ†ç±»ï¼ˆç§¯æ/æ¶ˆæ/ä¸­ç«‹ï¼‰"
    task_type = "classification"
    
    # æµ‹è¯•æ•°æ®é›†ï¼ˆé€‚åº¦è§„æ¨¡ï¼‰
    test_dataset = [
        {"input": "è¿™ä¸ªäº§å“çœŸçš„å¾ˆå¥½ç”¨ï¼Œéå¸¸æ»¡æ„ï¼", "ground_truth": "ç§¯æ"},
        {"input": "ä»·æ ¼å¤ªè´µäº†ï¼Œæ€§ä»·æ¯”ä¸é«˜", "ground_truth": "æ¶ˆæ"},
        {"input": "äº§å“è´¨é‡ä¸é”™ï¼Œä½†æ˜¯ä»·æ ¼æœ‰ç‚¹è´µï¼Œæ€»ä½“æ¥è¯´è¿˜è¡Œ", "ground_truth": "ä¸­ç«‹"},
        {"input": "å¹¶ä¸æ˜¯å¾ˆæ»¡æ„è¿™æ¬¡è´­ç‰©ä½“éªŒ", "ground_truth": "æ¶ˆæ"},
        {"input": "ä¸å¾—ä¸è¯´ï¼Œè¿™æ¬¡çš„æœåŠ¡è®©æˆ‘å¾ˆæƒŠå–œ", "ground_truth": "ç§¯æ"},
        {"input": "å‘µå‘µï¼ŒçœŸæ˜¯ç‰©è¶…æ‰€å€¼å•Šï¼Œä¹°çš„æ—¶å€™è¯´å¾—å¤©èŠ±ä¹±å ï¼Œæ”¶åˆ°è´§å°±æ˜¯ä¸ªç ´çƒ‚", "ground_truth": "æ¶ˆæ"},
    ]
    
    print("ğŸ“‹ æµ‹è¯•é…ç½®ï¼š")
    print(f"  ä»»åŠ¡ç±»å‹: {task_type}")
    print(f"  ä»»åŠ¡æè¿°: {task_description}")
    print(f"  æµ‹è¯•æ ·æœ¬: {len(test_dataset)} æ¡")
    print(f"  å°è¯•æ¬¡æ•°: 15 æ¬¡")
    print(f"  é¢„è®¡ API è°ƒç”¨: {15 * len(test_dataset)} æ¬¡")
    print(f"\nğŸ’¡ è´å¶æ–¯ä¼˜åŒ–ä¼šæ™ºèƒ½é€‰æ‹©å‚æ•°ï¼Œé€šå¸¸æ¯”éšæœºæœç´¢æ•ˆç‡é«˜2-3å€\n")
    
    # ç”Ÿæˆæœç´¢ç©ºé—´
    print("-" * 60)
    print("æ­¥éª¤ 1: ç”Ÿæˆæœç´¢ç©ºé—´")
    print("-" * 60)
    
    try:
        search_space = optimizer.generate_search_space(
            task_description=task_description,
            task_type=task_type
        )
        print("âœ… æœç´¢ç©ºé—´ç”ŸæˆæˆåŠŸï¼\n")
        print(f"  è§’è‰²æ± : {search_space.roles}")
        print(f"  é£æ ¼æ± : {search_space.styles}")
        print(f"  æŠ€å·§æ± : {search_space.techniques}\n")
    except Exception as e:
        print(f"âŒ ç”Ÿæˆæœç´¢ç©ºé—´å¤±è´¥: {e}")
        return
    
    # æ‰§è¡Œè´å¶æ–¯ä¼˜åŒ–
    print("-" * 60)
    print("æ­¥éª¤ 2: æ‰§è¡Œè´å¶æ–¯ä¼˜åŒ–")
    print("-" * 60)
    
    try:
        all_results, best_result, trial_history = optimizer.run_bayesian_optimization(
            task_description=task_description,
            task_type=task_type,
            test_dataset=test_dataset,
            search_space=search_space,
            n_trials=8  # è´å¶æ–¯ä¼˜åŒ–é€šå¸¸15-20æ¬¡å°±èƒ½æ‰¾åˆ°å¥½ç»“æœ
        )
        
        # æ˜¾ç¤ºç»“æœ
        print("\n" + "="*60)
        print("ğŸ† è´å¶æ–¯ä¼˜åŒ–ç»“æœ")
        print("="*60)
        
        print(f"\nğŸ¥‡ æœ€ç»ˆå† å†›:")
        print(f"  å¾—åˆ†: {best_result.avg_score:.2f}%")
        print(f"  è§’è‰²: {best_result.role}")
        print(f"  é£æ ¼: {best_result.style}")
        print(f"  æŠ€å·§: {best_result.technique}")
        
        print(f"\nğŸ“œ å®Œæ•´ Prompt:")
        print("-" * 60)
        print(best_result.full_prompt)
        print("-" * 60)
        
        # åˆ†ææ”¶æ•›æƒ…å†µ
        print(f"\nğŸ“Š æ”¶æ•›åˆ†æ:")
        best_trial_num = next(i for i, h in enumerate(trial_history, 1) if h['score'] == best_result.avg_score)
        print(f"  - åœ¨ç¬¬ {best_trial_num} æ¬¡è¯•éªŒä¸­æ‰¾åˆ°æœ€ä½³ç»“æœ")
        print(f"  - æ€»å…±å°è¯•äº† {len(trial_history)} æ¬¡")
        print(f"  - æ”¶æ•›æ•ˆç‡: {best_trial_num / len(trial_history) * 100:.1f}% è¿›åº¦æ—¶æ‰¾åˆ°æœ€ä¼˜è§£")
        
        # æ˜¾ç¤ºå¾—åˆ†åˆ†å¸ƒ
        scores = [h['score'] for h in trial_history]
        print(f"\nğŸ“ˆ å¾—åˆ†ç»Ÿè®¡:")
        print(f"  - æœ€é«˜åˆ†: {max(scores):.2f}")
        print(f"  - å¹³å‡åˆ†: {sum(scores)/len(scores):.2f}")
        print(f"  - æœ€ä½åˆ†: {min(scores):.2f}")
        print(f"  - åˆ†æ•°æå‡: {trial_history[-1]['best_score'] - trial_history[0]['score']:.2f}")
        
        print("\nâœ… æµ‹è¯•å®Œæˆï¼")
        
        # å¯¹æ¯”è¯´æ˜
        print(f"\nğŸ’¡ æ•ˆç‡å¯¹æ¯”:")
        print(f"  - éšæœºæœç´¢éœ€è¦ 30-50 æ¬¡æ‰èƒ½æ‰¾åˆ°å¥½ç»“æœ")
        print(f"  - è´å¶æ–¯ä¼˜åŒ–é€šå¸¸ 15-20 æ¬¡å³å¯")
        print(f"  - æœ¬æ¬¡åœ¨ç¬¬ {best_trial_num} æ¬¡æ‰¾åˆ°æœ€ä¼˜ï¼ŒèŠ‚çœäº†çº¦ {(1 - best_trial_num/30) * 100:.0f}% çš„æˆæœ¬")
        
    except ImportError as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        print("è¯·å…ˆå®‰è£… optuna: pip install optuna")
    except Exception as e:
        print(f"âŒ ä¼˜åŒ–è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    test_bayesian_optimization()
